﻿﻿﻿﻿﻿﻿# Notes CS50 course Stanford University﻿Welcome to my notes about the Stanford CS50 course. Here are some terms that are explained in this course.  # Computer language explained:Computers use a binary language to read and write: - Binary consists of 0 or 1- bit = a single zero or one (0 or 1)- byte = pattern of 8 bits in a row, like 01001001. This the pattern represent a decimal number which refers to a specific alphabet letter via ASCII. The pattern 01001001 stands for the letter 'I' and the total decimal representation is 73. - KB = 1000 bytes (kilo bytes), MB = 1.000.000 bytes (mega bytes), GB = 1.000.000.000 (giga bytes)With a byte pattern, you can in total represent 256 different letters or punctuation. This is not enough for all kinds of characters and letters we use as people over the world, let alone that we also send out emoji's in text messages. The emoji's are also represented by a pattern of 0 and 1's. Therefore the new used CS language is Unicode, which goes up to 32 bytes. Most used emoji is represented by the decimal number 128514![tear-laughing emoji](https://i.pinimg.com/originals/c7/5d/52/c75d524d2bd561a23d5bf0cc2688ad48.png)### PixelA single pixel is using 3 bytes to get the right mixture of Red Green and Blue (each represented by a single byte, to get the RGB total color code).## AlgorithmsAlgorithms are the recipe / set of instructions that computers use to get from input to output. They have to be: - Correct --> to get the right output- Precise --> no room for error, as computers will follow the instruction literally.- bug = a mistake in a program  or a mistake in an algorithm. - pseudocode = language that a human can read and write which translates to a script a computer can understand- function = action for the computer to do something