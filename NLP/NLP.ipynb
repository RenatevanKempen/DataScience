{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via the site 'Beingdatum.com'  I've followed the course: 'Guide on Deep Learning for NLP'. \n",
    "\n",
    "This Notebook is a summary of that course, which I will use as reference work when having questions in a NLP project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization\n",
    "The process of segmenting running text into words and sentences\n",
    "\n",
    "### Manually tokenize a textfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world']\n"
     ]
    }
   ],
   "source": [
    "filename = 'filename.txt' #this is a textfile in which we have written 'Hello World'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words by white space\n",
    "words = text.split()\n",
    "# convert to lowercase\n",
    "words = [word.lower() for word in words]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize a textfile with NLTK (Natural Language Toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'World']\n"
     ]
    }
   ],
   "source": [
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Bag of Words model\n",
    "\n",
    "To create the bag of words model, we need to create a matrix where the columns correspond to the most frequent words in our dictionary where rows correspond to the document or sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Tokenize a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Deep learning methods are popular for natural language, primarily because they are delivering on their promise. Some of the first large demonstrations of the power of deep learning were in natural language processing, specifically speech recognition. More recently in machine translation.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first preprocess the data, in order to:\n",
    "\n",
    "- Convert text to lower case.\n",
    "- Remove all non-word characters.\n",
    "- Remove all punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all needed librairies:\n",
    "import nltk \n",
    "import re \n",
    "import numpy as np \n",
    "dataset = nltk.sent_tokenize(text) \n",
    "for i in range(len(dataset)):     \n",
    "    dataset[i] = dataset[i].lower() #all text in lowercase\n",
    "    dataset[i] = re.sub(r'\\W', ' ', dataset[i]) #Search  any non-alphanumeric character\n",
    "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i])  #search for all punctuations and split the text into three sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep learning methods are popular for natural language primarily because they are delivering on their promise ',\n",
       " 'some of the first large demonstrations of the power of deep learning were in natural language processing specifically speech recognition ',\n",
       " 'more recently in machine translation ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Obtaining most frequent words in our text: \n",
    "\n",
    "\n",
    "We will apply the following steps to generate our model:\n",
    "- We declare a dictionary to hold our bag of words. \n",
    "- Next we tokenize each sentence to words. \n",
    "- Now for each word in a sentence, we check if the word exists in our dictionary.\n",
    "- If it does, then we increment its count by 1. If it doesn’t, we add it to our dictionary and set its count as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deep</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methods</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primarily</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delivering</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>their</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promise</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonstrations</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specifically</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recently</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "deep            2\n",
       "learning        2\n",
       "methods         1\n",
       "are             2\n",
       "popular         1\n",
       "for             1\n",
       "natural         2\n",
       "language        2\n",
       "primarily       1\n",
       "because         1\n",
       "they            1\n",
       "delivering      1\n",
       "on              1\n",
       "their           1\n",
       "promise         1\n",
       "some            1\n",
       "of              3\n",
       "the             2\n",
       "first           1\n",
       "large           1\n",
       "demonstrations  1\n",
       "power           1\n",
       "were            1\n",
       "in              2\n",
       "processing      1\n",
       "specifically    1\n",
       "speech          1\n",
       "recognition     1\n",
       "more            1\n",
       "recently        1\n",
       "machine         1\n",
       "translation     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count = {} \n",
    "for data in dataset: \n",
    "    words = nltk.word_tokenize(data) \n",
    "    for word in words: \n",
    "        if word not in word2count.keys(): \n",
    "            word2count[word] = 1\n",
    "        else: \n",
    "            word2count[word] += 1\n",
    "#show the output\n",
    "import pandas as pd\n",
    "table = pd.DataFrame(word2count, index=[0])\n",
    "table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our model, we have a total of 41 words. However when processing large texts, the number of words could reach millions. We do not need to use all those words. Hence, we select a particular number of most frequently used words. To implement this we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'are',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'the',\n",
       " 'in',\n",
       " 'methods',\n",
       " 'popular',\n",
       " 'for',\n",
       " 'primarily',\n",
       " 'because',\n",
       " 'they',\n",
       " 'delivering',\n",
       " 'on',\n",
       " 'their',\n",
       " 'promise',\n",
       " 'some',\n",
       " 'first']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "freq_words = heapq.nlargest(20, word2count, key=word2count.get) #20 denotes the number of words we want. In larger datasets we can set this to larger numbers\n",
    "freq_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3  Building the Bag of Words model:\n",
    "In this step we construct a vector, which would tell us whether a word in each sentence is a frequent word or not. If a word in a sentence is a frequent word, we set it as 1, else we set it as 0.+\n",
    "\n",
    "This can be implemented with the help of following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for data in dataset:\n",
    "    vector = []\n",
    "    for word in freq_words:\n",
    "        if word in nltk.word_tokenize(data):\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    X.append(vector)\n",
    "X = np.asarray(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. N-Grams\n",
    "\n",
    "N-grams of texts are extensively used in text mining and natural language processing tasks. They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward (although you can move X words forward in more advanced scenarios).\n",
    "- When N=1, this is referred to as unigrams and this is essentially the individual words in a sentence. \n",
    "- When N=2, this is called bigrams \n",
    "- When N=3 this is called trigrams. \n",
    "- When N>3 this is usually referred to as four grams or five grams and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many N-grams in a sentence?\n",
    "If X = Number of words in a given sentence K, the number of N-grams for sentence K would be: \n",
    "\n",
    "${Ngrams_K}= X - (N-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python code for N-grams\n",
    "def generate_ngrams(text,n): \n",
    "    # split sentences into tokens\n",
    "    tokens=re.split(\"\\\\s+\",text)\n",
    "    ngrams=[] \n",
    "    # collect the n-grams\n",
    "    for i in range(len(tokens)-n+1):\n",
    "     temp=[tokens[j] for j in range(i,i+n)]\n",
    "     ngrams.append(\" \".join(temp)) \n",
    "    return ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is', 'is sparta']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ngrams('This is sparta', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding is a dense representation of words in the form of numeric vectors.\n",
    "\n",
    "The word embedding representation is able to reveal many hidden relationships between words. For example, vector(“cat”) – vector(“kitten”) is similar to vector(“dog”) – vector(“puppy”).\n",
    "\n",
    "### Why do we use word embedding?\n",
    "Words aren’t things that computers naturally understand. By encoding them in a numeric form, we can apply mathematical rules and do matrix operations to them. This makes them amazing in the world of machine learning, especially.\n",
    "\n",
    "Take deep learning for example. By encoding words in a numerical form, we can take many deep learning architectures and apply them to words. Convolutional neural networks have been applied to NLP tasks using word embedding and have set the state-of-the-art performance for many tasks.\n",
    "\n",
    "Even better, what we have found is that we can actually pre-train word embedding that are applicable to many tasks. \n",
    "\n",
    "### examples of word embedding:\n",
    "-  <span style=\"text-decoration: underline\">**One-Hot-Encoding (Count Vectorizing)**</span>:\n",
    "\n",
    "Create a vector that has as many dimensions as your corpora has unique words. Each unique word has a unique dimension and will be represented by a 1 in that dimension with 0s everywhere else.\n",
    "- <span style=\"text-decoration: underline\">**TF-IDF Transform**</span>:\n",
    "\n",
    "TF-IDF vectors are related to one-hot encoded vectors. However, instead of just featuring a count, they feature numerical representations where words aren’t just there or not there. Instead, words are represented by their term frequency multiplied by their inverse document frequency.\n",
    "In simpler terms, words that occur a lot but everywhere should be given very little weighting or significance. We can think of this as words like the or and in the English language. They don’t provide a large amount of value.\n",
    "However, if a word appears very little or appears frequently, but only in one or two places, then these are probably more important words and should be weighted as such.\n",
    "Again, this suffers from the downside of very high dimensional representations that don’t capture semantic relatedness.\n",
    "- <span style=\"text-decoration: underline\">**Co-Occurrence Matrix**</span>:\n",
    "\n",
    "A co-occurrence matrix is exactly what it sounds like: a giant matrix that is as long and as wide as the vocabulary size. If words occur together, they are marked with a positive entry. Otherwise, they have a 0. \n",
    "It boils down to a numeric representation that simple asks the question of “Do words occur together? If yes, then count this.”\n",
    "And what can we already see becoming a big problem? Super large representation! If we thought that one-hot encoding was high dimensional, then co-occurrence is high dimensional squared. That’s a lot of data to store in memory\n",
    "\n",
    "Advantages of Co-occurrence Matrix\n",
    "\n",
    "- It preserves the semantic relationship between words. i.e men and women tend to be closer than man and apple.\n",
    "- It uses SVD at its core, which produces more accurate word vector representations than existing methods.\n",
    "- It uses factorization which is a well-defined problem and can be efficiently solved.\n",
    "- It has to be computed once and can be used anytime once computed. In this sense, it is faster in comparison to others.\n",
    "\n",
    "Disadvantages of Co-Occurrence Matrix+\n",
    "\n",
    "- It requires huge memory to store the co-occurrence matrix.\n",
    "- But, this problem can be circumvented by factoring the matrix out of the system for example in Hadoop clusters etc. and can be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example using count vertorizing / one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# To create a Count Vectorizer, we simply need to instantiate one.\n",
    "\n",
    "sample_text = [\"Machine Learning: Introduction to Machine learning and hands-on experience on the various applications of ML\",\n",
    "\"Deep Learning: Introduction to Deep learning & NLP\"]\n",
    "#these are two booktitles\n",
    "\n",
    "#CountVectorizer Plain and Simple\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(sample_text)\n",
    "count_vector=cv.fit_transform(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens above is that the 2 books titles are preprocessed, tokenized and represented as a sparse matrix as explained in the introduction. By default, CountVectorizer does the following:\n",
    "\n",
    "- lowercases your text (set lowercase=false if you don’t want lowercasing)\n",
    "- uses utf-8 encoding\n",
    "- performs tokenization (converts raw text to smaller units of text)\n",
    "- uses word level tokenization (meaning each word is treated as a separate token)\n",
    "- ignores single characters during tokenization (so say bye bye to words like ‘a’ and ‘I’)\n",
    "Now, let’s look at the vocabulary (collection of unique words from our documents):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'machine': 7,\n",
       " 'learning': 6,\n",
       " 'introduction': 5,\n",
       " 'to': 13,\n",
       " 'and': 0,\n",
       " 'hands': 4,\n",
       " 'on': 11,\n",
       " 'experience': 3,\n",
       " 'the': 12,\n",
       " 'various': 14,\n",
       " 'applications': 1,\n",
       " 'of': 10,\n",
       " 'ml': 8,\n",
       " 'deep': 2,\n",
       " 'nlp': 9}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using all the defaults, these are all word level tokens, lower-cased. Note that the numbers here are not counts, they are the position in the sparse vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check the shape:\n",
    "count_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have two rows (two titles) and 15 unique words! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer and Stop Words\n",
    "\n",
    "Now, the first thing you may want to do, is to eliminate stop words from your text as it has limited predictive power and may not help with downstream tasks such as text classification. Stop word removal is a breeze with CountVectorizer and it can be done in several ways:\n",
    "\n",
    "- Use a custom stop word list that you provide\n",
    "- Use sklearn’s built in English stop word list (not recommended)\n",
    "- Create corpora specific stop words using max_df and min_df (highly recommended)\n",
    "\n",
    "Now let’s look at these 3 ways of using stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Custom stop word list:\n",
    "cv = CountVectorizer(sample_text,stop_words=[\"all\",\"on\",\"the\",\"is\",\"and\",\"to\"])\n",
    "count_vector=cv.fit_transform(sample_text)\n",
    "count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all', 'on', 'the', 'is', 'and', 'to']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the shape has changed from 15 unique words to 11 unique words because the stop words have been removed. \n",
    "#let's see what python has remembered as the stop word list:\n",
    "cv.stop_words\n",
    "\n",
    "# Note that we can actually load stop words directly from a file into a list and supply that as the stop word list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Words using MIN_DF:\n",
    "\n",
    "The goal of MIN_DF is to ignore words that have very few occurrences to be considered meaningful. For example, in your text you may have names of people that may appear in only 1 or two documents. In some applications, this may qualify as noise and could be eliminated from further analysis.+\n",
    "\n",
    "Instead of using a minimum term frequency (total occurrences of a word) to eliminate words, MIN_DF looks at _**how many documents contained a term**_, better known as _**document frequency**_. The MIN_DF value can be an _**absolute value**_ (e.g. 1, 2, 3, 4) or a _**value representing proportion of documents**_ (e.g. 0.25 meaning, ignore words that have appeared in 25% of the documents) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and',\n",
       " 'applications',\n",
       " 'deep',\n",
       " 'experience',\n",
       " 'hands',\n",
       " 'machine',\n",
       " 'ml',\n",
       " 'nlp',\n",
       " 'of',\n",
       " 'on',\n",
       " 'the',\n",
       " 'various'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eliminating words that appeared in less than 2 documents:\n",
    "\n",
    "cv = CountVectorizer(sample_text,min_df=2)\n",
    "count_vector=cv.fit_transform(sample_text)\n",
    "cv.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning': 1, 'introduction': 0, 'to': 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To see what’s remaining, all we need to do is check the vocabulary again\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Words using MAX_DF:\n",
    "\n",
    "Just as we ignored words that were too rare with MIN_DF, we can ignore words that are too common with MAX_DF. \n",
    "\n",
    "MAX_DF looks at _**how many documents contained a term**_, and if it exceeds the MAX_DF threshold, then it is eliminated from consideration. The MAX_DF value can be an _**absolute value**_ (e.g. 1, 2, 3, 4) or a _**value representing proportion of documents**_ (e.g. 0.85 meaning, ignore words appeared in 85% of the documents as they are too common)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'introduction', 'learning', 'to'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(sample_text,max_df=0.50)\n",
    "count_vector=cv.fit_transform(sample_text)\n",
    "cv.stop_words_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to see which words have been eliminated, you can use cv.stop_words_ (see output above):+\n",
    "\n",
    "In this example, all the words that appeared in all 2 book titles have been eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction based methods:\n",
    "\n",
    "#### 1. Continuous Bag of Words(CBOW) model\n",
    "CBOW is learning to predict the word by the context. A context may be single word or multiple words for a given target words.\n",
    "\n",
    "- Example text “The man jumped over the wall.”\n",
    "\n",
    "CBOW's approach is to treat {“The”, “man”, ’over”, “the’, “wall”} as a context and from these words, be able to predict or generate the center word “jumped”. \n",
    "\n",
    "#### 2. Skip-gram model\n",
    "\n",
    "- Example text “The man jumped over the wall.”\n",
    "\n",
    "Skip-gram's approach is to create a model such that given the center word “jumped”, the model will be able to predict or generate the surrounding words “The”, “man”, “over”, “the”, “wall”. Here we call the word “jumped” the context. \n",
    "\n",
    "Advantages/Disadvantages of CBOW and Skip-gram:\n",
    "\n",
    "- Being probabilistic is nature, these are supposed to perform superior to deterministic methods(generally).\n",
    "- These are low on memory. They don’t need to have huge RAM requirements like that of co-occurrence matrix where it needs to store three huge matrices.\n",
    "- Though CBOW (predict target from context) and skip-gram (predict context words from target) are just inverted methods to each other, they each have their advantages/disadvantages. Since CBOW can use many context words to predict the 1 target word, it can essentially _**smooth out**_ over the distribution. This is essentially like regularization and offer very good performance when our input data is not so large. However the skip-gram model is more _**fine grained**_ so we are able to extract more information and essentially have more accurate embeddings when we have a large data set (large data is always the best regularizer). Skip-gram with negative sub-sampling outperforms every other method generally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec using Gensim library\n",
    "\n",
    "Let’s create a corpus using a single wikipedia article. To do so, we need to scrape wikipedia using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (4.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "#Used to parse XML and HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The article we are going to scrape is the Wikipedia article on Artificial Intelligence. \n",
    "#Let’s write a Python Script to scrape the article from Wikipedia\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "article = scrapped_data .read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the script above, we first download the Wikipedia article using the urlopen method of the request class of the urllib library. We then read the article content and parse it using an object of the BeautifulSoup class. Wikipedia stores the text content of the article inside p tags. We use the find_all function of the BeautifulSoup object to fetch all the contents from the paragraph tags of the article.\n",
    "\n",
    "Finally, we join all the paragraphs together and store the scraped article in article_text variable for later use.\n",
    "\n",
    "**Preprocessing**\n",
    "\n",
    "The next step is to preprocess the content for Word2Vec model. The following script preprocess the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "processed_article = article_text.lower()\n",
    "processed_article = re.sub('[^a-zA-Z]', ' ', processed_article )\n",
    "processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
    "\n",
    "# Preparing the dataset\n",
    "all_sentences = nltk.sent_tokenize(processed_article)\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "\n",
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['computer', 'science', 'artificial', 'intelligence', 'ai', 'sometimes', 'called', 'machine', 'intelligence', 'intelligence', 'demonstrated', 'machines', 'contrast', 'natural', 'intelligence', 'displayed', 'humans', 'leading', 'ai', 'textbooks', 'define', 'field', 'study', 'intelligent', 'agents', 'device', 'perceives', 'environment', 'takes', 'actions', 'maximize', 'chance', 'successfully', 'achieving', 'goals', 'colloquially', 'term', 'artificial', 'intelligence', 'often', 'used', 'describe', 'machines', 'computers', 'mimic', 'cognitive', 'functions', 'humans', 'associate', 'human', 'mind', 'learning', 'problem', 'solving', 'machines', 'become', 'increasingly', 'capable', 'tasks', 'considered', 'require', 'intelligence', 'often', 'removed', 'definition', 'ai', 'phenomenon', 'known', 'ai', 'effect', 'quip', 'tesler', 'theorem', 'says', 'ai', 'whatever', 'done', 'yet', 'instance', 'optical', 'character', 'recognition', 'frequently', 'excluded', 'things', 'considered', 'ai', 'become', 'routine', 'technology', 'modern', 'machine', 'capabilities', 'generally', 'classified', 'ai', 'include', 'successfully', 'understanding', 'human', 'speech', 'competing', 'highest', 'level', 'strategic', 'game', 'systems', 'chess', 'go', 'autonomously', 'operating', 'cars', 'intelligent', 'routing', 'content', 'delivery', 'networks', 'military', 'simulations', 'artificial', 'intelligence', 'founded', 'academic', 'discipline', 'years', 'since', 'experienced', 'several', 'waves', 'optimism', 'followed', 'disappointment', 'loss', 'funding', 'known', 'ai', 'winter', 'followed', 'new', 'approaches', 'success', 'renewed', 'funding', 'history', 'ai', 'research', 'divided', 'subfields', 'often', 'fail', 'communicate', 'sub', 'fields', 'based', 'technical', 'considerations', 'particular', 'goals', 'e', 'g', 'robotics', 'machine', 'learning', 'use', 'particular', 'tools', 'logic', 'artificial', 'neural', 'networks', 'deep', 'philosophical', 'differences', 'subfields', 'also', 'based', 'social', 'factors', 'particular', 'institutions', 'work', 'particular', 'researchers', 'traditional', 'problems', 'goals', 'ai', 'research', 'include', 'reasoning', 'knowledge', 'representation', 'planning', 'learning', 'natural', 'language', 'processing', 'perception', 'ability', 'move', 'manipulate', 'objects', 'general', 'intelligence', 'among', 'field', 'long', 'term', 'goals', 'approaches', 'include', 'statistical', 'methods', 'computational', 'intelligence', 'traditional', 'symbolic', 'ai', 'many', 'tools', 'used', 'ai', 'including', 'versions', 'search', 'mathematical', 'optimization', 'artificial', 'neural', 'networks', 'methods', 'based', 'statistics', 'probability', 'economics', 'ai', 'field', 'draws', 'upon', 'computer', 'science', 'information', 'engineering', 'mathematics', 'psychology', 'linguistics', 'philosophy', 'many', 'fields', 'field', 'founded', 'assumption', 'human', 'intelligence', 'precisely', 'described', 'machine', 'made', 'simulate', 'raises', 'philosophical', 'arguments', 'nature', 'mind', 'ethics', 'creating', 'artificial', 'beings', 'endowed', 'human', 'like', 'intelligence', 'issues', 'explored', 'myth', 'fiction', 'philosophy', 'since', 'antiquity', 'people', 'also', 'consider', 'ai', 'danger', 'humanity', 'progresses', 'unabated', 'others', 'believe', 'ai', 'unlike', 'previous', 'technological', 'revolutions', 'create', 'risk', 'mass', 'unemployment', 'twenty', 'first', 'century', 'ai', 'techniques', 'experienced', 'resurgence', 'following', 'concurrent', 'advances', 'computer', 'power', 'large', 'amounts', 'data', 'theoretical', 'understanding', 'ai', 'techniques', 'become', 'essential', 'part', 'technology', 'industry', 'helping', 'solve', 'many', 'challenging', 'problems', 'computer', 'science', 'software', 'engineering', 'operations', 'research', 'thought', 'capable', 'artificial', 'beings', 'appeared', 'storytelling', 'devices', 'antiquity', 'common', 'fiction', 'mary', 'shelley', 'frankenstein', 'karel', 'apek', 'r', 'u', 'r', 'rossum', 'universal', 'robots', 'characters', 'fates', 'raised', 'many', 'issues', 'discussed', 'ethics', 'artificial', 'intelligence', 'study', 'mechanical', 'formal', 'reasoning', 'began', 'philosophers', 'mathematicians', 'antiquity', 'study', 'mathematical', 'logic', 'led', 'directly', 'alan', 'turing', 'theory', 'computation', 'suggested', 'machine', 'shuffling', 'symbols', 'simple', 'could', 'simulate', 'conceivable', 'act', 'mathematical', 'deduction', 'insight', 'digital', 'computers', 'simulate', 'process', 'formal', 'reasoning', 'known', 'church', 'turing', 'thesis', 'along', 'concurrent', 'discoveries', 'neurobiology', 'information', 'theory', 'cybernetics', 'led', 'researchers', 'consider', 'possibility', 'building', 'electronic', 'brain', 'turing', 'proposed', 'changing', 'question', 'whether', 'machine', 'intelligent', 'whether', 'possible', 'machinery', 'show', 'intelligent', 'behaviour', 'first', 'work', 'generally', 'recognized', 'ai', 'mccullouch', 'pitts', 'formal', 'design', 'turing', 'complete', 'artificial', 'neurons', 'field', 'ai', 'research', 'born', 'workshop', 'dartmouth', 'college', 'term', 'artificial', 'intelligence', 'coined', 'john', 'mccarthy', 'distinguish', 'field', 'cybernetics', 'escape', 'influence', 'cyberneticist', 'norbert', 'wiener', 'attendees', 'allen', 'newell', 'cmu', 'herbert', 'simon', 'cmu', 'john', 'mccarthy', 'mit', 'marvin', 'minsky', 'mit', 'arthur', 'samuel', 'ibm', 'became', 'founders', 'leaders', 'ai', 'research', 'students', 'produced', 'programs', 'press', 'described', 'astonishing', 'computers', 'learning', 'checkers', 'strategies', 'c', 'reportedly', 'playing', 'better', 'average', 'human', 'solving', 'word', 'problems', 'algebra', 'proving', 'logical', 'theorems', 'logic', 'theorist', 'first', 'run', 'c', 'speaking', 'english', 'middle', 'research', 'u', 'heavily', 'funded', 'department', 'defense', 'laboratories', 'established', 'around', 'world', 'ai', 'founders', 'optimistic', 'future', 'herbert', 'simon', 'predicted', 'machines', 'capable', 'within', 'twenty', 'years', 'work', 'man', 'marvin', 'minsky', 'agreed', 'writing', 'within', 'generation', 'problem', 'creating', 'artificial', 'intelligence', 'substantially', 'solved', 'failed', 'recognize', 'difficulty', 'remaining', 'tasks', 'progress', 'slowed', 'response', 'criticism', 'sir', 'james', 'lighthill', 'ongoing', 'pressure', 'us', 'congress', 'fund', 'productive', 'projects', 'u', 'british', 'governments', 'cut', 'exploratory', 'research', 'ai', 'next', 'years', 'would', 'later', 'called', 'ai', 'winter', 'period', 'obtaining', 'funding', 'ai', 'projects', 'difficult', 'early', 'ai', 'research', 'revived', 'commercial', 'success', 'expert', 'systems', 'form', 'ai', 'program', 'simulated', 'knowledge', 'analytical', 'skills', 'human', 'experts', 'market', 'ai', 'reached', 'billion', 'dollars', 'time', 'japan', 'fifth', 'generation', 'computer', 'project', 'inspired', 'u', 'british', 'governments', 'restore', 'funding', 'academic', 'research', 'however', 'beginning', 'collapse', 'lisp', 'machine', 'market', 'ai', 'fell', 'disrepute', 'second', 'longer', 'lasting', 'hiatus', 'began', 'development', 'metal', 'oxide', 'semiconductor', 'mos', 'large', 'scale', 'integration', 'vlsi', 'form', 'complementary', 'mos', 'cmos', 'transistor', 'technology', 'enabled', 'development', 'practical', 'artificial', 'neural', 'network', 'ann', 'technology', 'landmark', 'publication', 'field', 'book', 'analog', 'vlsi', 'implementation', 'neural', 'systems', 'carver', 'mead', 'mohammed', 'ismail', 'late', 'early', 'st', 'century', 'ai', 'began', 'used', 'logistics', 'data', 'mining', 'medical', 'diagnosis', 'areas', 'success', 'due', 'increasing', 'computational', 'power', 'see', 'moore', 'law', 'transistor', 'count', 'greater', 'emphasis', 'solving', 'specific', 'problems', 'new', 'ties', 'ai', 'fields', 'statistics', 'economics', 'mathematics', 'commitment', 'researchers', 'mathematical', 'methods', 'scientific', 'standards', 'deep', 'blue', 'became', 'first', 'computer', 'chess', 'playing', 'system', 'beat', 'reigning', 'world', 'chess', 'champion', 'garry', 'kasparov', 'may', 'jeopardy', 'quiz', 'show', 'exhibition', 'match', 'ibm', 'question', 'answering', 'system', 'watson', 'defeated', 'two', 'greatest', 'jeopardy', 'champions', 'brad', 'rutter', 'ken', 'jennings', 'significant', 'margin', 'faster', 'computers', 'algorithmic', 'improvements', 'access', 'large', 'amounts', 'data', 'enabled', 'advances', 'machine', 'learning', 'perception', 'data', 'hungry', 'deep', 'learning', 'methods', 'started', 'dominate', 'accuracy', 'benchmarks', 'around', 'kinect', 'provides', 'body', 'motion', 'interface', 'xbox', 'xbox', 'one', 'uses', 'algorithms', 'emerged', 'lengthy', 'ai', 'research', 'intelligent', 'personal', 'assistants', 'smartphones', 'march', 'alphago', 'games', 'go', 'match', 'go', 'champion', 'lee', 'sedol', 'becoming', 'first', 'computer', 'go', 'playing', 'system', 'beat', 'professional', 'go', 'player', 'without', 'handicaps', 'future', 'go', 'summit', 'alphago', 'three', 'game', 'match', 'ke', 'jie', 'time', 'continuously', 'held', 'world', 'ranking', 'two', 'years', 'marked', 'completion', 'significant', 'milestone', 'development', 'artificial', 'intelligence', 'go', 'relatively', 'complex', 'game', 'chess', 'according', 'bloomberg', 'jack', 'clark', 'landmark', 'year', 'artificial', 'intelligence', 'number', 'software', 'projects', 'use', 'ai', 'google', 'increased', 'sporadic', 'usage', 'projects', 'clark', 'also', 'presents', 'factual', 'data', 'indicating', 'improvements', 'ai', 'since', 'supported', 'lower', 'error', 'rates', 'image', 'processing', 'tasks', 'attributes', 'increase', 'affordable', 'neural', 'networks', 'due', 'rise', 'cloud', 'computing', 'infrastructure', 'increase', 'research', 'tools', 'datasets', 'cited', 'examples', 'include', 'microsoft', 'development', 'skype', 'system', 'automatically', 'translate', 'one', 'language', 'another', 'facebook', 'system', 'describe', 'images', 'blind', 'people', 'survey', 'one', 'five', 'companies', 'reported', 'incorporated', 'ai', 'offerings', 'processes', 'around', 'china', 'greatly', 'accelerated', 'government', 'funding', 'given', 'large', 'supply', 'data', 'rapidly', 'increasing', 'research', 'output', 'observers', 'believe', 'may', 'track', 'becoming', 'ai', 'superpower', 'however', 'acknowledged', 'reports', 'regarding', 'artificial', 'intelligence', 'tended', 'exaggerated', 'computer', 'science', 'defines', 'ai', 'research', 'study', 'intelligent', 'agents', 'device', 'perceives', 'environment', 'takes', 'actions', 'maximize', 'chance', 'successfully', 'achieving', 'goals', 'elaborate', 'definition', 'characterizes', 'ai', 'system', 'ability', 'correctly', 'interpret', 'external', 'data', 'learn', 'data', 'use', 'learnings', 'achieve', 'specific', 'goals', 'tasks', 'flexible', 'adaptation', 'typical', 'ai', 'analyzes', 'environment', 'takes', 'actions', 'maximize', 'chance', 'success', 'ai', 'intended', 'utility', 'function', 'goal', 'simple', 'ai', 'wins', 'game', 'go', 'otherwise', 'complex', 'mathematically', 'similar', 'actions', 'ones', 'succeeded', 'past', 'goals', 'explicitly', 'defined', 'induced', 'ai', 'programmed', 'reinforcement', 'learning', 'goals', 'implicitly', 'induced', 'rewarding', 'types', 'behavior', 'punishing', 'others', 'alternatively', 'evolutionary', 'system', 'induce', 'goals', 'using', 'fitness', 'function', 'mutate', 'preferentially', 'replicate', 'high', 'scoring', 'ai', 'systems', 'similar', 'animals', 'evolved', 'innately', 'desire', 'certain', 'goals', 'finding', 'food', 'ai', 'systems', 'nearest', 'neighbor', 'instead', 'reason', 'analogy', 'systems', 'generally', 'given', 'goals', 'except', 'degree', 'goals', 'implicit', 'training', 'data', 'systems', 'still', 'benchmarked', 'non', 'goal', 'system', 'framed', 'system', 'whose', 'goal', 'successfully', 'accomplish', 'narrow', 'classification', 'task', 'ai', 'often', 'revolves', 'around', 'use', 'algorithms', 'algorithm', 'set', 'unambiguous', 'instructions', 'mechanical', 'computer', 'execute', 'b', 'complex', 'algorithm', 'often', 'built', 'top', 'simpler', 'algorithms', 'simple', 'example', 'algorithm', 'following', 'optimal', 'first', 'player', 'recipe', 'play', 'tic', 'tac', 'toe', 'many', 'ai', 'algorithms', 'capable', 'learning', 'data', 'enhance', 'learning', 'new', 'heuristics', 'strategies', 'rules', 'thumb', 'worked', 'well', 'past', 'write', 'algorithms', 'learners', 'described', 'including', 'bayesian', 'networks', 'decision', 'trees', 'nearest', 'neighbor', 'could', 'theoretically', 'given', 'infinite', 'data', 'time', 'memory', 'learn', 'approximate', 'function', 'including', 'combination', 'mathematical', 'functions', 'would', 'best', 'describe', 'world', 'citation', 'needed', 'learners', 'could', 'therefore', 'derive', 'possible', 'knowledge', 'considering', 'every', 'possible', 'hypothesis', 'matching', 'data', 'practice', 'almost', 'never', 'possible', 'consider', 'every', 'possibility', 'phenomenon', 'combinatorial', 'explosion', 'amount', 'time', 'needed', 'solve', 'problem', 'grows', 'exponentially', 'much', 'ai', 'research', 'involves', 'figuring', 'identify', 'avoid', 'considering', 'broad', 'range', 'possibilities', 'unlikely', 'beneficial', 'example', 'viewing', 'map', 'looking', 'shortest', 'driving', 'route', 'denver', 'new', 'york', 'east', 'one', 'cases', 'skip', 'looking', 'path', 'san', 'francisco', 'areas', 'far', 'west', 'thus', 'ai', 'wielding', 'pathfinding', 'algorithm', 'like', 'avoid', 'combinatorial', 'explosion', 'would', 'ensue', 'every', 'possible', 'route', 'ponderously', 'considered', 'turn', 'earliest', 'easiest', 'understand', 'approach', 'ai', 'symbolism', 'formal', 'logic', 'otherwise', 'healthy', 'adult', 'fever', 'may', 'influenza', 'second', 'general', 'approach', 'bayesian', 'inference', 'current', 'patient', 'fever', 'adjust', 'probability', 'influenza', 'way', 'third', 'major', 'approach', 'extremely', 'popular', 'routine', 'business', 'ai', 'applications', 'analogizers', 'svm', 'nearest', 'neighbor', 'examining', 'records', 'known', 'past', 'patients', 'whose', 'temperature', 'symptoms', 'age', 'factors', 'mostly', 'match', 'current', 'patient', 'x', 'patients', 'turned', 'influenza', 'fourth', 'approach', 'harder', 'intuitively', 'understand', 'inspired', 'brain', 'machinery', 'works', 'artificial', 'neural', 'network', 'approach', 'uses', 'artificial', 'neurons', 'learn', 'comparing', 'desired', 'output', 'altering', 'strengths', 'connections', 'internal', 'neurons', 'reinforce', 'connections', 'seemed', 'useful', 'four', 'main', 'approaches', 'overlap', 'evolutionary', 'systems', 'example', 'neural', 'nets', 'learn', 'make', 'inferences', 'generalize', 'make', 'analogies', 'systems', 'implicitly', 'explicitly', 'use', 'multiple', 'approaches', 'alongside', 'many', 'ai', 'non', 'ai', 'algorithms', 'best', 'approach', 'often', 'different', 'depending', 'problem', 'learning', 'algorithms', 'work', 'basis', 'strategies', 'algorithms', 'inferences', 'worked', 'well', 'past', 'likely', 'continue', 'working', 'well', 'future', 'inferences', 'obvious', 'since', 'sun', 'rose', 'every', 'morning', 'last', 'days', 'probably', 'rise', 'tomorrow', 'morning', 'well', 'nuanced', 'x', 'families', 'geographically', 'separate', 'species', 'color', 'variants', 'chance', 'undiscovered', 'black', 'swans', 'exist', 'learners', 'also', 'work', 'basis', 'occam', 'razor', 'simplest', 'theory', 'explains', 'data', 'likeliest', 'therefore', 'according', 'occam', 'razor', 'principle', 'learner', 'must', 'designed', 'prefers', 'simpler', 'theories', 'complex', 'theories', 'except', 'cases', 'complex', 'theory', 'proven', 'substantially', 'better', 'settling', 'bad', 'overly', 'complex', 'theory', 'gerrymandered', 'fit', 'past', 'training', 'data', 'known', 'overfitting', 'many', 'systems', 'attempt', 'reduce', 'overfitting', 'rewarding', 'theory', 'accordance', 'well', 'fits', 'data', 'penalizing', 'theory', 'accordance', 'complex', 'theory', 'besides', 'classic', 'overfitting', 'learners', 'also', 'disappoint', 'learning', 'wrong', 'lesson', 'toy', 'example', 'image', 'classifier', 'trained', 'pictures', 'brown', 'horses', 'black', 'cats', 'might', 'conclude', 'brown', 'patches', 'likely', 'horses', 'real', 'world', 'example', 'unlike', 'humans', 'current', 'image', 'classifiers', 'determine', 'spatial', 'relationship', 'components', 'picture', 'instead', 'learn', 'abstract', 'patterns', 'pixels', 'humans', 'oblivious', 'linearly', 'correlate', 'images', 'certain', 'types', 'real', 'objects', 'faintly', 'superimposing', 'pattern', 'legitimate', 'image', 'results', 'adversarial', 'image', 'system', 'misclassifies', 'c', 'compared', 'humans', 'existing', 'ai', 'lacks', 'several', 'features', 'human', 'commonsense', 'reasoning', 'notably', 'humans', 'powerful', 'mechanisms', 'reasoning', 'na', 'physics', 'space', 'time', 'physical', 'interactions', 'enables', 'even', 'young', 'children', 'easily', 'make', 'inferences', 'like', 'roll', 'pen', 'table', 'fall', 'floor', 'humans', 'also', 'powerful', 'mechanism', 'folk', 'psychology', 'helps', 'interpret', 'natural', 'language', 'sentences', 'city', 'councilmen', 'refused', 'demonstrators', 'permit', 'advocated', 'violence', 'generic', 'ai', 'difficulty', 'discerning', 'whether', 'ones', 'alleged', 'advocating', 'violence', 'councilmen', 'demonstrators', 'lack', 'common', 'knowledge', 'means', 'ai', 'often', 'makes', 'different', 'mistakes', 'humans', 'make', 'ways', 'seem', 'incomprehensible', 'example', 'existing', 'self', 'driving', 'cars', 'reason', 'location', 'intentions', 'pedestrians', 'exact', 'way', 'humans', 'instead', 'must', 'use', 'non', 'human', 'modes', 'reasoning', 'avoid', 'accidents', 'cognitive', 'capabilities', 'current', 'architectures', 'limited', 'using', 'simplified', 'version', 'intelligence', 'really', 'capable', 'instance', 'human', 'mind', 'come', 'ways', 'reason', 'beyond', 'measure', 'logical', 'explanations', 'different', 'occurrences', 'life', 'would', 'otherwise', 'straightforward', 'equivalently', 'difficult', 'problem', 'may', 'challenging', 'solve', 'computationally', 'opposed', 'using', 'human', 'mind', 'gives', 'rise', 'two', 'classes', 'models', 'structuralist', 'functionalist', 'structural', 'models', 'aim', 'loosely', 'mimic', 'basic', 'intelligence', 'operations', 'mind', 'reasoning', 'logic', 'functional', 'model', 'refers', 'correlating', 'data', 'computed', 'counterpart', 'overall', 'research', 'goal', 'artificial', 'intelligence', 'create', 'technology', 'allows', 'computers', 'machines', 'function', 'intelligent', 'manner', 'general', 'problem', 'simulating', 'creating', 'intelligence', 'broken', 'sub', 'problems', 'consist', 'particular', 'traits', 'capabilities', 'researchers', 'expect', 'intelligent', 'system', 'display', 'traits', 'described', 'received', 'attention', 'early', 'researchers', 'developed', 'algorithms', 'imitated', 'step', 'step', 'reasoning', 'humans', 'use', 'solve', 'puzzles', 'make', 'logical', 'deductions', 'late', 'ai', 'research', 'developed', 'methods', 'dealing', 'uncertain', 'incomplete', 'information', 'employing', 'concepts', 'probability', 'economics', 'algorithms', 'proved', 'insufficient', 'solving', 'large', 'reasoning', 'problems', 'experienced', 'combinatorial', 'explosion', 'became', 'exponentially', 'slower', 'problems', 'grew', 'larger', 'fact', 'even', 'humans', 'rarely', 'use', 'step', 'step', 'deduction', 'early', 'ai', 'research', 'able', 'model', 'solve', 'problems', 'using', 'fast', 'intuitive', 'judgments', 'knowledge', 'representation', 'knowledge', 'engineering', 'central', 'classical', 'ai', 'research', 'expert', 'systems', 'attempt', 'gather', 'together', 'explicit', 'knowledge', 'possessed', 'experts', 'narrow', 'domain', 'addition', 'projects', 'attempt', 'gather', 'commonsense', 'knowledge', 'known', 'average', 'person', 'database', 'containing', 'extensive', 'knowledge', 'world', 'among', 'things', 'comprehensive', 'commonsense', 'knowledge', 'base', 'would', 'contain', 'objects', 'properties', 'categories', 'relations', 'objects', 'situations', 'events', 'states', 'time', 'causes', 'effects', 'knowledge', 'knowledge', 'know', 'people', 'know', 'many', 'less', 'well', 'researched', 'domains', 'representation', 'exists', 'ontology', 'set', 'objects', 'relations', 'concepts', 'properties', 'formally', 'described', 'software', 'agents', 'interpret', 'semantics', 'captured', 'description', 'logic', 'concepts', 'roles', 'individuals', 'typically', 'implemented', 'classes', 'properties', 'individuals', 'web', 'ontology', 'language', 'general', 'ontologies', 'called', 'upper', 'ontologies', 'attempt', 'provide', 'foundation', 'knowledge', 'acting', 'mediators', 'domain', 'ontologies', 'cover', 'specific', 'knowledge', 'particular', 'knowledge', 'domain', 'field', 'interest', 'area', 'concern', 'formal', 'knowledge', 'representations', 'used', 'content', 'based', 'indexing', 'retrieval', 'scene', 'interpretation', 'clinical', 'decision', 'support', 'knowledge', 'discovery', 'mining', 'interesting', 'actionable', 'inferences', 'large', 'databases', 'areas', 'among', 'difficult', 'problems', 'knowledge', 'representation', 'intelligent', 'agents', 'must', 'able', 'set', 'goals', 'achieve', 'need', 'way', 'visualize', 'future', 'representation', 'state', 'world', 'able', 'make', 'predictions', 'actions', 'change', 'able', 'make', 'choices', 'maximize', 'utility', 'value', 'available', 'choices', 'classical', 'planning', 'problems', 'agent', 'assume', 'system', 'acting', 'world', 'allowing', 'agent', 'certain', 'consequences', 'actions', 'however', 'agent', 'actor', 'requires', 'agent', 'reason', 'uncertainty', 'calls', 'agent', 'assess', 'environment', 'make', 'predictions', 'also', 'evaluate', 'predictions', 'adapt', 'based', 'assessment', 'multi', 'agent', 'planning', 'uses', 'cooperation', 'competition', 'many', 'agents', 'achieve', 'given', 'goal', 'emergent', 'behavior', 'used', 'evolutionary', 'algorithms', 'swarm', 'intelligence', 'machine', 'learning', 'ml', 'fundamental', 'concept', 'ai', 'research', 'since', 'field', 'inception', 'study', 'computer', 'algorithms', 'improve', 'automatically', 'experience', 'unsupervised', 'learning', 'ability', 'find', 'patterns', 'stream', 'input', 'without', 'requiring', 'human', 'label', 'inputs', 'first', 'supervised', 'learning', 'includes', 'classification', 'numerical', 'regression', 'requires', 'human', 'label', 'input', 'data', 'first', 'classification', 'used', 'determine', 'category', 'something', 'belongs', 'occurs', 'program', 'sees', 'number', 'examples', 'things', 'several', 'categories', 'regression', 'attempt', 'produce', 'function', 'describes', 'relationship', 'inputs', 'outputs', 'predicts', 'outputs', 'change', 'inputs', 'change', 'classifiers', 'regression', 'learners', 'viewed', 'function', 'approximators', 'trying', 'learn', 'unknown', 'possibly', 'implicit', 'function', 'example', 'spam', 'classifier', 'viewed', 'learning', 'function', 'maps', 'text', 'email', 'one', 'two', 'categories', 'spam', 'spam', 'computational', 'learning', 'theory', 'assess', 'learners', 'computational', 'complexity', 'sample', 'complexity', 'much', 'data', 'required', 'notions', 'optimization', 'reinforcement', 'learning', 'agent', 'rewarded', 'good', 'responses', 'punished', 'bad', 'ones', 'agent', 'uses', 'sequence', 'rewards', 'punishments', 'form', 'strategy', 'operating', 'problem', 'space', 'natural', 'language', 'processing', 'nlp', 'gives', 'machines', 'ability', 'read', 'understand', 'human', 'language', 'sufficiently', 'powerful', 'natural', 'language', 'processing', 'system', 'would', 'enable', 'natural', 'language', 'user', 'interfaces', 'acquisition', 'knowledge', 'directly', 'human', 'written', 'sources', 'newswire', 'texts', 'straightforward', 'applications', 'natural', 'language', 'processing', 'include', 'information', 'retrieval', 'text', 'mining', 'question', 'answering', 'machine', 'translation', 'many', 'current', 'approaches', 'use', 'word', 'co', 'occurrence', 'frequencies', 'construct', 'syntactic', 'representations', 'text', 'keyword', 'spotting', 'strategies', 'search', 'popular', 'scalable', 'dumb', 'search', 'query', 'dog', 'might', 'match', 'documents', 'literal', 'word', 'dog', 'miss', 'document', 'word', 'poodle', 'lexical', 'affinity', 'strategies', 'use', 'occurrence', 'words', 'accident', 'assess', 'sentiment', 'document', 'modern', 'statistical', 'nlp', 'approaches', 'combine', 'strategies', 'well', 'others', 'often', 'achieve', 'acceptable', 'accuracy', 'page', 'paragraph', 'level', 'continue', 'lack', 'semantic', 'understanding', 'required', 'classify', 'isolated', 'sentences', 'well', 'besides', 'usual', 'difficulties', 'encoding', 'semantic', 'commonsense', 'knowledge', 'existing', 'semantic', 'nlp', 'sometimes', 'scales', 'poorly', 'viable', 'business', 'applications', 'beyond', 'semantic', 'nlp', 'ultimate', 'goal', 'narrative', 'nlp', 'embody', 'full', 'understanding', 'commonsense', 'reasoning', 'machine', 'perception', 'ability', 'use', 'input', 'sensors', 'cameras', 'visible', 'spectrum', 'infrared', 'microphones', 'wireless', 'signals', 'active', 'lidar', 'sonar', 'radar', 'tactile', 'sensors', 'deduce', 'aspects', 'world', 'applications', 'include', 'speech', 'recognition', 'facial', 'recognition', 'object', 'recognition', 'computer', 'vision', 'ability', 'analyze', 'visual', 'input', 'input', 'usually', 'ambiguous', 'giant', 'fifty', 'meter', 'tall', 'pedestrian', 'far', 'away', 'may', 'produce', 'exactly', 'pixels', 'nearby', 'normal', 'sized', 'pedestrian', 'requiring', 'ai', 'judge', 'relative', 'likelihood', 'reasonableness', 'different', 'interpretations', 'example', 'using', 'object', 'model', 'assess', 'fifty', 'meter', 'pedestrians', 'exist', 'ai', 'heavily', 'used', 'robotics', 'advanced', 'robotic', 'arms', 'industrial', 'robots', 'widely', 'used', 'modern', 'factories', 'learn', 'experience', 'move', 'efficiently', 'despite', 'presence', 'friction', 'gear', 'slippage', 'modern', 'mobile', 'robot', 'given', 'small', 'static', 'visible', 'environment', 'easily', 'determine', 'location', 'map', 'environment', 'however', 'dynamic', 'environments', 'endoscopy', 'interior', 'patient', 'breathing', 'body', 'pose', 'greater', 'challenge', 'motion', 'planning', 'process', 'breaking', 'movement', 'task', 'primitives', 'individual', 'joint', 'movements', 'movement', 'often', 'involves', 'compliant', 'motion', 'process', 'movement', 'requires', 'maintaining', 'physical', 'contact', 'object', 'moravec', 'paradox', 'generalizes', 'low', 'level', 'sensorimotor', 'skills', 'humans', 'take', 'granted', 'counterintuitively', 'difficult', 'program', 'robot', 'paradox', 'named', 'hans', 'moravec', 'stated', 'comparatively', 'easy', 'make', 'computers', 'exhibit', 'adult', 'level', 'performance', 'intelligence', 'tests', 'playing', 'checkers', 'difficult', 'impossible', 'give', 'skills', 'one', 'year', 'old', 'comes', 'perception', 'mobility', 'attributed', 'fact', 'unlike', 'checkers', 'physical', 'dexterity', 'direct', 'target', 'natural', 'selection', 'millions', 'years', 'moravec', 'paradox', 'extended', 'many', 'forms', 'social', 'intelligence', 'distributed', 'multi', 'agent', 'coordination', 'autonomous', 'vehicles', 'remains', 'difficult', 'problem', 'affective', 'computing', 'interdisciplinary', 'umbrella', 'comprises', 'systems', 'recognize', 'interpret', 'process', 'simulate', 'human', 'affects', 'moderate', 'successes', 'related', 'affective', 'computing', 'include', 'textual', 'sentiment', 'analysis', 'recently', 'multimodal', 'affect', 'analysis', 'see', 'multimodal', 'sentiment', 'analysis', 'wherein', 'ai', 'classifies', 'affects', 'displayed', 'videotaped', 'subject', 'long', 'run', 'social', 'skills', 'understanding', 'human', 'emotion', 'game', 'theory', 'would', 'valuable', 'social', 'agent', 'able', 'predict', 'actions', 'others', 'understanding', 'motives', 'emotional', 'states', 'would', 'allow', 'agent', 'make', 'better', 'decisions', 'computer', 'systems', 'mimic', 'human', 'emotion', 'expressions', 'appear', 'sensitive', 'emotional', 'dynamics', 'human', 'interaction', 'otherwise', 'facilitate', 'human', 'computer', 'interaction', 'similarly', 'virtual', 'assistants', 'programmed', 'speak', 'conversationally', 'even', 'banter', 'humorously', 'tends', 'give', 'na', 'users', 'unrealistic', 'conception', 'intelligent', 'existing', 'computer', 'agents', 'actually', 'historically', 'projects', 'cyc', 'knowledge', 'base', 'massive', 'japanese', 'fifth', 'generation', 'computer', 'systems', 'initiative', 'attempted', 'cover', 'breadth', 'human', 'cognition', 'early', 'projects', 'failed', 'escape', 'limitations', 'non', 'quantitative', 'symbolic', 'logic', 'models', 'retrospect', 'greatly', 'underestimated', 'difficulty', 'cross', 'domain', 'ai', 'nowadays', 'vast', 'majority', 'current', 'ai', 'researchers', 'work', 'instead', 'tractable', 'narrow', 'ai', 'applications', 'medical', 'diagnosis', 'automobile', 'navigation', 'many', 'researchers', 'predict', 'narrow', 'ai', 'work', 'different', 'individual', 'domains', 'eventually', 'incorporated', 'machine', 'artificial', 'general', 'intelligence', 'agi', 'combining', 'narrow', 'skills', 'mentioned', 'article', 'point', 'even', 'exceeding', 'human', 'ability', 'areas', 'many', 'advances', 'general', 'cross', 'domain', 'significance', 'one', 'high', 'profile', 'example', 'deepmind', 'developed', 'generalized', 'artificial', 'intelligence', 'could', 'learn', 'many', 'diverse', 'atari', 'games', 'later', 'developed', 'variant', 'system', 'succeeds', 'sequential', 'learning', 'besides', 'transfer', 'learning', 'hypothetical', 'agi', 'breakthroughs', 'could', 'include', 'development', 'reflective', 'architectures', 'engage', 'decision', 'theoretic', 'metareasoning', 'figuring', 'slurp', 'comprehensive', 'knowledge', 'base', 'entire', 'unstructured', 'web', 'argue', 'kind', 'currently', 'undiscovered', 'conceptually', 'straightforward', 'mathematically', 'difficult', 'master', 'algorithm', 'could', 'lead', 'agi', 'finally', 'emergent', 'approaches', 'look', 'simulating', 'human', 'intelligence', 'extremely', 'closely', 'believe', 'anthropomorphic', 'features', 'like', 'artificial', 'brain', 'simulated', 'child', 'development', 'may', 'someday', 'reach', 'critical', 'point', 'general', 'intelligence', 'emerges', 'many', 'problems', 'article', 'may', 'also', 'require', 'general', 'intelligence', 'machines', 'solve', 'problems', 'well', 'people', 'example', 'even', 'specific', 'straightforward', 'tasks', 'like', 'machine', 'translation', 'require', 'machine', 'read', 'write', 'languages', 'nlp', 'follow', 'author', 'argument', 'reason', 'know', 'talked', 'knowledge', 'faithfully', 'reproduce', 'author', 'original', 'intent', 'social', 'intelligence', 'problem', 'like', 'machine', 'translation', 'considered', 'ai', 'complete', 'problems', 'need', 'solved', 'simultaneously', 'order', 'reach', 'human', 'level', 'machine', 'performance', 'established', 'unifying', 'theory', 'paradigm', 'guides', 'ai', 'research', 'researchers', 'disagree', 'many', 'issues', 'long', 'standing', 'questions', 'remained', 'unanswered', 'artificial', 'intelligence', 'simulate', 'natural', 'intelligence', 'studying', 'psychology', 'neurobiology', 'human', 'biology', 'irrelevant', 'ai', 'research', 'bird', 'biology', 'aeronautical', 'engineering', 'intelligent', 'behavior', 'described', 'using', 'simple', 'elegant', 'principles', 'logic', 'optimization', 'necessarily', 'require', 'solving', 'large', 'number', 'completely', 'unrelated', 'problems', 'number', 'researchers', 'explored', 'connection', 'neurobiology', 'information', 'theory', 'cybernetics', 'built', 'machines', 'used', 'electronic', 'networks', 'exhibit', 'rudimentary', 'intelligence', 'w', 'grey', 'walter', 'turtles', 'johns', 'hopkins', 'beast', 'many', 'researchers', 'gathered', 'meetings', 'teleological', 'society', 'princeton', 'university', 'ratio', 'club', 'england', 'approach', 'largely', 'abandoned', 'although', 'elements', 'would', 'revived', 'access', 'digital', 'computers', 'became', 'possible', 'mid', 'ai', 'research', 'began', 'explore', 'possibility', 'human', 'intelligence', 'could', 'reduced', 'symbol', 'manipulation', 'research', 'centered', 'three', 'institutions', 'carnegie', 'mellon', 'university', 'stanford', 'mit', 'described', 'one', 'developed', 'style', 'research', 'john', 'haugeland', 'named', 'symbolic', 'approaches', 'ai', 'good', 'old', 'fashioned', 'ai', 'gofai', 'symbolic', 'approaches', 'achieved', 'great', 'success', 'simulating', 'high', 'level', 'thinking', 'small', 'demonstration', 'programs', 'approaches', 'based', 'cybernetics', 'artificial', 'neural', 'networks', 'abandoned', 'pushed', 'background', 'researchers', 'convinced', 'symbolic', 'approaches', 'would', 'eventually', 'succeed', 'creating', 'machine', 'artificial', 'general', 'intelligence', 'considered', 'goal', 'field', 'economist', 'herbert', 'simon', 'allen', 'newell', 'studied', 'human', 'problem', 'solving', 'skills', 'attempted', 'formalize', 'work', 'laid', 'foundations', 'field', 'artificial', 'intelligence', 'well', 'cognitive', 'science', 'operations', 'research', 'management', 'science', 'research', 'team', 'used', 'results', 'psychological', 'experiments', 'develop', 'programs', 'simulated', 'techniques', 'people', 'used', 'solve', 'problems', 'tradition', 'centered', 'carnegie', 'mellon', 'university', 'would', 'eventually', 'culminate', 'development', 'soar', 'architecture', 'middle', 'unlike', 'simon', 'newell', 'john', 'mccarthy', 'felt', 'machines', 'need', 'simulate', 'human', 'thought', 'instead', 'try', 'find', 'essence', 'abstract', 'reasoning', 'problem', 'solving', 'regardless', 'whether', 'people', 'used', 'algorithms', 'laboratory', 'stanford', 'sail', 'focused', 'using', 'formal', 'logic', 'solve', 'wide', 'variety', 'problems', 'including', 'knowledge', 'representation', 'planning', 'learning', 'logic', 'also', 'focus', 'work', 'university', 'edinburgh', 'elsewhere', 'europe', 'led', 'development', 'programming', 'language', 'prolog', 'science', 'logic', 'programming', 'researchers', 'mit', 'marvin', 'minsky', 'seymour', 'papert', 'found', 'solving', 'difficult', 'problems', 'vision', 'natural', 'language', 'processing', 'required', 'ad', 'hoc', 'solutions', 'argued', 'simple', 'general', 'principle', 'like', 'logic', 'would', 'capture', 'aspects', 'intelligent', 'behavior', 'roger', 'schank', 'described', 'anti', 'logic', 'approaches', 'scruffy', 'opposed', 'neat', 'paradigms', 'cmu', 'stanford', 'commonsense', 'knowledge', 'bases', 'doug', 'lenat', 'cyc', 'example', 'scruffy', 'ai', 'since', 'must', 'built', 'hand', 'one', 'complicated', 'concept', 'time', 'computers', 'large', 'memories', 'became', 'available', 'around', 'researchers', 'three', 'traditions', 'began', 'build', 'knowledge', 'ai', 'applications', 'knowledge', 'revolution', 'led', 'development', 'deployment', 'expert', 'systems', 'introduced', 'edward', 'feigenbaum', 'first', 'truly', 'successful', 'form', 'ai', 'software', 'key', 'component', 'system', 'architecture', 'expert', 'systems', 'knowledge', 'base', 'stores', 'facts', 'rules', 'illustrate', 'ai', 'knowledge', 'revolution', 'also', 'driven', 'realization', 'enormous', 'amounts', 'knowledge', 'would', 'required', 'many', 'simple', 'ai', 'applications', 'progress', 'symbolic', 'ai', 'seemed', 'stall', 'many', 'believed', 'symbolic', 'systems', 'would', 'never', 'able', 'imitate', 'processes', 'human', 'cognition', 'especially', 'perception', 'robotics', 'learning', 'pattern', 'recognition', 'number', 'researchers', 'began', 'look', 'sub', 'symbolic', 'approaches', 'specific', 'ai', 'problems', 'sub', 'symbolic', 'methods', 'manage', 'approach', 'intelligence', 'without', 'specific', 'representations', 'knowledge', 'includes', 'embodied', 'situated', 'behavior', 'based', 'nouvelle', 'ai', 'researchers', 'related', 'field', 'robotics', 'rodney', 'brooks', 'rejected', 'symbolic', 'ai', 'focused', 'basic', 'engineering', 'problems', 'would', 'allow', 'robots', 'move', 'survive', 'work', 'revived', 'non', 'symbolic', 'point', 'view', 'early', 'cybernetics', 'researchers', 'reintroduced', 'use', 'control', 'theory', 'ai', 'coincided', 'development', 'embodied', 'mind', 'thesis', 'related', 'field', 'cognitive', 'science', 'idea', 'aspects', 'body', 'movement', 'perception', 'visualization', 'required', 'higher', 'intelligence', 'within', 'developmental', 'robotics', 'developmental', 'learning', 'approaches', 'elaborated', 'upon', 'allow', 'robots', 'accumulate', 'repertoires', 'novel', 'skills', 'autonomous', 'self', 'exploration', 'social', 'interaction', 'human', 'teachers', 'use', 'guidance', 'mechanisms', 'active', 'learning', 'maturation', 'motor', 'synergies', 'etc', 'interest', 'neural', 'networks', 'connectionism', 'revived', 'david', 'rumelhart', 'others', 'middle', 'artificial', 'neural', 'networks', 'example', 'soft', 'computing', 'solutions', 'problems', 'solved', 'complete', 'logical', 'certainty', 'approximate', 'solution', 'often', 'sufficient', 'soft', 'computing', 'approaches', 'ai', 'include', 'fuzzy', 'systems', 'grey', 'system', 'theory', 'evolutionary', 'computation', 'many', 'statistical', 'tools', 'application', 'soft', 'computing', 'ai', 'studied', 'collectively', 'emerging', 'discipline', 'computational', 'intelligence', 'much', 'traditional', 'gofai', 'got', 'bogged', 'ad', 'hoc', 'patches', 'symbolic', 'computation', 'worked', 'toy', 'models', 'failed', 'generalize', 'real', 'world', 'results', 'however', 'around', 'ai', 'researchers', 'adopted', 'sophisticated', 'mathematical', 'tools', 'hidden', 'markov', 'models', 'hmm', 'information', 'theory', 'normative', 'bayesian', 'decision', 'theory', 'compare', 'unify', 'competing', 'architectures', 'shared', 'mathematical', 'language', 'permitted', 'high', 'level', 'collaboration', 'established', 'fields', 'like', 'mathematics', 'economics', 'operations', 'research', 'compared', 'gofai', 'new', 'statistical', 'learning', 'techniques', 'hmm', 'neural', 'networks', 'gaining', 'higher', 'levels', 'accuracy', 'many', 'practical', 'domains', 'data', 'mining', 'without', 'necessarily', 'acquiring', 'semantic', 'understanding', 'datasets', 'increased', 'successes', 'real', 'world', 'data', 'led', 'increasing', 'emphasis', 'comparing', 'different', 'approaches', 'shared', 'test', 'data', 'see', 'approach', 'performed', 'best', 'broader', 'context', 'provided', 'idiosyncratic', 'toy', 'models', 'ai', 'research', 'becoming', 'scientific', 'nowadays', 'results', 'experiments', 'often', 'rigorously', 'measurable', 'sometimes', 'difficulty', 'reproducible', 'different', 'statistical', 'learning', 'techniques', 'different', 'limitations', 'example', 'basic', 'hmm', 'model', 'infinite', 'possible', 'combinations', 'natural', 'language', 'critics', 'note', 'shift', 'gofai', 'statistical', 'learning', 'often', 'also', 'shift', 'away', 'explainable', 'ai', 'agi', 'research', 'scholars', 'caution', 'reliance', 'statistical', 'learning', 'argue', 'continuing', 'research', 'gofai', 'still', 'necessary', 'attain', 'general', 'intelligence', 'ai', 'developed', 'many', 'tools', 'solve', 'difficult', 'problems', 'computer', 'science', 'general', 'methods', 'discussed', 'many', 'problems', 'ai', 'solved', 'theory', 'intelligently', 'searching', 'many', 'possible', 'solutions', 'reasoning', 'reduced', 'performing', 'search', 'example', 'logical', 'proof', 'viewed', 'searching', 'path', 'leads', 'premises', 'conclusions', 'step', 'application', 'inference', 'rule', 'planning', 'algorithms', 'search', 'trees', 'goals', 'subgoals', 'attempting', 'find', 'path', 'target', 'goal', 'process', 'called', 'means', 'ends', 'analysis', 'robotics', 'algorithms', 'moving', 'limbs', 'grasping', 'objects', 'use', 'local', 'searches', 'configuration', 'space', 'many', 'learning', 'algorithms', 'use', 'search', 'algorithms', 'based', 'optimization', 'simple', 'exhaustive', 'searches', 'rarely', 'sufficient', 'real', 'world', 'problems', 'search', 'space', 'number', 'places', 'search', 'quickly', 'grows', 'astronomical', 'numbers', 'result', 'search', 'slow', 'never', 'completes', 'solution', 'many', 'problems', 'use', 'heuristics', 'rules', 'thumb', 'prioritize', 'choices', 'favor', 'likely', 'reach', 'goal', 'shorter', 'number', 'steps', 'search', 'methodologies', 'heuristics', 'also', 'serve', 'entirely', 'eliminate', 'choices', 'unlikely', 'lead', 'goal', 'called', 'pruning', 'search', 'tree', 'heuristics', 'supply', 'program', 'best', 'guess', 'path', 'solution', 'lies', 'heuristics', 'limit', 'search', 'solutions', 'smaller', 'sample', 'size', 'different', 'kind', 'search', 'came', 'prominence', 'based', 'mathematical', 'theory', 'optimization', 'many', 'problems', 'possible', 'begin', 'search', 'form', 'guess', 'refine', 'guess', 'incrementally', 'refinements', 'made', 'algorithms', 'visualized', 'blind', 'hill', 'climbing', 'begin', 'search', 'random', 'point', 'landscape', 'jumps', 'steps', 'keep', 'moving', 'guess', 'uphill', 'reach', 'top', 'optimization', 'algorithms', 'simulated', 'annealing', 'beam', 'search', 'random', 'optimization', 'evolutionary', 'computation', 'uses', 'form', 'optimization', 'search', 'example', 'may', 'begin', 'population', 'organisms', 'guesses', 'allow', 'mutate', 'recombine', 'selecting', 'fittest', 'survive', 'generation', 'refining', 'guesses', 'classic', 'evolutionary', 'algorithms', 'include', 'genetic', 'algorithms', 'gene', 'expression', 'programming', 'genetic', 'programming', 'alternatively', 'distributed', 'search', 'processes', 'coordinate', 'via', 'swarm', 'intelligence', 'algorithms', 'two', 'popular', 'swarm', 'algorithms', 'used', 'search', 'particle', 'swarm', 'optimization', 'inspired', 'bird', 'flocking', 'ant', 'colony', 'optimization', 'inspired', 'ant', 'trails', 'logic', 'used', 'knowledge', 'representation', 'problem', 'solving', 'applied', 'problems', 'well', 'example', 'satplan', 'algorithm', 'uses', 'logic', 'planning', 'inductive', 'logic', 'programming', 'method', 'learning', 'several', 'different', 'forms', 'logic', 'used', 'ai', 'research', 'propositional', 'logic', 'involves', 'truth', 'functions', 'first', 'order', 'logic', 'adds', 'quantifiers', 'predicates', 'express', 'facts', 'objects', 'properties', 'relations', 'fuzzy', 'set', 'theory', 'assigns', 'degree', 'truth', 'vague', 'statements', 'alice', 'old', 'rich', 'tall', 'hungry', 'linguistically', 'imprecise', 'completely', 'true', 'false', 'fuzzy', 'logic', 'successfully', 'used', 'control', 'systems', 'allow', 'experts', 'contribute', 'vague', 'rules', 'close', 'destination', 'station', 'moving', 'fast', 'increase', 'train', 'brake', 'pressure', 'vague', 'rules', 'numerically', 'refined', 'within', 'system', 'fuzzy', 'logic', 'fails', 'scale', 'well', 'knowledge', 'bases', 'many', 'ai', 'researchers', 'question', 'validity', 'chaining', 'fuzzy', 'logic', 'inferences', 'e', 'default', 'logics', 'non', 'monotonic', 'logics', 'circumscription', 'forms', 'logic', 'designed', 'help', 'default', 'reasoning', 'qualification', 'problem', 'several', 'extensions', 'logic', 'designed', 'handle', 'specific', 'domains', 'knowledge', 'description', 'logics', 'situation', 'calculus', 'event', 'calculus', 'fluent', 'calculus', 'representing', 'events', 'time', 'causal', 'calculus', 'belief', 'calculus', 'belief', 'revision', 'modal', 'logics', 'logics', 'model', 'contradictory', 'inconsistent', 'statements', 'arising', 'multi', 'agent', 'systems', 'also', 'designed', 'paraconsistent', 'logics', 'many', 'problems', 'ai', 'reasoning', 'planning', 'learning', 'perception', 'robotics', 'require', 'agent', 'operate', 'incomplete', 'uncertain', 'information', 'ai', 'researchers', 'devised', 'number', 'powerful', 'tools', 'solve', 'problems', 'using', 'methods', 'probability', 'theory', 'economics', 'bayesian', 'networks', 'general', 'tool', 'used', 'various', 'problems', 'reasoning', 'using', 'bayesian', 'inference', 'algorithm', 'learning', 'using', 'expectation', 'maximization', 'algorithm', 'f', 'planning', 'using', 'decision', 'networks', 'perception', 'using', 'dynamic', 'bayesian', 'networks', 'probabilistic', 'algorithms', 'also', 'used', 'filtering', 'prediction', 'smoothing', 'finding', 'explanations', 'streams', 'data', 'helping', 'perception', 'systems', 'analyze', 'processes', 'occur', 'time', 'e', 'g', 'hidden', 'markov', 'models', 'kalman', 'filters', 'compared', 'symbolic', 'logic', 'formal', 'bayesian', 'inference', 'computationally', 'expensive', 'inference', 'tractable', 'observations', 'must', 'conditionally', 'independent', 'one', 'another', 'complicated', 'graphs', 'diamonds', 'loops', 'undirected', 'cycles', 'require', 'sophisticated', 'method', 'markov', 'chain', 'monte', 'carlo', 'spreads', 'ensemble', 'random', 'walkers', 'throughout', 'bayesian', 'network', 'attempts', 'converge', 'assessment', 'conditional', 'probabilities', 'bayesian', 'networks', 'used', 'xbox', 'live', 'rate', 'match', 'players', 'wins', 'losses', 'evidence', 'good', 'player', 'citation', 'needed', 'adsense', 'uses', 'bayesian', 'network', 'million', 'edges', 'learn', 'ads', 'serve', 'key', 'concept', 'science', 'economics', 'utility', 'measure', 'valuable', 'something', 'intelligent', 'agent', 'precise', 'mathematical', 'tools', 'developed', 'analyze', 'agent', 'make', 'choices', 'plan', 'using', 'decision', 'theory', 'decision', 'analysis', 'information', 'value', 'theory', 'tools', 'include', 'models', 'markov', 'decision', 'processes', 'dynamic', 'decision', 'networks', 'game', 'theory', 'mechanism', 'design', 'simplest', 'ai', 'applications', 'divided', 'two', 'types', 'classifiers', 'shiny', 'diamond', 'controllers', 'shiny', 'pick', 'controllers', 'however', 'also', 'classify', 'conditions', 'inferring', 'actions', 'therefore', 'classification', 'forms', 'central', 'part', 'many', 'ai', 'systems', 'classifiers', 'functions', 'use', 'pattern', 'matching', 'determine', 'closest', 'match', 'tuned', 'according', 'examples', 'making', 'attractive', 'use', 'ai', 'examples', 'known', 'observations', 'patterns', 'supervised', 'learning', 'pattern', 'belongs', 'certain', 'predefined', 'class', 'class', 'seen', 'decision', 'made', 'observations', 'combined', 'class', 'labels', 'known', 'data', 'set', 'new', 'observation', 'received', 'observation', 'classified', 'based', 'previous', 'experience', 'classifier', 'trained', 'various', 'ways', 'many', 'statistical', 'machine', 'learning', 'approaches', 'decision', 'tree', 'perhaps', 'widely', 'used', 'machine', 'learning', 'algorithm', 'widely', 'used', 'classifiers', 'neural', 'network', 'k', 'nearest', 'neighbor', 'algorithm', 'g', 'kernel', 'methods', 'support', 'vector', 'machine', 'svm', 'h', 'gaussian', 'mixture', 'model', 'extremely', 'popular', 'naive', 'bayes', 'classifier', 'classifier', 'performance', 'depends', 'greatly', 'characteristics', 'data', 'classified', 'dataset', 'size', 'distribution', 'samples', 'across', 'classes', 'dimensionality', 'level', 'noise', 'model', 'based', 'classifiers', 'perform', 'well', 'assumed', 'model', 'extremely', 'good', 'fit', 'actual', 'data', 'otherwise', 'matching', 'model', 'available', 'accuracy', 'rather', 'speed', 'scalability', 'sole', 'concern', 'conventional', 'wisdom', 'discriminative', 'classifiers', 'especially', 'svm', 'tend', 'accurate', 'model', 'based', 'classifiers', 'naive', 'bayes', 'practical', 'data', 'sets', 'neural', 'networks', 'inspired', 'architecture', 'neurons', 'human', 'brain', 'simple', 'neuron', 'n', 'accepts', 'input', 'neurons', 'activated', 'fired', 'cast', 'weighted', 'vote', 'whether', 'neuron', 'n', 'activate', 'learning', 'requires', 'algorithm', 'adjust', 'weights', 'based', 'training', 'data', 'one', 'simple', 'algorithm', 'dubbed', 'fire', 'together', 'wire', 'together', 'increase', 'weight', 'two', 'connected', 'neurons', 'activation', 'one', 'triggers', 'successful', 'activation', 'another', 'neural', 'network', 'forms', 'concepts', 'distributed', 'among', 'subnetwork', 'shared', 'j', 'neurons', 'tend', 'fire', 'together', 'concept', 'meaning', 'leg', 'might', 'coupled', 'subnetwork', 'meaning', 'foot', 'includes', 'sound', 'foot', 'neurons', 'continuous', 'spectrum', 'activation', 'addition', 'neurons', 'process', 'inputs', 'nonlinear', 'way', 'rather', 'weighing', 'straightforward', 'votes', 'modern', 'neural', 'networks', 'learn', 'continuous', 'functions', 'surprisingly', 'digital', 'logical', 'operations', 'neural', 'networks', 'early', 'successes', 'included', 'predicting', 'stock', 'market', 'mostly', 'self', 'driving', 'car', 'k', 'advances', 'neural', 'networks', 'using', 'deep', 'learning', 'thrust', 'ai', 'widespread', 'public', 'consciousness', 'contributed', 'enormous', 'upshift', 'corporate', 'ai', 'spending', 'example', 'ai', 'related', 'times', 'large', 'study', 'non', 'learning', 'artificial', 'neural', 'networks', 'began', 'decade', 'field', 'ai', 'research', 'founded', 'work', 'walter', 'pitts', 'warren', 'mccullouch', 'frank', 'rosenblatt', 'invented', 'perceptron', 'learning', 'network', 'single', 'layer', 'similar', 'old', 'concept', 'linear', 'regression', 'early', 'pioneers', 'also', 'include', 'alexey', 'grigorevich', 'ivakhnenko', 'teuvo', 'kohonen', 'stephen', 'grossberg', 'kunihiko', 'fukushima', 'christoph', 'von', 'der', 'malsburg', 'david', 'willshaw', 'shun', 'ichi', 'amari', 'bernard', 'widrow', 'john', 'hopfield', 'eduardo', 'r', 'caianiello', 'others', 'citation', 'needed', 'main', 'categories', 'networks', 'acyclic', 'feedforward', 'neural', 'networks', 'signal', 'passes', 'one', 'direction', 'recurrent', 'neural', 'networks', 'allow', 'feedback', 'short', 'term', 'memories', 'previous', 'input', 'events', 'among', 'popular', 'feedforward', 'networks', 'perceptrons', 'multi', 'layer', 'perceptrons', 'radial', 'basis', 'networks', 'neural', 'networks', 'applied', 'problem', 'intelligent', 'control', 'robotics', 'learning', 'using', 'techniques', 'hebbian', 'learning', 'fire', 'together', 'wire', 'together', 'gmdh', 'competitive', 'learning', 'today', 'neural', 'networks', 'often', 'trained', 'backpropagation', 'algorithm', 'around', 'since', 'reverse', 'mode', 'automatic', 'differentiation', 'published', 'seppo', 'linnainmaa', 'introduced', 'neural', 'networks', 'paul', 'werbos', 'hierarchical', 'temporal', 'memory', 'approach', 'models', 'structural', 'algorithmic', 'properties', 'neocortex', 'summarize', 'neural', 'networks', 'use', 'form', 'gradient', 'descent', 'hand', 'created', 'neural', 'topology', 'however', 'research', 'groups', 'uber', 'argue', 'simple', 'neuroevolution', 'mutate', 'new', 'neural', 'network', 'topologies', 'weights', 'may', 'competitive', 'sophisticated', 'gradient', 'descent', 'approaches', 'citation', 'needed', 'one', 'advantage', 'neuroevolution', 'may', 'less', 'prone', 'get', 'caught', 'dead', 'ends', 'deep', 'learning', 'artificial', 'neural', 'network', 'learn', 'long', 'chain', 'causal', 'links', 'dubious', 'discuss', 'example', 'feedforward', 'network', 'six', 'hidden', 'layers', 'learn', 'seven', 'link', 'causal', 'chain', 'six', 'hidden', 'layers', 'output', 'layer', 'credit', 'assignment', 'path', 'cap', 'depth', 'seven', 'citation', 'needed', 'many', 'deep', 'learning', 'systems', 'need', 'able', 'learn', 'chains', 'ten', 'causal', 'links', 'length', 'deep', 'learning', 'transformed', 'many', 'important', 'subfields', 'artificial', 'intelligence', 'including', 'computer', 'vision', 'speech', 'recognition', 'natural', 'language', 'processing', 'others', 'according', 'one', 'overview', 'expression', 'deep', 'learning', 'introduced', 'machine', 'learning', 'community', 'rina', 'dechter', 'gained', 'traction', 'igor', 'aizenberg', 'colleagues', 'introduced', 'artificial', 'neural', 'networks', 'first', 'functional', 'deep', 'learning', 'networks', 'published', 'alexey', 'grigorevich', 'ivakhnenko', 'v', 'g', 'lapa', 'page', 'needed', 'networks', 'trained', 'one', 'layer', 'time', 'ivakhnenko', 'paper', 'describes', 'learning', 'deep', 'feedforward', 'multilayer', 'perceptron', 'eight', 'layers', 'already', 'much', 'deeper', 'many', 'later', 'networks', 'publication', 'geoffrey', 'hinton', 'ruslan', 'salakhutdinov', 'introduced', 'another', 'way', 'pre', 'training', 'many', 'layered', 'feedforward', 'neural', 'networks', 'fnns', 'one', 'layer', 'time', 'treating', 'layer', 'turn', 'unsupervised', 'restricted', 'boltzmann', 'machine', 'using', 'supervised', 'backpropagation', 'fine', 'tuning', 'similar', 'shallow', 'artificial', 'neural', 'networks', 'deep', 'neural', 'networks', 'model', 'complex', 'non', 'linear', 'relationships', 'last', 'years', 'advances', 'machine', 'learning', 'algorithms', 'computer', 'hardware', 'led', 'efficient', 'methods', 'training', 'deep', 'neural', 'networks', 'contain', 'many', 'layers', 'non', 'linear', 'hidden', 'units', 'large', 'output', 'layer', 'deep', 'learning', 'often', 'uses', 'convolutional', 'neural', 'networks', 'cnns', 'whose', 'origins', 'traced', 'back', 'neocognitron', 'introduced', 'kunihiko', 'fukushima', 'yann', 'lecun', 'colleagues', 'applied', 'backpropagation', 'architecture', 'early', 'industrial', 'application', 'cnns', 'already', 'processed', 'estimated', 'checks', 'written', 'us', 'since', 'fast', 'implementations', 'cnns', 'gpus', 'many', 'visual', 'pattern', 'recognition', 'competitions', 'cnns', 'convolutional', 'layers', 'used', 'conjunction', 'reinforcement', 'learning', 'deepmind', 'alphago', 'lee', 'program', 'beat', 'top', 'go', 'champion', 'early', 'deep', 'learning', 'also', 'applied', 'sequence', 'learning', 'recurrent', 'neural', 'networks', 'rnns', 'theory', 'turing', 'complete', 'run', 'arbitrary', 'programs', 'process', 'arbitrary', 'sequences', 'inputs', 'depth', 'rnn', 'unlimited', 'depends', 'length', 'input', 'sequence', 'thus', 'rnn', 'example', 'deep', 'learning', 'rnns', 'trained', 'gradient', 'descent', 'suffer', 'vanishing', 'gradient', 'problem', 'shown', 'unsupervised', 'pre', 'training', 'stack', 'recurrent', 'neural', 'networks', 'speed', 'subsequent', 'supervised', 'learning', 'deep', 'sequential', 'problems', 'numerous', 'researchers', 'use', 'variants', 'deep', 'learning', 'recurrent', 'nn', 'called', 'long', 'short', 'term', 'memory', 'lstm', 'network', 'published', 'hochreiter', 'schmidhuber', 'lstm', 'often', 'trained', 'connectionist', 'temporal', 'classification', 'ctc', 'google', 'microsoft', 'baidu', 'approach', 'revolutionized', 'speech', 'recognition', 'example', 'google', 'speech', 'recognition', 'experienced', 'dramatic', 'performance', 'jump', 'ctc', 'trained', 'lstm', 'available', 'google', 'voice', 'billions', 'smartphone', 'users', 'google', 'also', 'used', 'lstm', 'improve', 'machine', 'translation', 'language', 'modeling', 'multilingual', 'language', 'processing', 'lstm', 'combined', 'cnns', 'also', 'improved', 'automatic', 'image', 'captioning', 'plethora', 'applications', 'ai', 'like', 'electricity', 'steam', 'engine', 'general', 'purpose', 'technology', 'consensus', 'characterize', 'tasks', 'ai', 'tends', 'excel', 'projects', 'alphazero', 'succeeded', 'generating', 'knowledge', 'scratch', 'many', 'machine', 'learning', 'projects', 'require', 'large', 'training', 'datasets', 'researcher', 'andrew', 'ng', 'suggested', 'highly', 'imperfect', 'rule', 'thumb', 'almost', 'anything', 'typical', 'human', 'less', 'one', 'second', 'mental', 'thought', 'probably', 'near', 'future', 'automate', 'using', 'ai', 'moravec', 'paradox', 'suggests', 'ai', 'lags', 'humans', 'many', 'tasks', 'human', 'brain', 'specifically', 'evolved', 'perform', 'well', 'games', 'provide', 'well', 'publicized', 'benchmark', 'assessing', 'rates', 'progress', 'alphago', 'around', 'brought', 'era', 'classical', 'board', 'game', 'benchmarks', 'close', 'games', 'imperfect', 'knowledge', 'provide', 'new', 'challenges', 'ai', 'area', 'game', 'theory', 'e', 'sports', 'starcraft', 'continue', 'provide', 'additional', 'public', 'benchmarks', 'many', 'competitions', 'prizes', 'imagenet', 'challenge', 'promote', 'research', 'artificial', 'intelligence', 'common', 'areas', 'competition', 'include', 'general', 'machine', 'intelligence', 'conversational', 'behavior', 'data', 'mining', 'robotic', 'cars', 'robot', 'soccer', 'well', 'conventional', 'games', 'imitation', 'game', 'interpretation', 'turing', 'test', 'assesses', 'whether', 'computer', 'imitate', 'human', 'nowadays', 'considered', 'exploitable', 'meaningful', 'benchmark', 'derivative', 'turing', 'test', 'completely', 'automated', 'public', 'turing', 'test', 'tell', 'computers', 'humans', 'apart', 'captcha', 'name', 'implies', 'helps', 'determine', 'user', 'actual', 'person', 'computer', 'posing', 'human', 'contrast', 'standard', 'turing', 'test', 'captcha', 'administered', 'machine', 'targeted', 'human', 'opposed', 'administered', 'human', 'targeted', 'machine', 'computer', 'asks', 'user', 'complete', 'simple', 'test', 'generates', 'grade', 'test', 'computers', 'unable', 'solve', 'problem', 'correct', 'solutions', 'deemed', 'result', 'person', 'taking', 'test', 'common', 'type', 'captcha', 'test', 'requires', 'typing', 'distorted', 'letters', 'numbers', 'symbols', 'appear', 'image', 'undecipherable', 'computer', 'proposed', 'universal', 'intelligence', 'tests', 'aim', 'compare', 'well', 'machines', 'humans', 'even', 'non', 'human', 'animals', 'perform', 'problem', 'sets', 'generic', 'possible', 'extreme', 'test', 'suite', 'contain', 'every', 'possible', 'problem', 'weighted', 'kolmogorov', 'complexity', 'unfortunately', 'problem', 'sets', 'tend', 'dominated', 'impoverished', 'pattern', 'matching', 'exercises', 'tuned', 'ai', 'easily', 'exceed', 'human', 'performance', 'levels', 'ai', 'relevant', 'intellectual', 'task', 'modern', 'artificial', 'intelligence', 'techniques', 'pervasive', 'numerous', 'list', 'frequently', 'technique', 'reaches', 'mainstream', 'use', 'longer', 'considered', 'artificial', 'intelligence', 'phenomenon', 'described', 'ai', 'effect', 'high', 'profile', 'examples', 'ai', 'include', 'autonomous', 'vehicles', 'drones', 'self', 'driving', 'cars', 'medical', 'diagnosis', 'creating', 'art', 'poetry', 'proving', 'mathematical', 'theorems', 'playing', 'games', 'chess', 'go', 'search', 'engines', 'google', 'search', 'online', 'assistants', 'siri', 'image', 'recognition', 'photographs', 'spam', 'filtering', 'predicting', 'flight', 'delays', 'prediction', 'judicial', 'decisions', 'targeting', 'online', 'advertisements', 'energy', 'storage', 'social', 'media', 'sites', 'overtaking', 'tv', 'source', 'news', 'young', 'people', 'news', 'organizations', 'increasingly', 'reliant', 'social', 'media', 'platforms', 'generating', 'distribution', 'major', 'publishers', 'use', 'artificial', 'intelligence', 'ai', 'technology', 'post', 'stories', 'effectively', 'generate', 'higher', 'volumes', 'traffic', 'ai', 'also', 'produce', 'deepfakes', 'content', 'altering', 'technology', 'zdnet', 'reports', 'presents', 'something', 'actually', 'occur', 'though', 'americans', 'believe', 'deepfakes', 'cause', 'harm', 'good', 'believe', 'targeted', 'boom', 'election', 'year', 'also', 'opens', 'public', 'discourse', 'threats', 'videos', 'falsified', 'politician', 'media', 'ai', 'healthcare', 'often', 'used', 'classification', 'whether', 'automate', 'initial', 'evaluation', 'ct', 'scan', 'ekg', 'identify', 'high', 'risk', 'patients', 'population', 'health', 'breadth', 'applications', 'rapidly', 'increasing', 'example', 'ai', 'applied', 'high', 'cost', 'problem', 'dosage', 'issues', 'findings', 'suggested', 'ai', 'could', 'save', 'billion', 'ground', 'breaking', 'study', 'california', 'found', 'mathematical', 'formula', 'developed', 'help', 'ai', 'correctly', 'determined', 'accurate', 'dose', 'immunosuppressant', 'drugs', 'give', 'organ', 'patients', 'artificial', 'intelligence', 'assisting', 'doctors', 'according', 'bloomberg', 'technology', 'microsoft', 'developed', 'ai', 'help', 'doctors', 'find', 'right', 'treatments', 'cancer', 'great', 'amount', 'research', 'drugs', 'developed', 'relating', 'cancer', 'detail', 'medicines', 'vaccines', 'treat', 'cancer', 'negatively', 'affects', 'doctors', 'many', 'options', 'choose', 'making', 'difficult', 'choose', 'right', 'drugs', 'patients', 'microsoft', 'working', 'project', 'develop', 'machine', 'called', 'hanover', 'citation', 'needed', 'goal', 'memorize', 'papers', 'necessary', 'cancer', 'help', 'predict', 'combinations', 'drugs', 'effective', 'patient', 'one', 'project', 'worked', 'moment', 'fighting', 'myeloid', 'leukemia', 'fatal', 'cancer', 'treatment', 'improved', 'decades', 'another', 'study', 'reported', 'found', 'artificial', 'intelligence', 'good', 'trained', 'doctors', 'identifying', 'skin', 'cancers', 'another', 'study', 'using', 'artificial', 'intelligence', 'try', 'monitor', 'multiple', 'high', 'risk', 'patients', 'done', 'asking', 'patient', 'numerous', 'questions', 'based', 'data', 'acquired', 'live', 'doctor', 'patient', 'interactions', 'one', 'study', 'done', 'transfer', 'learning', 'machine', 'performed', 'diagnosis', 'similarly', 'well', 'trained', 'ophthalmologist', 'could', 'generate', 'decision', 'within', 'seconds', 'whether', 'patient', 'referred', 'treatment', 'accuracy', 'according', 'cnn', 'recent', 'study', 'surgeons', 'children', 'national', 'medical', 'center', 'washington', 'successfully', 'demonstrated', 'surgery', 'autonomous', 'robot', 'team', 'supervised', 'robot', 'performed', 'soft', 'tissue', 'surgery', 'stitching', 'together', 'pig', 'bowel', 'open', 'surgery', 'better', 'human', 'surgeon', 'team', 'claimed', 'ibm', 'created', 'artificial', 'intelligence', 'computer', 'ibm', 'watson', 'beaten', 'human', 'intelligence', 'levels', 'watson', 'struggled', 'achieve', 'success', 'adoption', 'healthcare', 'advancements', 'ai', 'contributed', 'growth', 'automotive', 'industry', 'creation', 'evolution', 'self', 'driving', 'vehicles', 'update', 'companies', 'utilizing', 'ai', 'creation', 'self', 'driving', 'cars', 'companies', 'involved', 'ai', 'include', 'tesla', 'google', 'apple', 'many', 'components', 'contribute', 'functioning', 'self', 'driving', 'cars', 'vehicles', 'incorporate', 'systems', 'braking', 'lane', 'changing', 'collision', 'prevention', 'navigation', 'mapping', 'together', 'systems', 'well', 'high', 'performance', 'computers', 'integrated', 'one', 'complex', 'vehicle', 'recent', 'developments', 'autonomous', 'automobiles', 'made', 'innovation', 'self', 'driving', 'trucks', 'possible', 'though', 'still', 'testing', 'phase', 'uk', 'government', 'passed', 'legislation', 'begin', 'testing', 'self', 'driving', 'truck', 'platoons', 'self', 'driving', 'truck', 'platoons', 'fleet', 'self', 'driving', 'trucks', 'following', 'lead', 'one', 'non', 'self', 'driving', 'truck', 'truck', 'platoons', 'entirely', 'autonomous', 'yet', 'meanwhile', 'daimler', 'german', 'automobile', 'corporation', 'testing', 'freightliner', 'inspiration', 'semi', 'autonomous', 'truck', 'used', 'highway', 'one', 'main', 'factor', 'influences', 'ability', 'driver', 'less', 'automobile', 'function', 'mapping', 'general', 'vehicle', 'would', 'pre', 'programmed', 'map', 'area', 'driven', 'map', 'would', 'include', 'data', 'approximations', 'street', 'light', 'curb', 'heights', 'order', 'vehicle', 'aware', 'surroundings', 'however', 'google', 'working', 'algorithm', 'purpose', 'eliminating', 'need', 'pre', 'programmed', 'maps', 'instead', 'creating', 'device', 'would', 'able', 'adjust', 'variety', 'new', 'surroundings', 'self', 'driving', 'cars', 'equipped', 'steering', 'wheels', 'brake', 'pedals', 'also', 'research', 'focused', 'creating', 'algorithm', 'capable', 'maintaining', 'safe', 'environment', 'passengers', 'vehicle', 'awareness', 'speed', 'driving', 'conditions', 'another', 'factor', 'influencing', 'ability', 'driver', 'less', 'automobile', 'safety', 'passenger', 'make', 'driver', 'less', 'automobile', 'engineers', 'must', 'program', 'handle', 'high', 'risk', 'situations', 'situations', 'could', 'include', 'head', 'collision', 'pedestrians', 'car', 'main', 'goal', 'make', 'decision', 'would', 'avoid', 'hitting', 'pedestrians', 'saving', 'passengers', 'car', 'possibility', 'car', 'would', 'need', 'make', 'decision', 'would', 'put', 'someone', 'danger', 'words', 'car', 'would', 'need', 'decide', 'save', 'pedestrians', 'passengers', 'programming', 'car', 'situations', 'crucial', 'successful', 'driver', 'less', 'automobile', 'financial', 'institutions', 'long', 'used', 'artificial', 'neural', 'network', 'systems', 'detect', 'charges', 'claims', 'outside', 'norm', 'flagging', 'human', 'investigation', 'use', 'ai', 'banking', 'traced', 'back', 'security', 'pacific', 'national', 'bank', 'us', 'set', 'fraud', 'prevention', 'task', 'force', 'counter', 'unauthorized', 'use', 'debit', 'cards', 'programs', 'like', 'kasisto', 'moneystream', 'using', 'ai', 'financial', 'services', 'banks', 'use', 'artificial', 'intelligence', 'systems', 'today', 'organize', 'operations', 'maintain', 'book', 'keeping', 'invest', 'stocks', 'manage', 'properties', 'ai', 'react', 'changes', 'overnight', 'business', 'taking', 'place', 'august', 'robots', 'beat', 'humans', 'simulated', 'financial', 'trading', 'competition', 'ai', 'also', 'reduced', 'fraud', 'financial', 'crimes', 'monitoring', 'behavioral', 'patterns', 'users', 'abnormal', 'changes', 'anomalies', 'ai', 'also', 'used', 'corporations', 'whereas', 'ai', 'ceo', 'still', 'years', 'away', 'robotic', 'process', 'automation', 'rpa', 'already', 'used', 'today', 'corporate', 'finance', 'rpa', 'uses', 'artificial', 'intelligence', 'train', 'teach', 'software', 'robots', 'process', 'transactions', 'monitor', 'compliance', 'audit', 'processes', 'automatically', 'use', 'ai', 'machines', 'market', 'applications', 'online', 'trading', 'decision', 'making', 'changed', 'major', 'economic', 'theories', 'example', 'ai', 'based', 'buying', 'selling', 'platforms', 'changed', 'law', 'supply', 'demand', 'possible', 'easily', 'estimate', 'individualized', 'demand', 'supply', 'curves', 'thus', 'individualized', 'pricing', 'furthermore', 'ai', 'machines', 'reduce', 'information', 'asymmetry', 'market', 'thus', 'making', 'markets', 'efficient', 'reducing', 'volume', 'trades', 'citation', 'needed', 'furthermore', 'ai', 'markets', 'limits', 'consequences', 'behavior', 'markets', 'making', 'markets', 'efficient', 'citation', 'needed', 'theories', 'ai', 'impact', 'include', 'rational', 'choice', 'rational', 'expectations', 'game', 'theory', 'lewis', 'turning', 'point', 'portfolio', 'optimization', 'counterfactual', 'thinking', 'citation', 'needed', 'august', 'aicpa', 'introduced', 'ai', 'training', 'course', 'accounting', 'professionals', 'cybersecurity', 'arena', 'faces', 'significant', 'challenges', 'form', 'larges', 'scale', 'hacking', 'attacks', 'different', 'types', 'harm', 'organizations', 'kinds', 'create', 'billions', 'dollars', 'business', 'damage', 'artificial', 'intelligence', 'natural', 'language', 'processing', 'nlp', 'begun', 'used', 'security', 'companies', 'example', 'siem', 'security', 'information', 'event', 'management', 'solutions', 'advanced', 'solutions', 'use', 'ai', 'nlp', 'automatically', 'sort', 'data', 'networks', 'high', 'risk', 'low', 'risk', 'information', 'enables', 'security', 'teams', 'focus', 'attacks', 'potential', 'real', 'harm', 'organization', 'become', 'victims', 'attacks', 'denial', 'service', 'dos', 'malware', 'others', 'artificial', 'intelligence', 'paired', 'facial', 'recognition', 'systems', 'may', 'used', 'mass', 'surveillance', 'already', 'case', 'parts', 'china', 'artificial', 'intelligence', 'also', 'competed', 'tama', 'city', 'mayoral', 'elections', 'tech', 'city', 'bengaluru', 'india', 'set', 'deploy', 'ai', 'managed', 'traffic', 'signal', 'systems', 'across', 'traffic', 'signals', 'city', 'system', 'involve', 'use', 'cameras', 'ascertain', 'traffic', 'density', 'accordingly', 'calculate', 'time', 'needed', 'clear', 'traffic', 'volume', 'determine', 'signal', 'duration', 'vehicular', 'traffic', 'across', 'streets', 'artificial', 'intelligence', 'ai', 'becoming', 'mainstay', 'component', 'law', 'related', 'professions', 'circumstances', 'analytics', 'crunching', 'technology', 'using', 'algorithms', 'machine', 'learning', 'work', 'previously', 'done', 'entry', 'level', 'lawyers', 'citation', 'needed', 'electronic', 'discovery', 'ediscovery', 'industry', 'focused', 'machine', 'learning', 'predictive', 'coding', 'technology', 'assisted', 'review', 'subset', 'ai', 'add', 'soup', 'applications', 'natural', 'language', 'processing', 'nlp', 'automated', 'speech', 'recognition', 'asr', 'also', 'vogue', 'industry', 'video', 'games', 'artificial', 'intelligence', 'routinely', 'used', 'generate', 'dynamic', 'purposeful', 'behavior', 'non', 'player', 'characters', 'npcs', 'addition', 'well', 'understood', 'ai', 'techniques', 'routinely', 'used', 'pathfinding', 'researchers', 'consider', 'npc', 'ai', 'games', 'solved', 'problem', 'production', 'tasks', 'games', 'atypical', 'ai', 'include', 'ai', 'director', 'left', 'dead', 'neuroevolutionary', 'training', 'platoons', 'supreme', 'commander', 'main', 'military', 'applications', 'artificial', 'intelligence', 'machine', 'learning', 'enhance', 'c', 'communications', 'sensors', 'integration', 'interoperability', 'artificial', 'intelligence', 'technologies', 'enables', 'coordination', 'sensors', 'effectors', 'threat', 'detection', 'identification', 'marking', 'enemy', 'positions', 'target', 'acquisition', 'coordination', 'deconfliction', 'distributed', 'join', 'fires', 'networked', 'combat', 'vehicles', 'tanks', 'also', 'inside', 'manned', 'unmanned', 'teams', 'mum', 'worldwide', 'annual', 'military', 'spending', 'robotics', 'rose', 'us', 'billion', 'us', 'billion', 'military', 'drones', 'capable', 'autonomous', 'action', 'widely', 'considered', 'useful', 'asset', 'many', 'artificial', 'intelligence', 'researchers', 'seek', 'distance', 'military', 'applications', 'ai', 'hospitality', 'industry', 'artificial', 'intelligence', 'based', 'solutions', 'used', 'reduce', 'staff', 'load', 'increase', 'efficiency', 'cutting', 'repetitive', 'tasks', 'frequency', 'trends', 'analysis', 'guest', 'interaction', 'customer', 'needs', 'prediction', 'hotel', 'services', 'backed', 'artificial', 'intelligence', 'represented', 'form', 'chatbot', 'application', 'virtual', 'voice', 'assistant', 'service', 'robots', 'financial', 'statements', 'audit', 'ai', 'makes', 'continuous', 'audit', 'possible', 'ai', 'tools', 'could', 'analyze', 'many', 'sets', 'different', 'information', 'immediately', 'potential', 'benefit', 'would', 'overall', 'audit', 'risk', 'reduced', 'level', 'assurance', 'increased', 'time', 'duration', 'audit', 'reduced', 'possible', 'use', 'ai', 'predict', 'generalize', 'behavior', 'customers', 'digital', 'footprints', 'order', 'target', 'personalized', 'promotions', 'build', 'customer', 'personas', 'automatically', 'documented', 'case', 'reports', 'online', 'gambling', 'companies', 'using', 'ai', 'improve', 'customer', 'targeting', 'moreover', 'application', 'personality', 'computing', 'ai', 'models', 'help', 'reducing', 'cost', 'advertising', 'campaigns', 'adding', 'psychological', 'targeting', 'traditional', 'sociodemographic', 'behavioral', 'targeting', 'artificial', 'intelligence', 'inspired', 'numerous', 'creative', 'applications', 'including', 'usage', 'produce', 'visual', 'art', 'exhibition', 'thinking', 'machines', 'art', 'design', 'computer', 'age', 'moma', 'provides', 'good', 'overview', 'historical', 'applications', 'ai', 'art', 'architecture', 'design', 'recent', 'exhibitions', 'showcasing', 'usage', 'ai', 'produce', 'art', 'include', 'google', 'sponsored', 'benefit', 'auction', 'gray', 'area', 'foundation', 'san', 'francisco', 'artists', 'experimented', 'deepdream', 'algorithm', 'exhibition', 'unhuman', 'art', 'age', 'ai', 'took', 'place', 'los', 'angeles', 'frankfurt', 'fall', 'spring', 'association', 'computing', 'machinery', 'dedicated', 'special', 'magazine', 'issue', 'subject', 'computers', 'art', 'highlighting', 'role', 'machine', 'learning', 'arts', 'austrian', 'ars', 'electronica', 'museum', 'applied', 'arts', 'vienna', 'opened', 'exhibitions', 'ai', 'ars', 'electronica', 'festival', 'box', 'extensively', 'thematized', 'role', 'arts', 'sustainable', 'societal', 'transformation', 'ai', 'three', 'philosophical', 'questions', 'related', 'ai', 'machine', 'intelligent', 'think', 'widespread', 'use', 'artificial', 'intelligence', 'could', 'unintended', 'consequences', 'dangerous', 'undesirable', 'scientists', 'future', 'life', 'institute', 'among', 'others', 'described', 'short', 'term', 'research', 'goals', 'see', 'ai', 'influences', 'economy', 'laws', 'ethics', 'involved', 'ai', 'minimize', 'ai', 'security', 'risks', 'long', 'term', 'scientists', 'proposed', 'continue', 'optimizing', 'function', 'minimizing', 'possible', 'security', 'risks', 'come', 'along', 'new', 'technologies', 'potential', 'negative', 'effects', 'ai', 'automation', 'major', 'issue', 'andrew', 'yang', 'presidential', 'campaign', 'irakli', 'beridze', 'head', 'centre', 'artificial', 'intelligence', 'robotics', 'unicri', 'united', 'nations', 'expressed', 'think', 'dangerous', 'applications', 'ai', 'point', 'view', 'would', 'criminals', 'large', 'terrorist', 'organizations', 'using', 'disrupt', 'large', 'processes', 'simply', 'pure', 'harm', 'terrorists', 'could', 'cause', 'harm', 'via', 'digital', 'warfare', 'could', 'combination', 'robotics', 'drones', 'ai', 'things', 'well', 'could', 'really', 'dangerous', 'course', 'risks', 'come', 'things', 'like', 'job', 'losses', 'massive', 'numbers', 'people', 'losing', 'jobs', 'find', 'solution', 'extremely', 'dangerous', 'things', 'like', 'lethal', 'autonomous', 'weapons', 'systems', 'properly', 'governed', 'otherwise', 'massive', 'potential', 'misuse', 'physicist', 'stephen', 'hawking', 'microsoft', 'founder', 'bill', 'gates', 'spacex', 'founder', 'elon', 'musk', 'expressed', 'concerns', 'possibility', 'ai', 'could', 'evolve', 'point', 'humans', 'could', 'control', 'hawking', 'theorizing', 'could', 'spell', 'end', 'human', 'race', 'development', 'full', 'artificial', 'intelligence', 'could', 'spell', 'end', 'human', 'race', 'humans', 'develop', 'artificial', 'intelligence', 'take', 'redesign', 'ever', 'increasing', 'rate', 'humans', 'limited', 'slow', 'biological', 'evolution', 'compete', 'would', 'superseded', 'book', 'superintelligence', 'nick', 'bostrom', 'provides', 'argument', 'artificial', 'intelligence', 'pose', 'threat', 'humankind', 'argues', 'sufficiently', 'intelligent', 'ai', 'chooses', 'actions', 'based', 'achieving', 'goal', 'exhibit', 'convergent', 'behavior', 'acquiring', 'resources', 'protecting', 'shut', 'ai', 'goals', 'reflect', 'humanity', 'one', 'example', 'ai', 'told', 'compute', 'many', 'digits', 'pi', 'possible', 'might', 'harm', 'humanity', 'order', 'acquire', 'resources', 'prevent', 'shut', 'ultimately', 'better', 'achieve', 'goal', 'concern', 'risk', 'artificial', 'intelligence', 'led', 'high', 'profile', 'donations', 'investments', 'group', 'prominent', 'tech', 'titans', 'including', 'peter', 'thiel', 'amazon', 'web', 'services', 'musk', 'committed', 'billion', 'openai', 'nonprofit', 'company', 'aimed', 'championing', 'responsible', 'ai', 'development', 'opinion', 'experts', 'within', 'field', 'artificial', 'intelligence', 'mixed', 'sizable', 'fractions', 'concerned', 'unconcerned', 'risk', 'eventual', 'superhumanly', 'capable', 'ai', 'technology', 'industry', 'leaders', 'believe', 'artificial', 'intelligence', 'helpful', 'current', 'form', 'continue', 'assist', 'humans', 'oracle', 'ceo', 'mark', 'hurd', 'stated', 'ai', 'actually', 'create', 'jobs', 'less', 'jobs', 'humans', 'needed', 'manage', 'ai', 'systems', 'facebook', 'ceo', 'mark', 'zuckerberg', 'believes', 'ai', 'unlock', 'huge', 'amount', 'positive', 'things', 'curing', 'disease', 'increasing', 'safety', 'autonomous', 'cars', 'january', 'elon', 'musk', 'donated', 'ten', 'million', 'dollars', 'future', 'life', 'institute', 'fund', 'research', 'understanding', 'ai', 'decision', 'making', 'goal', 'institute', 'grow', 'wisdom', 'manage', 'growing', 'power', 'technology', 'musk', 'also', 'funds', 'companies', 'developing', 'artificial', 'intelligence', 'deepmind', 'vicarious', 'keep', 'eye', 'going', 'artificial', 'intelligence', 'think', 'potentially', 'dangerous', 'outcome', 'danger', 'realized', 'hypothetical', 'ai', 'would', 'overpower', 'think', 'humanity', 'minority', 'experts', 'argue', 'possibility', 'far', 'enough', 'future', 'worth', 'researching', 'counterarguments', 'revolve', 'around', 'humans', 'either', 'intrinsically', 'convergently', 'valuable', 'perspective', 'artificial', 'intelligence', 'joseph', 'weizenbaum', 'wrote', 'ai', 'applications', 'definition', 'successfully', 'simulate', 'genuine', 'human', 'empathy', 'use', 'ai', 'technology', 'fields', 'customer', 'service', 'psychotherapy', 'deeply', 'misguided', 'weizenbaum', 'also', 'bothered', 'ai', 'researchers', 'philosophers', 'willing', 'view', 'human', 'mind', 'nothing', 'computer', 'program', 'position', 'known', 'computationalism', 'weizenbaum', 'points', 'suggest', 'ai', 'research', 'devalues', 'human', 'life', 'one', 'concern', 'ai', 'programs', 'may', 'programmed', 'biased', 'certain', 'groups', 'women', 'minorities', 'developers', 'wealthy', 'caucasian', 'men', 'support', 'artificial', 'intelligence', 'higher', 'among', 'men', 'approving', 'women', 'approving', 'algorithms', 'host', 'applications', 'today', 'legal', 'system', 'already', 'assisting', 'officials', 'ranging', 'judges', 'parole', 'officers', 'public', 'defenders', 'gauging', 'predicted', 'likelihood', 'recidivism', 'defendants', 'compas', 'acronym', 'correctional', 'offender', 'management', 'profiling', 'alternative', 'sanctions', 'counts', 'among', 'widely', 'utilized', 'commercially', 'available', 'solutions', 'suggested', 'compas', 'assigns', 'exceptionally', 'elevated', 'risk', 'recidivism', 'black', 'defendants', 'conversely', 'ascribing', 'low', 'risk', 'estimate', 'white', 'defendants', 'significantly', 'often', 'statistically', 'expected', 'relationship', 'automation', 'employment', 'complicated', 'automation', 'eliminates', 'old', 'jobs', 'also', 'creates', 'new', 'jobs', 'micro', 'economic', 'macro', 'economic', 'effects', 'unlike', 'previous', 'waves', 'automation', 'many', 'middle', 'class', 'jobs', 'may', 'eliminated', 'artificial', 'intelligence', 'economist', 'states', 'worry', 'ai', 'could', 'white', 'collar', 'jobs', 'steam', 'power', 'blue', 'collar', 'ones', 'industrial', 'revolution', 'worth', 'taking', 'seriously', 'subjective', 'estimates', 'risk', 'vary', 'widely', 'example', 'michael', 'osborne', 'carl', 'benedikt', 'frey', 'estimate', 'u', 'jobs', 'high', 'risk', 'potential', 'automation', 'oecd', 'report', 'classifies', 'u', 'jobs', 'high', 'risk', 'jobs', 'extreme', 'risk', 'range', 'paralegals', 'fast', 'food', 'cooks', 'job', 'demand', 'likely', 'increase', 'care', 'related', 'professions', 'ranging', 'personal', 'healthcare', 'clergy', 'author', 'martin', 'ford', 'others', 'go', 'argue', 'many', 'jobs', 'routine', 'repetitive', 'ai', 'predictable', 'ford', 'warns', 'jobs', 'may', 'automated', 'next', 'couple', 'decades', 'many', 'new', 'jobs', 'may', 'accessible', 'people', 'average', 'capability', 'even', 'retraining', 'economists', 'point', 'past', 'technology', 'tended', 'increase', 'rather', 'reduce', 'total', 'employment', 'acknowledge', 'uncharted', 'territory', 'ai', 'currently', 'countries', 'researching', 'battlefield', 'robots', 'including', 'united', 'states', 'china', 'russia', 'united', 'kingdom', 'many', 'people', 'concerned', 'risk', 'superintelligent', 'ai', 'also', 'want', 'limit', 'use', 'artificial', 'soldiers', 'drones', 'machines', 'intelligence', 'potential', 'use', 'intelligence', 'prevent', 'harm', 'minimize', 'risks', 'may', 'ability', 'use', 'ethical', 'reasoning', 'better', 'choose', 'actions', 'world', 'research', 'area', 'includes', 'machine', 'ethics', 'artificial', 'moral', 'agents', 'friendly', 'ai', 'discussion', 'towards', 'building', 'human', 'rights', 'framework', 'also', 'talks', 'wendell', 'wallach', 'introduced', 'concept', 'artificial', 'moral', 'agents', 'ama', 'book', 'moral', 'machines', 'wallach', 'amas', 'become', 'part', 'research', 'landscape', 'artificial', 'intelligence', 'guided', 'two', 'central', 'questions', 'identifies', 'humanity', 'want', 'computers', 'making', 'moral', 'decisions', 'ro', 'bots', 'really', 'moral', 'wallach', 'question', 'centered', 'issue', 'whether', 'machines', 'demonstrate', 'equivalent', 'moral', 'behavior', 'contrast', 'constraints', 'society', 'may', 'place', 'development', 'amas', 'field', 'machine', 'ethics', 'concerned', 'giving', 'machines', 'ethical', 'principles', 'procedure', 'discovering', 'way', 'resolve', 'ethical', 'dilemmas', 'might', 'encounter', 'enabling', 'function', 'ethically', 'responsible', 'manner', 'ethical', 'decision', 'making', 'field', 'delineated', 'aaai', 'fall', 'symposium', 'machine', 'ethics', 'past', 'research', 'concerning', 'relationship', 'technology', 'ethics', 'largely', 'focused', 'responsible', 'irresponsible', 'use', 'technology', 'human', 'beings', 'people', 'interested', 'human', 'beings', 'ought', 'treat', 'machines', 'cases', 'human', 'beings', 'engaged', 'ethical', 'reasoning', 'time', 'come', 'adding', 'ethical', 'dimension', 'least', 'machines', 'recognition', 'ethical', 'ramifications', 'behavior', 'involving', 'machines', 'well', 'recent', 'potential', 'developments', 'machine', 'autonomy', 'necessitate', 'contrast', 'computer', 'hacking', 'software', 'property', 'issues', 'privacy', 'issues', 'topics', 'normally', 'ascribed', 'computer', 'ethics', 'machine', 'ethics', 'concerned', 'behavior', 'machines', 'towards', 'human', 'users', 'machines', 'research', 'machine', 'ethics', 'key', 'alleviating', 'concerns', 'autonomous', 'systems', 'could', 'argued', 'notion', 'autonomous', 'machines', 'without', 'dimension', 'root', 'fear', 'concerning', 'machine', 'intelligence', 'investigation', 'machine', 'ethics', 'could', 'enable', 'discovery', 'problems', 'current', 'ethical', 'theories', 'advancing', 'thinking', 'ethics', 'machine', 'ethics', 'sometimes', 'referred', 'machine', 'morality', 'computational', 'ethics', 'computational', 'morality', 'variety', 'perspectives', 'nascent', 'field', 'found', 'collected', 'edition', 'machine', 'ethics', 'stems', 'aaai', 'fall', 'symposium', 'machine', 'ethics', 'political', 'scientist', 'charles', 'rubin', 'believes', 'ai', 'neither', 'designed', 'guaranteed', 'benevolent', 'argues', 'sufficiently', 'advanced', 'benevolence', 'may', 'indistinguishable', 'malevolence', 'humans', 'assume', 'machines', 'robots', 'would', 'treat', 'us', 'favorably', 'priori', 'reason', 'believe', 'would', 'sympathetic', 'system', 'morality', 'evolved', 'along', 'particular', 'biology', 'ais', 'would', 'share', 'hyper', 'intelligent', 'software', 'may', 'necessarily', 'decide', 'support', 'continued', 'existence', 'humanity', 'would', 'extremely', 'difficult', 'stop', 'topic', 'also', 'recently', 'begun', 'discussed', 'academic', 'publications', 'real', 'source', 'risks', 'civilization', 'humans', 'planet', 'earth', 'one', 'proposal', 'deal', 'ensure', 'first', 'generally', 'intelligent', 'ai', 'friendly', 'ai', 'able', 'control', 'subsequently', 'developed', 'ais', 'question', 'whether', 'kind', 'check', 'could', 'actually', 'remain', 'place', 'leading', 'ai', 'researcher', 'rodney', 'brooks', 'writes', 'think', 'mistake', 'worrying', 'us', 'developing', 'malevolent', 'ai', 'anytime', 'next', 'hundred', 'years', 'think', 'worry', 'stems', 'fundamental', 'error', 'distinguishing', 'difference', 'real', 'recent', 'advances', 'particular', 'aspect', 'ai', 'enormity', 'complexity', 'building', 'sentient', 'volitional', 'intelligence', 'ai', 'system', 'replicates', 'key', 'aspects', 'human', 'intelligence', 'system', 'also', 'sentient', 'mind', 'conscious', 'experiences', 'question', 'closely', 'related', 'philosophical', 'problem', 'nature', 'human', 'consciousness', 'generally', 'referred', 'hard', 'problem', 'consciousness', 'david', 'chalmers', 'identified', 'two', 'problems', 'understanding', 'mind', 'named', 'hard', 'easy', 'problems', 'consciousness', 'easy', 'problem', 'understanding', 'brain', 'processes', 'signals', 'makes', 'plans', 'controls', 'behavior', 'hard', 'problem', 'explaining', 'feels', 'feel', 'like', 'anything', 'human', 'information', 'processing', 'easy', 'explain', 'however', 'human', 'subjective', 'experience', 'difficult', 'explain', 'example', 'consider', 'happens', 'person', 'shown', 'color', 'swatch', 'identifies', 'saying', 'red', 'easy', 'problem', 'requires', 'understanding', 'machinery', 'brain', 'makes', 'possible', 'person', 'know', 'color', 'swatch', 'red', 'hard', 'problem', 'people', 'also', 'know', 'something', 'else', 'also', 'know', 'red', 'looks', 'like', 'consider', 'person', 'born', 'blind', 'know', 'something', 'red', 'without', 'knowing', 'red', 'looks', 'like', 'l', 'everyone', 'knows', 'subjective', 'experience', 'exists', 'every', 'day', 'e', 'g', 'sighted', 'people', 'know', 'red', 'looks', 'like', 'hard', 'problem', 'explaining', 'brain', 'creates', 'exists', 'different', 'knowledge', 'aspects', 'brain', 'computationalism', 'position', 'philosophy', 'mind', 'human', 'mind', 'human', 'brain', 'information', 'processing', 'system', 'thinking', 'form', 'computing', 'computationalism', 'argues', 'relationship', 'mind', 'body', 'similar', 'identical', 'relationship', 'software', 'hardware', 'thus', 'may', 'solution', 'mind', 'body', 'problem', 'philosophical', 'position', 'inspired', 'work', 'ai', 'researchers', 'cognitive', 'scientists', 'originally', 'proposed', 'philosophers', 'jerry', 'fodor', 'hilary', 'putnam', 'philosophical', 'position', 'john', 'searle', 'named', 'strong', 'ai', 'states', 'appropriately', 'programmed', 'computer', 'right', 'inputs', 'outputs', 'would', 'thereby', 'mind', 'exactly', 'sense', 'human', 'beings', 'minds', 'searle', 'counters', 'assertion', 'chinese', 'room', 'argument', 'asks', 'us', 'look', 'inside', 'computer', 'try', 'find', 'mind', 'might', 'machine', 'created', 'intelligence', 'could', 'also', 'feel', 'feel', 'rights', 'human', 'issue', 'known', 'robot', 'rights', 'currently', 'considered', 'example', 'california', 'institute', 'future', 'although', 'many', 'critics', 'believe', 'discussion', 'premature', 'critics', 'transhumanism', 'argue', 'hypothetical', 'robot', 'rights', 'would', 'lie', 'spectrum', 'animal', 'rights', 'human', 'rights', 'subject', 'profoundly', 'discussed', 'documentary', 'film', 'plug', 'pray', 'many', 'sci', 'fi', 'media', 'star', 'trek', 'next', 'generation', 'character', 'commander', 'data', 'fought', 'disassembled', 'research', 'wanted', 'become', 'human', 'robotic', 'holograms', 'voyager', 'limits', 'intelligent', 'machines', 'human', 'machine', 'hybrids', 'superintelligence', 'hyperintelligence', 'superhuman', 'intelligence', 'hypothetical', 'agent', 'would', 'possess', 'intelligence', 'far', 'surpassing', 'brightest', 'gifted', 'human', 'mind', 'superintelligence', 'may', 'also', 'refer', 'form', 'degree', 'intelligence', 'possessed', 'agent', 'research', 'strong', 'ai', 'produced', 'sufficiently', 'intelligent', 'software', 'might', 'able', 'reprogram', 'improve', 'improved', 'software', 'would', 'even', 'better', 'improving', 'leading', 'recursive', 'self', 'improvement', 'new', 'intelligence', 'could', 'thus', 'increase', 'exponentially', 'dramatically', 'surpass', 'humans', 'science', 'fiction', 'writer', 'vernor', 'vinge', 'named', 'scenario', 'singularity', 'technological', 'singularity', 'accelerating', 'progress', 'technologies', 'cause', 'runaway', 'effect', 'wherein', 'artificial', 'intelligence', 'exceed', 'human', 'intellectual', 'capacity', 'control', 'thus', 'radically', 'changing', 'even', 'ending', 'civilization', 'capabilities', 'intelligence', 'may', 'impossible', 'comprehend', 'technological', 'singularity', 'occurrence', 'beyond', 'events', 'unpredictable', 'even', 'unfathomable', 'ray', 'kurzweil', 'used', 'moore', 'law', 'describes', 'relentless', 'exponential', 'improvement', 'digital', 'technology', 'calculate', 'desktop', 'computers', 'processing', 'power', 'human', 'brains', 'year', 'predicts', 'singularity', 'occur', 'robot', 'designer', 'hans', 'moravec', 'cyberneticist', 'kevin', 'warwick', 'inventor', 'ray', 'kurzweil', 'predicted', 'humans', 'machines', 'merge', 'future', 'cyborgs', 'capable', 'powerful', 'either', 'idea', 'called', 'transhumanism', 'roots', 'aldous', 'huxley', 'robert', 'ettinger', 'edward', 'fredkin', 'argues', 'artificial', 'intelligence', 'next', 'stage', 'evolution', 'idea', 'first', 'proposed', 'samuel', 'butler', 'darwin', 'among', 'machines', 'far', 'back', 'expanded', 'upon', 'george', 'dyson', 'book', 'name', 'long', 'term', 'economic', 'effects', 'ai', 'uncertain', 'survey', 'economists', 'showed', 'disagreement', 'whether', 'increasing', 'use', 'robots', 'ai', 'cause', 'substantial', 'increase', 'long', 'term', 'unemployment', 'generally', 'agree', 'could', 'net', 'benefit', 'productivity', 'gains', 'redistributed', 'thought', 'capable', 'artificial', 'beings', 'appeared', 'storytelling', 'devices', 'since', 'antiquity', 'persistent', 'theme', 'science', 'fiction', 'common', 'trope', 'works', 'began', 'mary', 'shelley', 'frankenstein', 'human', 'creation', 'becomes', 'threat', 'masters', 'includes', 'works', 'arthur', 'c', 'clarke', 'stanley', 'kubrick', 'space', 'odyssey', 'hal', 'murderous', 'computer', 'charge', 'discovery', 'one', 'spaceship', 'well', 'terminator', 'matrix', 'contrast', 'rare', 'loyal', 'robots', 'gort', 'day', 'earth', 'stood', 'still', 'bishop', 'aliens', 'less', 'prominent', 'popular', 'culture', 'isaac', 'asimov', 'introduced', 'three', 'laws', 'robotics', 'many', 'books', 'stories', 'notably', 'multivac', 'series', 'super', 'intelligent', 'computer', 'name', 'asimov', 'laws', 'often', 'brought', 'lay', 'discussions', 'machine', 'ethics', 'almost', 'artificial', 'intelligence', 'researchers', 'familiar', 'asimov', 'laws', 'popular', 'culture', 'generally', 'consider', 'laws', 'useless', 'many', 'reasons', 'one', 'ambiguity', 'transhumanism', 'merging', 'humans', 'machines', 'explored', 'manga', 'ghost', 'shell', 'science', 'fiction', 'series', 'dune', 'artist', 'hajime', 'sorayama', 'sexy', 'robots', 'series', 'painted', 'published', 'japan', 'depicting', 'actual', 'organic', 'human', 'form', 'lifelike', 'muscular', 'metallic', 'skins', 'later', 'gynoids', 'book', 'followed', 'used', 'influenced', 'movie', 'makers', 'including', 'george', 'lucas', 'creatives', 'sorayama', 'never', 'considered', 'organic', 'robots', 'real', 'part', 'nature', 'always', 'unnatural', 'product', 'human', 'mind', 'fantasy', 'existing', 'mind', 'even', 'realized', 'actual', 'form', 'several', 'works', 'use', 'ai', 'force', 'us', 'confront', 'fundamental', 'question', 'makes', 'us', 'human', 'showing', 'us', 'artificial', 'beings', 'ability', 'feel', 'thus', 'suffer', 'appears', 'karel', 'apek', 'r', 'u', 'r', 'films', 'artificial', 'intelligence', 'ex', 'machina', 'well', 'novel', 'androids', 'dream', 'electric', 'sheep', 'philip', 'k', 'dick', 'dick', 'considers', 'idea', 'understanding', 'human', 'subjectivity', 'altered', 'technology', 'created', 'artificial', 'intelligence', 'see', 'also', 'logic', 'machines', 'fiction', 'list', 'fictional', 'computers']]\n"
     ]
    }
   ],
   "source": [
    "print(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above script, we converted all the text to lowercase, and then removed all the digits, special characters, extra spaces from the text. After preprocessing, we are left with words. The Word2Vec model is trained on collection of words. Firest, we need to convert our article into sentences, we use nltk.sent_tokenize utility to convert our article to sentences, and then to words, we use nltk.word_tokenize utility. And as a last step, we remove all the stop words such as in, at, and on, etc.\n",
    "\n",
    "After the script completes its execution, the all_words object contains the list of all the words in the article. We will use this list to create our Word2Vec model with the Gensim library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Gensim model**\n",
    "\n",
    "The word list is passed to the Word2Vec class of the gensim.models package. We need to specify the value for the min_count parameter. A value of 2 for min_count specifies to include only those words in the Word2Vec model that appear at least twice in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading https://files.pythonhosted.org/packages/09/ed/b59a2edde05b7f5755ea68648487c150c7c742361e9c8733c6d4ca005020/gensim-3.8.1-cp37-cp37m-win_amd64.whl (24.2MB)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from gensim) (1.16.2)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/09/735f2786dfac9bbf39d244ce75c0313d27d4962e71e0774750dc809f2395/smart_open-1.9.0.tar.gz (70kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\n",
      "Collecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/57/e9675a5a8d0ee586594ff19cb9a601334fbf24fa2fb29052d2a900ee5d23/boto3-1.11.9-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting botocore<1.15.0,>=1.14.9 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/4c/b0b0d3b6f84a05f9135051b56d3eb8708012a289c4b82ee21c8c766f47b5/botocore-1.14.9-py2.py3-none-any.whl (5.9MB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/c7/48/a8252b6b3cd31774eab312b19d58a6ac55f296240c206617dcd38cd93bf8/s3transfer-0.3.2-py2.py3-none-any.whl (69kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.8.1->gensim) (0.14)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Renate\\AppData\\Local\\pip\\Cache\\wheels\\ab\\10\\93\\5cff86f5b721d77edaecc29959b1c60d894be1f66d91407d28\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.11.9 botocore-1.14.9 gensim-3.8.1 jmespath-0.9.4 s3transfer-0.3.2 smart-open-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': <gensim.models.keyedvectors.Vocab object at 0x000002114D9A4550>, 'science': <gensim.models.keyedvectors.Vocab object at 0x000002114F225B70>, 'artificial': <gensim.models.keyedvectors.Vocab object at 0x000002114F226160>, 'intelligence': <gensim.models.keyedvectors.Vocab object at 0x000002114F226048>, 'ai': <gensim.models.keyedvectors.Vocab object at 0x000002114F707588>, 'sometimes': <gensim.models.keyedvectors.Vocab object at 0x000002114F7075C0>, 'called': <gensim.models.keyedvectors.Vocab object at 0x000002114F817EF0>, 'machine': <gensim.models.keyedvectors.Vocab object at 0x000002114A479080>, 'demonstrated': <gensim.models.keyedvectors.Vocab object at 0x000002114A5364A8>, 'machines': <gensim.models.keyedvectors.Vocab object at 0x000002114A536518>, 'contrast': <gensim.models.keyedvectors.Vocab object at 0x000002114A536550>, 'natural': <gensim.models.keyedvectors.Vocab object at 0x000002114A536588>, 'displayed': <gensim.models.keyedvectors.Vocab object at 0x000002114A5365C0>, 'humans': <gensim.models.keyedvectors.Vocab object at 0x000002114A5365F8>, 'leading': <gensim.models.keyedvectors.Vocab object at 0x000002114A536630>, 'field': <gensim.models.keyedvectors.Vocab object at 0x000002114A536668>, 'study': <gensim.models.keyedvectors.Vocab object at 0x000002114A5366A0>, 'intelligent': <gensim.models.keyedvectors.Vocab object at 0x000002114A5366D8>, 'agents': <gensim.models.keyedvectors.Vocab object at 0x000002114A536710>, 'device': <gensim.models.keyedvectors.Vocab object at 0x000002114A536748>, 'perceives': <gensim.models.keyedvectors.Vocab object at 0x000002114A536780>, 'environment': <gensim.models.keyedvectors.Vocab object at 0x000002114A5367B8>, 'takes': <gensim.models.keyedvectors.Vocab object at 0x000002114A5367F0>, 'actions': <gensim.models.keyedvectors.Vocab object at 0x000002114A536828>, 'maximize': <gensim.models.keyedvectors.Vocab object at 0x000002114A536860>, 'chance': <gensim.models.keyedvectors.Vocab object at 0x000002114A536898>, 'successfully': <gensim.models.keyedvectors.Vocab object at 0x000002114A5368D0>, 'achieving': <gensim.models.keyedvectors.Vocab object at 0x000002114A536908>, 'goals': <gensim.models.keyedvectors.Vocab object at 0x000002114A536940>, 'term': <gensim.models.keyedvectors.Vocab object at 0x000002114A536978>, 'often': <gensim.models.keyedvectors.Vocab object at 0x000002114A5369B0>, 'used': <gensim.models.keyedvectors.Vocab object at 0x000002114A5369E8>, 'describe': <gensim.models.keyedvectors.Vocab object at 0x000002114A536A20>, 'computers': <gensim.models.keyedvectors.Vocab object at 0x000002114A536A58>, 'mimic': <gensim.models.keyedvectors.Vocab object at 0x000002114A536A90>, 'cognitive': <gensim.models.keyedvectors.Vocab object at 0x000002114A536AC8>, 'functions': <gensim.models.keyedvectors.Vocab object at 0x000002114A536B00>, 'human': <gensim.models.keyedvectors.Vocab object at 0x000002114A536B38>, 'mind': <gensim.models.keyedvectors.Vocab object at 0x000002114A536B70>, 'learning': <gensim.models.keyedvectors.Vocab object at 0x000002114A536BA8>, 'problem': <gensim.models.keyedvectors.Vocab object at 0x000002114A536BE0>, 'solving': <gensim.models.keyedvectors.Vocab object at 0x000002114A536C18>, 'become': <gensim.models.keyedvectors.Vocab object at 0x000002114A536C50>, 'increasingly': <gensim.models.keyedvectors.Vocab object at 0x000002114A536C88>, 'capable': <gensim.models.keyedvectors.Vocab object at 0x000002114A536CC0>, 'tasks': <gensim.models.keyedvectors.Vocab object at 0x000002114A536CF8>, 'considered': <gensim.models.keyedvectors.Vocab object at 0x000002114A536D30>, 'require': <gensim.models.keyedvectors.Vocab object at 0x000002114A536D68>, 'definition': <gensim.models.keyedvectors.Vocab object at 0x000002114A536DA0>, 'phenomenon': <gensim.models.keyedvectors.Vocab object at 0x000002114A536DD8>, 'known': <gensim.models.keyedvectors.Vocab object at 0x000002114A536E10>, 'effect': <gensim.models.keyedvectors.Vocab object at 0x000002114A536E48>, 'done': <gensim.models.keyedvectors.Vocab object at 0x000002114A536E80>, 'yet': <gensim.models.keyedvectors.Vocab object at 0x000002114A536EB8>, 'instance': <gensim.models.keyedvectors.Vocab object at 0x000002114A536EF0>, 'character': <gensim.models.keyedvectors.Vocab object at 0x000002114A536F28>, 'recognition': <gensim.models.keyedvectors.Vocab object at 0x000002114A536F60>, 'frequently': <gensim.models.keyedvectors.Vocab object at 0x000002114A536F98>, 'things': <gensim.models.keyedvectors.Vocab object at 0x000002114A536FD0>, 'routine': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E048>, 'technology': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E080>, 'modern': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E0B8>, 'capabilities': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E0F0>, 'generally': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E128>, 'classified': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E160>, 'include': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E198>, 'understanding': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E1D0>, 'speech': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E208>, 'competing': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E240>, 'level': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E278>, 'game': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E2B0>, 'systems': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E2E8>, 'chess': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E320>, 'go': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E358>, 'operating': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E390>, 'cars': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E3C8>, 'content': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E400>, 'networks': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E438>, 'military': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E470>, 'founded': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E4A8>, 'academic': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E4E0>, 'discipline': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E518>, 'years': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E550>, 'since': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E588>, 'experienced': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E5C0>, 'several': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E5F8>, 'waves': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E630>, 'followed': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E668>, 'funding': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E6A0>, 'winter': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E6D8>, 'new': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E710>, 'approaches': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E748>, 'success': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E780>, 'research': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E7B8>, 'divided': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E7F0>, 'subfields': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E828>, 'sub': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E860>, 'fields': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E898>, 'based': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E8D0>, 'particular': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E908>, 'e': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E940>, 'g': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E978>, 'robotics': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E9B0>, 'use': <gensim.models.keyedvectors.Vocab object at 0x000002114A53E9E8>, 'tools': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EA20>, 'logic': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EA58>, 'neural': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EA90>, 'deep': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EAC8>, 'philosophical': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EB00>, 'also': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EB38>, 'social': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EB70>, 'factors': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EBA8>, 'institutions': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EBE0>, 'work': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EC18>, 'researchers': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EC50>, 'traditional': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EC88>, 'problems': <gensim.models.keyedvectors.Vocab object at 0x000002114A53ECC0>, 'reasoning': <gensim.models.keyedvectors.Vocab object at 0x000002114A53ECF8>, 'knowledge': <gensim.models.keyedvectors.Vocab object at 0x000002114A53ED30>, 'representation': <gensim.models.keyedvectors.Vocab object at 0x000002114A53ED68>, 'planning': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EDA0>, 'language': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EDD8>, 'processing': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EE10>, 'perception': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EE48>, 'ability': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EE80>, 'move': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EEB8>, 'objects': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EEF0>, 'general': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EF28>, 'among': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EF60>, 'long': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EF98>, 'statistical': <gensim.models.keyedvectors.Vocab object at 0x000002114A53EFD0>, 'methods': <gensim.models.keyedvectors.Vocab object at 0x000002114A541048>, 'computational': <gensim.models.keyedvectors.Vocab object at 0x000002114A541080>, 'symbolic': <gensim.models.keyedvectors.Vocab object at 0x000002114A5410B8>, 'many': <gensim.models.keyedvectors.Vocab object at 0x000002114A5410F0>, 'including': <gensim.models.keyedvectors.Vocab object at 0x000002114A541128>, 'search': <gensim.models.keyedvectors.Vocab object at 0x000002114A541160>, 'mathematical': <gensim.models.keyedvectors.Vocab object at 0x000002114A541198>, 'optimization': <gensim.models.keyedvectors.Vocab object at 0x000002114A5411D0>, 'statistics': <gensim.models.keyedvectors.Vocab object at 0x000002114A541208>, 'probability': <gensim.models.keyedvectors.Vocab object at 0x000002114A541240>, 'economics': <gensim.models.keyedvectors.Vocab object at 0x000002114A541278>, 'upon': <gensim.models.keyedvectors.Vocab object at 0x000002114A5412B0>, 'information': <gensim.models.keyedvectors.Vocab object at 0x000002114A5412E8>, 'engineering': <gensim.models.keyedvectors.Vocab object at 0x000002114A541320>, 'mathematics': <gensim.models.keyedvectors.Vocab object at 0x000002114A541358>, 'psychology': <gensim.models.keyedvectors.Vocab object at 0x000002114A541390>, 'philosophy': <gensim.models.keyedvectors.Vocab object at 0x000002114A5413C8>, 'described': <gensim.models.keyedvectors.Vocab object at 0x000002114A541400>, 'made': <gensim.models.keyedvectors.Vocab object at 0x000002114A541438>, 'simulate': <gensim.models.keyedvectors.Vocab object at 0x000002114A541470>, 'nature': <gensim.models.keyedvectors.Vocab object at 0x000002114A5414A8>, 'ethics': <gensim.models.keyedvectors.Vocab object at 0x000002114A5414E0>, 'creating': <gensim.models.keyedvectors.Vocab object at 0x000002114A541518>, 'beings': <gensim.models.keyedvectors.Vocab object at 0x000002114A541550>, 'like': <gensim.models.keyedvectors.Vocab object at 0x000002114A541588>, 'issues': <gensim.models.keyedvectors.Vocab object at 0x000002114A5415C0>, 'explored': <gensim.models.keyedvectors.Vocab object at 0x000002114A5415F8>, 'fiction': <gensim.models.keyedvectors.Vocab object at 0x000002114A541630>, 'antiquity': <gensim.models.keyedvectors.Vocab object at 0x000002114A541668>, 'people': <gensim.models.keyedvectors.Vocab object at 0x000002114A5416A0>, 'consider': <gensim.models.keyedvectors.Vocab object at 0x000002114A5416D8>, 'danger': <gensim.models.keyedvectors.Vocab object at 0x000002114A541710>, 'humanity': <gensim.models.keyedvectors.Vocab object at 0x000002114A541748>, 'others': <gensim.models.keyedvectors.Vocab object at 0x000002114A541780>, 'believe': <gensim.models.keyedvectors.Vocab object at 0x000002114A5417B8>, 'unlike': <gensim.models.keyedvectors.Vocab object at 0x000002114A5417F0>, 'previous': <gensim.models.keyedvectors.Vocab object at 0x000002114A541828>, 'technological': <gensim.models.keyedvectors.Vocab object at 0x000002114A541860>, 'create': <gensim.models.keyedvectors.Vocab object at 0x000002114A541898>, 'risk': <gensim.models.keyedvectors.Vocab object at 0x000002114A5418D0>, 'mass': <gensim.models.keyedvectors.Vocab object at 0x000002114A541908>, 'unemployment': <gensim.models.keyedvectors.Vocab object at 0x000002114A541940>, 'twenty': <gensim.models.keyedvectors.Vocab object at 0x000002114A541978>, 'first': <gensim.models.keyedvectors.Vocab object at 0x000002114A5419B0>, 'century': <gensim.models.keyedvectors.Vocab object at 0x000002114A5419E8>, 'techniques': <gensim.models.keyedvectors.Vocab object at 0x000002114A541A20>, 'following': <gensim.models.keyedvectors.Vocab object at 0x000002114A541A58>, 'concurrent': <gensim.models.keyedvectors.Vocab object at 0x000002114A541A90>, 'advances': <gensim.models.keyedvectors.Vocab object at 0x000002114A541AC8>, 'power': <gensim.models.keyedvectors.Vocab object at 0x000002114A541B00>, 'large': <gensim.models.keyedvectors.Vocab object at 0x000002114A541B38>, 'amounts': <gensim.models.keyedvectors.Vocab object at 0x000002114A541B70>, 'data': <gensim.models.keyedvectors.Vocab object at 0x000002114A541BA8>, 'part': <gensim.models.keyedvectors.Vocab object at 0x000002114A541BE0>, 'industry': <gensim.models.keyedvectors.Vocab object at 0x000002114A541C18>, 'helping': <gensim.models.keyedvectors.Vocab object at 0x000002114A541C50>, 'solve': <gensim.models.keyedvectors.Vocab object at 0x000002114A541C88>, 'challenging': <gensim.models.keyedvectors.Vocab object at 0x000002114A541CC0>, 'software': <gensim.models.keyedvectors.Vocab object at 0x000002114A541CF8>, 'operations': <gensim.models.keyedvectors.Vocab object at 0x000002114A541D30>, 'thought': <gensim.models.keyedvectors.Vocab object at 0x000002114A541D68>, 'appeared': <gensim.models.keyedvectors.Vocab object at 0x000002114A541DA0>, 'storytelling': <gensim.models.keyedvectors.Vocab object at 0x000002114A541DD8>, 'devices': <gensim.models.keyedvectors.Vocab object at 0x000002114A541E10>, 'common': <gensim.models.keyedvectors.Vocab object at 0x000002114A541E48>, 'mary': <gensim.models.keyedvectors.Vocab object at 0x000002114A541E80>, 'shelley': <gensim.models.keyedvectors.Vocab object at 0x000002114A541EB8>, 'frankenstein': <gensim.models.keyedvectors.Vocab object at 0x000002114A541EF0>, 'karel': <gensim.models.keyedvectors.Vocab object at 0x000002114A541F28>, 'apek': <gensim.models.keyedvectors.Vocab object at 0x000002114A541F60>, 'r': <gensim.models.keyedvectors.Vocab object at 0x000002114A541F98>, 'u': <gensim.models.keyedvectors.Vocab object at 0x000002114A541FD0>, 'universal': <gensim.models.keyedvectors.Vocab object at 0x000002114A543048>, 'robots': <gensim.models.keyedvectors.Vocab object at 0x000002114A543080>, 'characters': <gensim.models.keyedvectors.Vocab object at 0x000002114A5430B8>, 'discussed': <gensim.models.keyedvectors.Vocab object at 0x000002114A5430F0>, 'mechanical': <gensim.models.keyedvectors.Vocab object at 0x000002114A543128>, 'formal': <gensim.models.keyedvectors.Vocab object at 0x000002114A543160>, 'began': <gensim.models.keyedvectors.Vocab object at 0x000002114A543198>, 'philosophers': <gensim.models.keyedvectors.Vocab object at 0x000002114A5431D0>, 'led': <gensim.models.keyedvectors.Vocab object at 0x000002114A543208>, 'directly': <gensim.models.keyedvectors.Vocab object at 0x000002114A543240>, 'turing': <gensim.models.keyedvectors.Vocab object at 0x000002114A543278>, 'theory': <gensim.models.keyedvectors.Vocab object at 0x000002114A5432B0>, 'computation': <gensim.models.keyedvectors.Vocab object at 0x000002114A5432E8>, 'suggested': <gensim.models.keyedvectors.Vocab object at 0x000002114A543320>, 'symbols': <gensim.models.keyedvectors.Vocab object at 0x000002114A543358>, 'simple': <gensim.models.keyedvectors.Vocab object at 0x000002114A543390>, 'could': <gensim.models.keyedvectors.Vocab object at 0x000002114A5433C8>, 'deduction': <gensim.models.keyedvectors.Vocab object at 0x000002114A543400>, 'digital': <gensim.models.keyedvectors.Vocab object at 0x000002114A543438>, 'process': <gensim.models.keyedvectors.Vocab object at 0x000002114A543470>, 'thesis': <gensim.models.keyedvectors.Vocab object at 0x000002114A5434A8>, 'along': <gensim.models.keyedvectors.Vocab object at 0x000002114A5434E0>, 'neurobiology': <gensim.models.keyedvectors.Vocab object at 0x000002114A543518>, 'cybernetics': <gensim.models.keyedvectors.Vocab object at 0x000002114A543550>, 'possibility': <gensim.models.keyedvectors.Vocab object at 0x000002114A543588>, 'building': <gensim.models.keyedvectors.Vocab object at 0x000002114A5435C0>, 'electronic': <gensim.models.keyedvectors.Vocab object at 0x000002114A5435F8>, 'brain': <gensim.models.keyedvectors.Vocab object at 0x000002114A543630>, 'proposed': <gensim.models.keyedvectors.Vocab object at 0x000002114A543668>, 'changing': <gensim.models.keyedvectors.Vocab object at 0x000002114A5436A0>, 'question': <gensim.models.keyedvectors.Vocab object at 0x000002114A5436D8>, 'whether': <gensim.models.keyedvectors.Vocab object at 0x000002114A543710>, 'possible': <gensim.models.keyedvectors.Vocab object at 0x000002114A543748>, 'machinery': <gensim.models.keyedvectors.Vocab object at 0x000002114A543780>, 'show': <gensim.models.keyedvectors.Vocab object at 0x000002114A5437B8>, 'mccullouch': <gensim.models.keyedvectors.Vocab object at 0x000002114A5437F0>, 'pitts': <gensim.models.keyedvectors.Vocab object at 0x000002114A543828>, 'design': <gensim.models.keyedvectors.Vocab object at 0x000002114A543860>, 'complete': <gensim.models.keyedvectors.Vocab object at 0x000002114A543898>, 'neurons': <gensim.models.keyedvectors.Vocab object at 0x000002114A5438D0>, 'born': <gensim.models.keyedvectors.Vocab object at 0x000002114A543908>, 'john': <gensim.models.keyedvectors.Vocab object at 0x000002114A543940>, 'mccarthy': <gensim.models.keyedvectors.Vocab object at 0x000002114A543978>, 'escape': <gensim.models.keyedvectors.Vocab object at 0x000002114A5439B0>, 'cyberneticist': <gensim.models.keyedvectors.Vocab object at 0x000002114A5439E8>, 'allen': <gensim.models.keyedvectors.Vocab object at 0x000002114A543A20>, 'newell': <gensim.models.keyedvectors.Vocab object at 0x000002114A543A58>, 'cmu': <gensim.models.keyedvectors.Vocab object at 0x000002114A543A90>, 'herbert': <gensim.models.keyedvectors.Vocab object at 0x000002114A543AC8>, 'simon': <gensim.models.keyedvectors.Vocab object at 0x000002114A543B00>, 'mit': <gensim.models.keyedvectors.Vocab object at 0x000002114A543B38>, 'marvin': <gensim.models.keyedvectors.Vocab object at 0x000002114A543B70>, 'minsky': <gensim.models.keyedvectors.Vocab object at 0x000002114A543BA8>, 'arthur': <gensim.models.keyedvectors.Vocab object at 0x000002114A543BE0>, 'samuel': <gensim.models.keyedvectors.Vocab object at 0x000002114A543C18>, 'ibm': <gensim.models.keyedvectors.Vocab object at 0x000002114A543C50>, 'became': <gensim.models.keyedvectors.Vocab object at 0x000002114A543C88>, 'founders': <gensim.models.keyedvectors.Vocab object at 0x000002114A543CC0>, 'leaders': <gensim.models.keyedvectors.Vocab object at 0x000002114A543CF8>, 'produced': <gensim.models.keyedvectors.Vocab object at 0x000002114A543D30>, 'programs': <gensim.models.keyedvectors.Vocab object at 0x000002114A543D68>, 'checkers': <gensim.models.keyedvectors.Vocab object at 0x000002114A543DA0>, 'strategies': <gensim.models.keyedvectors.Vocab object at 0x000002114A543DD8>, 'c': <gensim.models.keyedvectors.Vocab object at 0x000002114A543E10>, 'playing': <gensim.models.keyedvectors.Vocab object at 0x000002114A543E48>, 'better': <gensim.models.keyedvectors.Vocab object at 0x000002114A543E80>, 'average': <gensim.models.keyedvectors.Vocab object at 0x000002114A543EB8>, 'word': <gensim.models.keyedvectors.Vocab object at 0x000002114A543EF0>, 'proving': <gensim.models.keyedvectors.Vocab object at 0x000002114A543F28>, 'logical': <gensim.models.keyedvectors.Vocab object at 0x000002114A543F60>, 'theorems': <gensim.models.keyedvectors.Vocab object at 0x000002114A543F98>, 'run': <gensim.models.keyedvectors.Vocab object at 0x000002114A543FD0>, 'middle': <gensim.models.keyedvectors.Vocab object at 0x000002114A548048>, 'heavily': <gensim.models.keyedvectors.Vocab object at 0x000002114A548080>, 'established': <gensim.models.keyedvectors.Vocab object at 0x000002114A5480B8>, 'around': <gensim.models.keyedvectors.Vocab object at 0x000002114A5480F0>, 'world': <gensim.models.keyedvectors.Vocab object at 0x000002114A548128>, 'future': <gensim.models.keyedvectors.Vocab object at 0x000002114A548160>, 'predicted': <gensim.models.keyedvectors.Vocab object at 0x000002114A548198>, 'within': <gensim.models.keyedvectors.Vocab object at 0x000002114A5481D0>, 'generation': <gensim.models.keyedvectors.Vocab object at 0x000002114A548208>, 'substantially': <gensim.models.keyedvectors.Vocab object at 0x000002114A548240>, 'solved': <gensim.models.keyedvectors.Vocab object at 0x000002114A548278>, 'failed': <gensim.models.keyedvectors.Vocab object at 0x000002114A5482B0>, 'recognize': <gensim.models.keyedvectors.Vocab object at 0x000002114A5482E8>, 'difficulty': <gensim.models.keyedvectors.Vocab object at 0x000002114A548320>, 'progress': <gensim.models.keyedvectors.Vocab object at 0x000002114A548358>, 'pressure': <gensim.models.keyedvectors.Vocab object at 0x000002114A548390>, 'us': <gensim.models.keyedvectors.Vocab object at 0x000002114A5483C8>, 'fund': <gensim.models.keyedvectors.Vocab object at 0x000002114A548400>, 'projects': <gensim.models.keyedvectors.Vocab object at 0x000002114A548438>, 'british': <gensim.models.keyedvectors.Vocab object at 0x000002114A548470>, 'governments': <gensim.models.keyedvectors.Vocab object at 0x000002114A5484A8>, 'next': <gensim.models.keyedvectors.Vocab object at 0x000002114A5484E0>, 'would': <gensim.models.keyedvectors.Vocab object at 0x000002114A548518>, 'later': <gensim.models.keyedvectors.Vocab object at 0x000002114A548550>, 'difficult': <gensim.models.keyedvectors.Vocab object at 0x000002114A548588>, 'early': <gensim.models.keyedvectors.Vocab object at 0x000002114A5485C0>, 'revived': <gensim.models.keyedvectors.Vocab object at 0x000002114A5485F8>, 'expert': <gensim.models.keyedvectors.Vocab object at 0x000002114A548630>, 'form': <gensim.models.keyedvectors.Vocab object at 0x000002114A548668>, 'program': <gensim.models.keyedvectors.Vocab object at 0x000002114A5486A0>, 'simulated': <gensim.models.keyedvectors.Vocab object at 0x000002114A5486D8>, 'skills': <gensim.models.keyedvectors.Vocab object at 0x000002114A548710>, 'experts': <gensim.models.keyedvectors.Vocab object at 0x000002114A548748>, 'market': <gensim.models.keyedvectors.Vocab object at 0x000002114A548780>, 'billion': <gensim.models.keyedvectors.Vocab object at 0x000002114A5487B8>, 'dollars': <gensim.models.keyedvectors.Vocab object at 0x000002114A5487F0>, 'time': <gensim.models.keyedvectors.Vocab object at 0x000002114A548828>, 'japan': <gensim.models.keyedvectors.Vocab object at 0x000002114A548860>, 'fifth': <gensim.models.keyedvectors.Vocab object at 0x000002114A548898>, 'project': <gensim.models.keyedvectors.Vocab object at 0x000002114A5488D0>, 'inspired': <gensim.models.keyedvectors.Vocab object at 0x000002114A548908>, 'however': <gensim.models.keyedvectors.Vocab object at 0x000002114A548940>, 'second': <gensim.models.keyedvectors.Vocab object at 0x000002114A548978>, 'longer': <gensim.models.keyedvectors.Vocab object at 0x000002114A5489B0>, 'development': <gensim.models.keyedvectors.Vocab object at 0x000002114A5489E8>, 'mos': <gensim.models.keyedvectors.Vocab object at 0x000002114A548A20>, 'scale': <gensim.models.keyedvectors.Vocab object at 0x000002114A548A58>, 'integration': <gensim.models.keyedvectors.Vocab object at 0x000002114A548A90>, 'vlsi': <gensim.models.keyedvectors.Vocab object at 0x000002114A548AC8>, 'transistor': <gensim.models.keyedvectors.Vocab object at 0x000002114A548B00>, 'enabled': <gensim.models.keyedvectors.Vocab object at 0x000002114A548B38>, 'practical': <gensim.models.keyedvectors.Vocab object at 0x000002114A548B70>, 'network': <gensim.models.keyedvectors.Vocab object at 0x000002114A548BA8>, 'landmark': <gensim.models.keyedvectors.Vocab object at 0x000002114A548BE0>, 'publication': <gensim.models.keyedvectors.Vocab object at 0x000002114A548C18>, 'book': <gensim.models.keyedvectors.Vocab object at 0x000002114A548C50>, 'late': <gensim.models.keyedvectors.Vocab object at 0x000002114A548C88>, 'mining': <gensim.models.keyedvectors.Vocab object at 0x000002114A548CC0>, 'medical': <gensim.models.keyedvectors.Vocab object at 0x000002114A548CF8>, 'diagnosis': <gensim.models.keyedvectors.Vocab object at 0x000002114A548D30>, 'areas': <gensim.models.keyedvectors.Vocab object at 0x000002114A548D68>, 'due': <gensim.models.keyedvectors.Vocab object at 0x000002114A548DA0>, 'increasing': <gensim.models.keyedvectors.Vocab object at 0x000002114A548DD8>, 'see': <gensim.models.keyedvectors.Vocab object at 0x000002114A548E10>, 'moore': <gensim.models.keyedvectors.Vocab object at 0x000002114A548E48>, 'law': <gensim.models.keyedvectors.Vocab object at 0x000002114A548E80>, 'greater': <gensim.models.keyedvectors.Vocab object at 0x000002114A548EB8>, 'emphasis': <gensim.models.keyedvectors.Vocab object at 0x000002114A548EF0>, 'specific': <gensim.models.keyedvectors.Vocab object at 0x000002114A548F28>, 'scientific': <gensim.models.keyedvectors.Vocab object at 0x000002114A548F60>, 'blue': <gensim.models.keyedvectors.Vocab object at 0x000002114A548F98>, 'system': <gensim.models.keyedvectors.Vocab object at 0x000002114A548FD0>, 'beat': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B048>, 'champion': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B080>, 'may': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B0B8>, 'jeopardy': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B0F0>, 'exhibition': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B128>, 'match': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B160>, 'answering': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B198>, 'watson': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B1D0>, 'two': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B208>, 'significant': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B240>, 'algorithmic': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B278>, 'improvements': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B2B0>, 'access': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B2E8>, 'hungry': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B320>, 'accuracy': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B358>, 'benchmarks': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B390>, 'provides': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B3C8>, 'body': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B400>, 'motion': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B438>, 'xbox': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B470>, 'one': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B4A8>, 'uses': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B4E0>, 'algorithms': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B518>, 'personal': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B550>, 'assistants': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B588>, 'alphago': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B5C0>, 'games': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B5F8>, 'lee': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B630>, 'becoming': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B668>, 'player': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B6A0>, 'without': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B6D8>, 'three': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B710>, 'complex': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B748>, 'according': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B780>, 'bloomberg': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B7B8>, 'clark': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B7F0>, 'year': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B828>, 'number': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B860>, 'google': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B898>, 'increased': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B8D0>, 'usage': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B908>, 'presents': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B940>, 'error': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B978>, 'rates': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B9B0>, 'image': <gensim.models.keyedvectors.Vocab object at 0x000002114A54B9E8>, 'increase': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BA20>, 'rise': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BA58>, 'computing': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BA90>, 'datasets': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BAC8>, 'examples': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BB00>, 'microsoft': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BB38>, 'automatically': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BB70>, 'another': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BBA8>, 'facebook': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BBE0>, 'images': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BC18>, 'blind': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BC50>, 'survey': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BC88>, 'companies': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BCC0>, 'reported': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BCF8>, 'incorporated': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BD30>, 'processes': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BD68>, 'china': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BDA0>, 'greatly': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BDD8>, 'government': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BE10>, 'given': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BE48>, 'supply': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BE80>, 'rapidly': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BEB8>, 'output': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BEF0>, 'reports': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BF28>, 'tended': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BF60>, 'correctly': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BF98>, 'interpret': <gensim.models.keyedvectors.Vocab object at 0x000002114A54BFD0>, 'learn': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F048>, 'achieve': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F080>, 'typical': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F0B8>, 'utility': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F0F0>, 'function': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F128>, 'goal': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F160>, 'wins': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F198>, 'otherwise': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F1D0>, 'mathematically': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F208>, 'similar': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F240>, 'ones': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F278>, 'succeeded': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F2B0>, 'past': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F2E8>, 'explicitly': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F320>, 'induced': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F358>, 'programmed': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F390>, 'reinforcement': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F3C8>, 'implicitly': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F400>, 'rewarding': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F438>, 'types': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F470>, 'behavior': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F4A8>, 'alternatively': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F4E0>, 'evolutionary': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F518>, 'using': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F550>, 'mutate': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F588>, 'high': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F5C0>, 'animals': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F5F8>, 'evolved': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F630>, 'certain': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F668>, 'finding': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F6A0>, 'food': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F6D8>, 'nearest': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F710>, 'neighbor': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F748>, 'instead': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F780>, 'reason': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F7B8>, 'except': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F7F0>, 'degree': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F828>, 'implicit': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F860>, 'training': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F898>, 'still': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F8D0>, 'non': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F908>, 'whose': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F940>, 'narrow': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F978>, 'classification': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F9B0>, 'task': <gensim.models.keyedvectors.Vocab object at 0x000002114A54F9E8>, 'algorithm': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FA20>, 'set': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FA58>, 'built': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FA90>, 'top': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FAC8>, 'simpler': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FB00>, 'example': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FB38>, 'enhance': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FB70>, 'heuristics': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FBA8>, 'rules': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FBE0>, 'thumb': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FC18>, 'worked': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FC50>, 'well': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FC88>, 'write': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FCC0>, 'learners': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FCF8>, 'bayesian': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FD30>, 'decision': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FD68>, 'trees': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FDA0>, 'infinite': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FDD8>, 'memory': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FE10>, 'approximate': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FE48>, 'combination': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FE80>, 'best': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FEB8>, 'citation': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FEF0>, 'needed': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FF28>, 'therefore': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FF60>, 'considering': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FF98>, 'every': <gensim.models.keyedvectors.Vocab object at 0x000002114A54FFD0>, 'matching': <gensim.models.keyedvectors.Vocab object at 0x000002114A551048>, 'almost': <gensim.models.keyedvectors.Vocab object at 0x000002114A551080>, 'never': <gensim.models.keyedvectors.Vocab object at 0x000002114A5510B8>, 'combinatorial': <gensim.models.keyedvectors.Vocab object at 0x000002114A5510F0>, 'explosion': <gensim.models.keyedvectors.Vocab object at 0x000002114A551128>, 'amount': <gensim.models.keyedvectors.Vocab object at 0x000002114A551160>, 'grows': <gensim.models.keyedvectors.Vocab object at 0x000002114A551198>, 'exponentially': <gensim.models.keyedvectors.Vocab object at 0x000002114A5511D0>, 'much': <gensim.models.keyedvectors.Vocab object at 0x000002114A551208>, 'involves': <gensim.models.keyedvectors.Vocab object at 0x000002114A551240>, 'figuring': <gensim.models.keyedvectors.Vocab object at 0x000002114A551278>, 'identify': <gensim.models.keyedvectors.Vocab object at 0x000002114A5512B0>, 'avoid': <gensim.models.keyedvectors.Vocab object at 0x000002114A5512E8>, 'range': <gensim.models.keyedvectors.Vocab object at 0x000002114A551320>, 'unlikely': <gensim.models.keyedvectors.Vocab object at 0x000002114A551358>, 'map': <gensim.models.keyedvectors.Vocab object at 0x000002114A551390>, 'looking': <gensim.models.keyedvectors.Vocab object at 0x000002114A5513C8>, 'driving': <gensim.models.keyedvectors.Vocab object at 0x000002114A551400>, 'route': <gensim.models.keyedvectors.Vocab object at 0x000002114A551438>, 'cases': <gensim.models.keyedvectors.Vocab object at 0x000002114A551470>, 'path': <gensim.models.keyedvectors.Vocab object at 0x000002114A5514A8>, 'san': <gensim.models.keyedvectors.Vocab object at 0x000002114A5514E0>, 'francisco': <gensim.models.keyedvectors.Vocab object at 0x000002114A551518>, 'far': <gensim.models.keyedvectors.Vocab object at 0x000002114A551550>, 'thus': <gensim.models.keyedvectors.Vocab object at 0x000002114A551588>, 'pathfinding': <gensim.models.keyedvectors.Vocab object at 0x000002114A5515C0>, 'turn': <gensim.models.keyedvectors.Vocab object at 0x000002114A5515F8>, 'understand': <gensim.models.keyedvectors.Vocab object at 0x000002114A551630>, 'approach': <gensim.models.keyedvectors.Vocab object at 0x000002114A551668>, 'adult': <gensim.models.keyedvectors.Vocab object at 0x000002114A5516A0>, 'fever': <gensim.models.keyedvectors.Vocab object at 0x000002114A5516D8>, 'influenza': <gensim.models.keyedvectors.Vocab object at 0x000002114A551710>, 'inference': <gensim.models.keyedvectors.Vocab object at 0x000002114A551748>, 'current': <gensim.models.keyedvectors.Vocab object at 0x000002114A551780>, 'patient': <gensim.models.keyedvectors.Vocab object at 0x000002114A5517B8>, 'adjust': <gensim.models.keyedvectors.Vocab object at 0x000002114A5517F0>, 'way': <gensim.models.keyedvectors.Vocab object at 0x000002114A551828>, 'major': <gensim.models.keyedvectors.Vocab object at 0x000002114A551860>, 'extremely': <gensim.models.keyedvectors.Vocab object at 0x000002114A551898>, 'popular': <gensim.models.keyedvectors.Vocab object at 0x000002114A5518D0>, 'business': <gensim.models.keyedvectors.Vocab object at 0x000002114A551908>, 'applications': <gensim.models.keyedvectors.Vocab object at 0x000002114A551940>, 'svm': <gensim.models.keyedvectors.Vocab object at 0x000002114A551978>, 'patients': <gensim.models.keyedvectors.Vocab object at 0x000002114A5519B0>, 'age': <gensim.models.keyedvectors.Vocab object at 0x000002114A5519E8>, 'mostly': <gensim.models.keyedvectors.Vocab object at 0x000002114A551A20>, 'x': <gensim.models.keyedvectors.Vocab object at 0x000002114A551A58>, 'works': <gensim.models.keyedvectors.Vocab object at 0x000002114A551A90>, 'comparing': <gensim.models.keyedvectors.Vocab object at 0x000002114A551AC8>, 'altering': <gensim.models.keyedvectors.Vocab object at 0x000002114A551B00>, 'connections': <gensim.models.keyedvectors.Vocab object at 0x000002114A551B38>, 'seemed': <gensim.models.keyedvectors.Vocab object at 0x000002114A551B70>, 'useful': <gensim.models.keyedvectors.Vocab object at 0x000002114A551BA8>, 'main': <gensim.models.keyedvectors.Vocab object at 0x000002114A551BE0>, 'make': <gensim.models.keyedvectors.Vocab object at 0x000002114A551C18>, 'inferences': <gensim.models.keyedvectors.Vocab object at 0x000002114A551C50>, 'generalize': <gensim.models.keyedvectors.Vocab object at 0x000002114A551C88>, 'multiple': <gensim.models.keyedvectors.Vocab object at 0x000002114A551CC0>, 'different': <gensim.models.keyedvectors.Vocab object at 0x000002114A551CF8>, 'basis': <gensim.models.keyedvectors.Vocab object at 0x000002114A551D30>, 'likely': <gensim.models.keyedvectors.Vocab object at 0x000002114A551D68>, 'continue': <gensim.models.keyedvectors.Vocab object at 0x000002114A551DA0>, 'working': <gensim.models.keyedvectors.Vocab object at 0x000002114A551DD8>, 'rose': <gensim.models.keyedvectors.Vocab object at 0x000002114A551E10>, 'morning': <gensim.models.keyedvectors.Vocab object at 0x000002114A551E48>, 'last': <gensim.models.keyedvectors.Vocab object at 0x000002114A551E80>, 'probably': <gensim.models.keyedvectors.Vocab object at 0x000002114A551EB8>, 'color': <gensim.models.keyedvectors.Vocab object at 0x000002114A551EF0>, 'variants': <gensim.models.keyedvectors.Vocab object at 0x000002114A551F28>, 'undiscovered': <gensim.models.keyedvectors.Vocab object at 0x000002114A551F60>, 'black': <gensim.models.keyedvectors.Vocab object at 0x000002114A551F98>, 'exist': <gensim.models.keyedvectors.Vocab object at 0x000002114A551FD0>, 'occam': <gensim.models.keyedvectors.Vocab object at 0x000002114A556048>, 'razor': <gensim.models.keyedvectors.Vocab object at 0x000002114A556080>, 'simplest': <gensim.models.keyedvectors.Vocab object at 0x000002114A5560B8>, 'principle': <gensim.models.keyedvectors.Vocab object at 0x000002114A5560F0>, 'must': <gensim.models.keyedvectors.Vocab object at 0x000002114A556128>, 'designed': <gensim.models.keyedvectors.Vocab object at 0x000002114A556160>, 'theories': <gensim.models.keyedvectors.Vocab object at 0x000002114A556198>, 'bad': <gensim.models.keyedvectors.Vocab object at 0x000002114A5561D0>, 'fit': <gensim.models.keyedvectors.Vocab object at 0x000002114A556208>, 'overfitting': <gensim.models.keyedvectors.Vocab object at 0x000002114A556240>, 'attempt': <gensim.models.keyedvectors.Vocab object at 0x000002114A556278>, 'reduce': <gensim.models.keyedvectors.Vocab object at 0x000002114A5562B0>, 'accordance': <gensim.models.keyedvectors.Vocab object at 0x000002114A5562E8>, 'besides': <gensim.models.keyedvectors.Vocab object at 0x000002114A556320>, 'classic': <gensim.models.keyedvectors.Vocab object at 0x000002114A556358>, 'toy': <gensim.models.keyedvectors.Vocab object at 0x000002114A556390>, 'classifier': <gensim.models.keyedvectors.Vocab object at 0x000002114A5563C8>, 'trained': <gensim.models.keyedvectors.Vocab object at 0x000002114A556400>, 'brown': <gensim.models.keyedvectors.Vocab object at 0x000002114A556438>, 'horses': <gensim.models.keyedvectors.Vocab object at 0x000002114A556470>, 'might': <gensim.models.keyedvectors.Vocab object at 0x000002114A5564A8>, 'patches': <gensim.models.keyedvectors.Vocab object at 0x000002114A5564E0>, 'real': <gensim.models.keyedvectors.Vocab object at 0x000002114A556518>, 'classifiers': <gensim.models.keyedvectors.Vocab object at 0x000002114A556550>, 'determine': <gensim.models.keyedvectors.Vocab object at 0x000002114A556588>, 'relationship': <gensim.models.keyedvectors.Vocab object at 0x000002114A5565C0>, 'components': <gensim.models.keyedvectors.Vocab object at 0x000002114A5565F8>, 'abstract': <gensim.models.keyedvectors.Vocab object at 0x000002114A556630>, 'patterns': <gensim.models.keyedvectors.Vocab object at 0x000002114A556668>, 'pixels': <gensim.models.keyedvectors.Vocab object at 0x000002114A5566A0>, 'pattern': <gensim.models.keyedvectors.Vocab object at 0x000002114A5566D8>, 'results': <gensim.models.keyedvectors.Vocab object at 0x000002114A556710>, 'compared': <gensim.models.keyedvectors.Vocab object at 0x000002114A556748>, 'existing': <gensim.models.keyedvectors.Vocab object at 0x000002114A556780>, 'features': <gensim.models.keyedvectors.Vocab object at 0x000002114A5567B8>, 'commonsense': <gensim.models.keyedvectors.Vocab object at 0x000002114A5567F0>, 'notably': <gensim.models.keyedvectors.Vocab object at 0x000002114A556828>, 'powerful': <gensim.models.keyedvectors.Vocab object at 0x000002114A556860>, 'mechanisms': <gensim.models.keyedvectors.Vocab object at 0x000002114A556898>, 'na': <gensim.models.keyedvectors.Vocab object at 0x000002114A5568D0>, 'space': <gensim.models.keyedvectors.Vocab object at 0x000002114A556908>, 'physical': <gensim.models.keyedvectors.Vocab object at 0x000002114A556940>, 'interactions': <gensim.models.keyedvectors.Vocab object at 0x000002114A556978>, 'enables': <gensim.models.keyedvectors.Vocab object at 0x000002114A5569B0>, 'even': <gensim.models.keyedvectors.Vocab object at 0x000002114A5569E8>, 'young': <gensim.models.keyedvectors.Vocab object at 0x000002114A556A20>, 'children': <gensim.models.keyedvectors.Vocab object at 0x000002114A556A58>, 'easily': <gensim.models.keyedvectors.Vocab object at 0x000002114A556A90>, 'fall': <gensim.models.keyedvectors.Vocab object at 0x000002114A556AC8>, 'mechanism': <gensim.models.keyedvectors.Vocab object at 0x000002114A556B00>, 'helps': <gensim.models.keyedvectors.Vocab object at 0x000002114A556B38>, 'sentences': <gensim.models.keyedvectors.Vocab object at 0x000002114A556B70>, 'city': <gensim.models.keyedvectors.Vocab object at 0x000002114A556BA8>, 'councilmen': <gensim.models.keyedvectors.Vocab object at 0x000002114A556BE0>, 'demonstrators': <gensim.models.keyedvectors.Vocab object at 0x000002114A556C18>, 'violence': <gensim.models.keyedvectors.Vocab object at 0x000002114A556C50>, 'generic': <gensim.models.keyedvectors.Vocab object at 0x000002114A556C88>, 'lack': <gensim.models.keyedvectors.Vocab object at 0x000002114A556CC0>, 'means': <gensim.models.keyedvectors.Vocab object at 0x000002114A556CF8>, 'makes': <gensim.models.keyedvectors.Vocab object at 0x000002114A556D30>, 'ways': <gensim.models.keyedvectors.Vocab object at 0x000002114A556D68>, 'self': <gensim.models.keyedvectors.Vocab object at 0x000002114A556DA0>, 'location': <gensim.models.keyedvectors.Vocab object at 0x000002114A556DD8>, 'pedestrians': <gensim.models.keyedvectors.Vocab object at 0x000002114A556E10>, 'architectures': <gensim.models.keyedvectors.Vocab object at 0x000002114A556E48>, 'limited': <gensim.models.keyedvectors.Vocab object at 0x000002114A556E80>, 'really': <gensim.models.keyedvectors.Vocab object at 0x000002114A556EB8>, 'come': <gensim.models.keyedvectors.Vocab object at 0x000002114A556EF0>, 'beyond': <gensim.models.keyedvectors.Vocab object at 0x000002114A556F28>, 'measure': <gensim.models.keyedvectors.Vocab object at 0x000002114A556F60>, 'explanations': <gensim.models.keyedvectors.Vocab object at 0x000002114A556F98>, 'life': <gensim.models.keyedvectors.Vocab object at 0x000002114A556FD0>, 'straightforward': <gensim.models.keyedvectors.Vocab object at 0x000002114A559048>, 'computationally': <gensim.models.keyedvectors.Vocab object at 0x000002114A559080>, 'opposed': <gensim.models.keyedvectors.Vocab object at 0x000002114A5590B8>, 'gives': <gensim.models.keyedvectors.Vocab object at 0x000002114A5590F0>, 'classes': <gensim.models.keyedvectors.Vocab object at 0x000002114A559128>, 'models': <gensim.models.keyedvectors.Vocab object at 0x000002114A559160>, 'structural': <gensim.models.keyedvectors.Vocab object at 0x000002114A559198>, 'aim': <gensim.models.keyedvectors.Vocab object at 0x000002114A5591D0>, 'basic': <gensim.models.keyedvectors.Vocab object at 0x000002114A559208>, 'functional': <gensim.models.keyedvectors.Vocab object at 0x000002114A559240>, 'model': <gensim.models.keyedvectors.Vocab object at 0x000002114A559278>, 'overall': <gensim.models.keyedvectors.Vocab object at 0x000002114A5592B0>, 'manner': <gensim.models.keyedvectors.Vocab object at 0x000002114A5592E8>, 'simulating': <gensim.models.keyedvectors.Vocab object at 0x000002114A559320>, 'traits': <gensim.models.keyedvectors.Vocab object at 0x000002114A559358>, 'received': <gensim.models.keyedvectors.Vocab object at 0x000002114A559390>, 'developed': <gensim.models.keyedvectors.Vocab object at 0x000002114A5593C8>, 'step': <gensim.models.keyedvectors.Vocab object at 0x000002114A559400>, 'uncertain': <gensim.models.keyedvectors.Vocab object at 0x000002114A559438>, 'incomplete': <gensim.models.keyedvectors.Vocab object at 0x000002114A559470>, 'concepts': <gensim.models.keyedvectors.Vocab object at 0x000002114A5594A8>, 'fact': <gensim.models.keyedvectors.Vocab object at 0x000002114A5594E0>, 'rarely': <gensim.models.keyedvectors.Vocab object at 0x000002114A559518>, 'able': <gensim.models.keyedvectors.Vocab object at 0x000002114A559550>, 'fast': <gensim.models.keyedvectors.Vocab object at 0x000002114A559588>, 'central': <gensim.models.keyedvectors.Vocab object at 0x000002114A5595C0>, 'classical': <gensim.models.keyedvectors.Vocab object at 0x000002114A5595F8>, 'gather': <gensim.models.keyedvectors.Vocab object at 0x000002114A559630>, 'together': <gensim.models.keyedvectors.Vocab object at 0x000002114A559668>, 'possessed': <gensim.models.keyedvectors.Vocab object at 0x000002114A5596A0>, 'domain': <gensim.models.keyedvectors.Vocab object at 0x000002114A5596D8>, 'addition': <gensim.models.keyedvectors.Vocab object at 0x000002114A559710>, 'person': <gensim.models.keyedvectors.Vocab object at 0x000002114A559748>, 'comprehensive': <gensim.models.keyedvectors.Vocab object at 0x000002114A559780>, 'base': <gensim.models.keyedvectors.Vocab object at 0x000002114A5597B8>, 'contain': <gensim.models.keyedvectors.Vocab object at 0x000002114A5597F0>, 'properties': <gensim.models.keyedvectors.Vocab object at 0x000002114A559828>, 'categories': <gensim.models.keyedvectors.Vocab object at 0x000002114A559860>, 'relations': <gensim.models.keyedvectors.Vocab object at 0x000002114A559898>, 'situations': <gensim.models.keyedvectors.Vocab object at 0x000002114A5598D0>, 'events': <gensim.models.keyedvectors.Vocab object at 0x000002114A559908>, 'states': <gensim.models.keyedvectors.Vocab object at 0x000002114A559940>, 'effects': <gensim.models.keyedvectors.Vocab object at 0x000002114A559978>, 'know': <gensim.models.keyedvectors.Vocab object at 0x000002114A5599B0>, 'less': <gensim.models.keyedvectors.Vocab object at 0x000002114A5599E8>, 'domains': <gensim.models.keyedvectors.Vocab object at 0x000002114A559A20>, 'exists': <gensim.models.keyedvectors.Vocab object at 0x000002114A559A58>, 'ontology': <gensim.models.keyedvectors.Vocab object at 0x000002114A559A90>, 'description': <gensim.models.keyedvectors.Vocab object at 0x000002114A559AC8>, 'individuals': <gensim.models.keyedvectors.Vocab object at 0x000002114A559B00>, 'web': <gensim.models.keyedvectors.Vocab object at 0x000002114A559B38>, 'ontologies': <gensim.models.keyedvectors.Vocab object at 0x000002114A559B70>, 'provide': <gensim.models.keyedvectors.Vocab object at 0x000002114A559BA8>, 'foundation': <gensim.models.keyedvectors.Vocab object at 0x000002114A559BE0>, 'acting': <gensim.models.keyedvectors.Vocab object at 0x000002114A559C18>, 'cover': <gensim.models.keyedvectors.Vocab object at 0x000002114A559C50>, 'interest': <gensim.models.keyedvectors.Vocab object at 0x000002114A559C88>, 'area': <gensim.models.keyedvectors.Vocab object at 0x000002114A559CC0>, 'concern': <gensim.models.keyedvectors.Vocab object at 0x000002114A559CF8>, 'representations': <gensim.models.keyedvectors.Vocab object at 0x000002114A559D30>, 'retrieval': <gensim.models.keyedvectors.Vocab object at 0x000002114A559D68>, 'interpretation': <gensim.models.keyedvectors.Vocab object at 0x000002114A559DA0>, 'support': <gensim.models.keyedvectors.Vocab object at 0x000002114A559DD8>, 'discovery': <gensim.models.keyedvectors.Vocab object at 0x000002114A559E10>, 'need': <gensim.models.keyedvectors.Vocab object at 0x000002114A559E48>, 'predictions': <gensim.models.keyedvectors.Vocab object at 0x000002114A559E80>, 'change': <gensim.models.keyedvectors.Vocab object at 0x000002114A559EB8>, 'choices': <gensim.models.keyedvectors.Vocab object at 0x000002114A559EF0>, 'value': <gensim.models.keyedvectors.Vocab object at 0x000002114A559F28>, 'available': <gensim.models.keyedvectors.Vocab object at 0x000002114A559F60>, 'agent': <gensim.models.keyedvectors.Vocab object at 0x000002114A559F98>, 'assume': <gensim.models.keyedvectors.Vocab object at 0x000002114A559FD0>, 'consequences': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C048>, 'requires': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C080>, 'assess': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C0B8>, 'assessment': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C0F0>, 'multi': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C128>, 'competition': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C160>, 'emergent': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C198>, 'swarm': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C1D0>, 'fundamental': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C208>, 'concept': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C240>, 'improve': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C278>, 'experience': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C2B0>, 'unsupervised': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C2E8>, 'find': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C320>, 'input': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C358>, 'requiring': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C390>, 'label': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C3C8>, 'inputs': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C400>, 'supervised': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C438>, 'includes': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C470>, 'regression': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C4A8>, 'something': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C4E0>, 'belongs': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C518>, 'produce': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C550>, 'describes': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C588>, 'outputs': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C5C0>, 'predicts': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C5F8>, 'viewed': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C630>, 'spam': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C668>, 'maps': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C6A0>, 'text': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C6D8>, 'complexity': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C710>, 'sample': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C748>, 'required': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C780>, 'good': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C7B8>, 'sequence': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C7F0>, 'nlp': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C828>, 'read': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C860>, 'sufficiently': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C898>, 'enable': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C8D0>, 'user': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C908>, 'acquisition': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C940>, 'written': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C978>, 'translation': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C9B0>, 'occurrence': <gensim.models.keyedvectors.Vocab object at 0x000002114A55C9E8>, 'dog': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CA20>, 'document': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CA58>, 'words': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CA90>, 'sentiment': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CAC8>, 'page': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CB00>, 'semantic': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CB38>, 'classify': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CB70>, 'full': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CBA8>, 'sensors': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CBE0>, 'cameras': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CC18>, 'visible': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CC50>, 'spectrum': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CC88>, 'signals': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CCC0>, 'active': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CCF8>, 'aspects': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CD30>, 'facial': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CD68>, 'object': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CDA0>, 'vision': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CDD8>, 'analyze': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CE10>, 'visual': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CE48>, 'fifty': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CE80>, 'meter': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CEB8>, 'tall': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CEF0>, 'pedestrian': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CF28>, 'away': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CF60>, 'exactly': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CF98>, 'likelihood': <gensim.models.keyedvectors.Vocab object at 0x000002114A55CFD0>, 'advanced': <gensim.models.keyedvectors.Vocab object at 0x000002114A561048>, 'robotic': <gensim.models.keyedvectors.Vocab object at 0x000002114A561080>, 'industrial': <gensim.models.keyedvectors.Vocab object at 0x000002114A5610B8>, 'widely': <gensim.models.keyedvectors.Vocab object at 0x000002114A5610F0>, 'robot': <gensim.models.keyedvectors.Vocab object at 0x000002114A561128>, 'small': <gensim.models.keyedvectors.Vocab object at 0x000002114A561160>, 'dynamic': <gensim.models.keyedvectors.Vocab object at 0x000002114A561198>, 'pose': <gensim.models.keyedvectors.Vocab object at 0x000002114A5611D0>, 'challenge': <gensim.models.keyedvectors.Vocab object at 0x000002114A561208>, 'breaking': <gensim.models.keyedvectors.Vocab object at 0x000002114A561240>, 'movement': <gensim.models.keyedvectors.Vocab object at 0x000002114A561278>, 'individual': <gensim.models.keyedvectors.Vocab object at 0x000002114A5612B0>, 'maintaining': <gensim.models.keyedvectors.Vocab object at 0x000002114A5612E8>, 'moravec': <gensim.models.keyedvectors.Vocab object at 0x000002114A561320>, 'paradox': <gensim.models.keyedvectors.Vocab object at 0x000002114A561358>, 'low': <gensim.models.keyedvectors.Vocab object at 0x000002114A561390>, 'take': <gensim.models.keyedvectors.Vocab object at 0x000002114A5613C8>, 'named': <gensim.models.keyedvectors.Vocab object at 0x000002114A561400>, 'hans': <gensim.models.keyedvectors.Vocab object at 0x000002114A561438>, 'stated': <gensim.models.keyedvectors.Vocab object at 0x000002114A561470>, 'easy': <gensim.models.keyedvectors.Vocab object at 0x000002114A5614A8>, 'exhibit': <gensim.models.keyedvectors.Vocab object at 0x000002114A5614E0>, 'performance': <gensim.models.keyedvectors.Vocab object at 0x000002114A561518>, 'tests': <gensim.models.keyedvectors.Vocab object at 0x000002114A561550>, 'impossible': <gensim.models.keyedvectors.Vocab object at 0x000002114A561588>, 'give': <gensim.models.keyedvectors.Vocab object at 0x000002114A5615C0>, 'old': <gensim.models.keyedvectors.Vocab object at 0x000002114A5615F8>, 'target': <gensim.models.keyedvectors.Vocab object at 0x000002114A561630>, 'forms': <gensim.models.keyedvectors.Vocab object at 0x000002114A561668>, 'distributed': <gensim.models.keyedvectors.Vocab object at 0x000002114A5616A0>, 'coordination': <gensim.models.keyedvectors.Vocab object at 0x000002114A5616D8>, 'autonomous': <gensim.models.keyedvectors.Vocab object at 0x000002114A561710>, 'vehicles': <gensim.models.keyedvectors.Vocab object at 0x000002114A561748>, 'affective': <gensim.models.keyedvectors.Vocab object at 0x000002114A561780>, 'affects': <gensim.models.keyedvectors.Vocab object at 0x000002114A5617B8>, 'successes': <gensim.models.keyedvectors.Vocab object at 0x000002114A5617F0>, 'related': <gensim.models.keyedvectors.Vocab object at 0x000002114A561828>, 'analysis': <gensim.models.keyedvectors.Vocab object at 0x000002114A561860>, 'recently': <gensim.models.keyedvectors.Vocab object at 0x000002114A561898>, 'multimodal': <gensim.models.keyedvectors.Vocab object at 0x000002114A5618D0>, 'wherein': <gensim.models.keyedvectors.Vocab object at 0x000002114A561908>, 'classifies': <gensim.models.keyedvectors.Vocab object at 0x000002114A561940>, 'subject': <gensim.models.keyedvectors.Vocab object at 0x000002114A561978>, 'emotion': <gensim.models.keyedvectors.Vocab object at 0x000002114A5619B0>, 'valuable': <gensim.models.keyedvectors.Vocab object at 0x000002114A5619E8>, 'predict': <gensim.models.keyedvectors.Vocab object at 0x000002114A561A20>, 'emotional': <gensim.models.keyedvectors.Vocab object at 0x000002114A561A58>, 'allow': <gensim.models.keyedvectors.Vocab object at 0x000002114A561A90>, 'decisions': <gensim.models.keyedvectors.Vocab object at 0x000002114A561AC8>, 'appear': <gensim.models.keyedvectors.Vocab object at 0x000002114A561B00>, 'interaction': <gensim.models.keyedvectors.Vocab object at 0x000002114A561B38>, 'similarly': <gensim.models.keyedvectors.Vocab object at 0x000002114A561B70>, 'virtual': <gensim.models.keyedvectors.Vocab object at 0x000002114A561BA8>, 'tends': <gensim.models.keyedvectors.Vocab object at 0x000002114A561BE0>, 'users': <gensim.models.keyedvectors.Vocab object at 0x000002114A561C18>, 'actually': <gensim.models.keyedvectors.Vocab object at 0x000002114A561C50>, 'cyc': <gensim.models.keyedvectors.Vocab object at 0x000002114A561C88>, 'massive': <gensim.models.keyedvectors.Vocab object at 0x000002114A561CC0>, 'attempted': <gensim.models.keyedvectors.Vocab object at 0x000002114A561CF8>, 'breadth': <gensim.models.keyedvectors.Vocab object at 0x000002114A561D30>, 'cognition': <gensim.models.keyedvectors.Vocab object at 0x000002114A561D68>, 'limitations': <gensim.models.keyedvectors.Vocab object at 0x000002114A561DA0>, 'cross': <gensim.models.keyedvectors.Vocab object at 0x000002114A561DD8>, 'nowadays': <gensim.models.keyedvectors.Vocab object at 0x000002114A561E10>, 'tractable': <gensim.models.keyedvectors.Vocab object at 0x000002114A561E48>, 'automobile': <gensim.models.keyedvectors.Vocab object at 0x000002114A561E80>, 'navigation': <gensim.models.keyedvectors.Vocab object at 0x000002114A561EB8>, 'eventually': <gensim.models.keyedvectors.Vocab object at 0x000002114A561EF0>, 'agi': <gensim.models.keyedvectors.Vocab object at 0x000002114A561F28>, 'article': <gensim.models.keyedvectors.Vocab object at 0x000002114A561F60>, 'point': <gensim.models.keyedvectors.Vocab object at 0x000002114A561F98>, 'profile': <gensim.models.keyedvectors.Vocab object at 0x000002114A561FD0>, 'deepmind': <gensim.models.keyedvectors.Vocab object at 0x000002114A564048>, 'sequential': <gensim.models.keyedvectors.Vocab object at 0x000002114A564080>, 'transfer': <gensim.models.keyedvectors.Vocab object at 0x000002114A5640B8>, 'hypothetical': <gensim.models.keyedvectors.Vocab object at 0x000002114A5640F0>, 'argue': <gensim.models.keyedvectors.Vocab object at 0x000002114A564128>, 'kind': <gensim.models.keyedvectors.Vocab object at 0x000002114A564160>, 'currently': <gensim.models.keyedvectors.Vocab object at 0x000002114A564198>, 'lead': <gensim.models.keyedvectors.Vocab object at 0x000002114A5641D0>, 'look': <gensim.models.keyedvectors.Vocab object at 0x000002114A564208>, 'closely': <gensim.models.keyedvectors.Vocab object at 0x000002114A564240>, 'reach': <gensim.models.keyedvectors.Vocab object at 0x000002114A564278>, 'author': <gensim.models.keyedvectors.Vocab object at 0x000002114A5642B0>, 'argument': <gensim.models.keyedvectors.Vocab object at 0x000002114A5642E8>, 'order': <gensim.models.keyedvectors.Vocab object at 0x000002114A564320>, 'questions': <gensim.models.keyedvectors.Vocab object at 0x000002114A564358>, 'biology': <gensim.models.keyedvectors.Vocab object at 0x000002114A564390>, 'bird': <gensim.models.keyedvectors.Vocab object at 0x000002114A5643C8>, 'principles': <gensim.models.keyedvectors.Vocab object at 0x000002114A564400>, 'necessarily': <gensim.models.keyedvectors.Vocab object at 0x000002114A564438>, 'completely': <gensim.models.keyedvectors.Vocab object at 0x000002114A564470>, 'grey': <gensim.models.keyedvectors.Vocab object at 0x000002114A5644A8>, 'walter': <gensim.models.keyedvectors.Vocab object at 0x000002114A5644E0>, 'society': <gensim.models.keyedvectors.Vocab object at 0x000002114A564518>, 'university': <gensim.models.keyedvectors.Vocab object at 0x000002114A564550>, 'largely': <gensim.models.keyedvectors.Vocab object at 0x000002114A564588>, 'abandoned': <gensim.models.keyedvectors.Vocab object at 0x000002114A5645C0>, 'although': <gensim.models.keyedvectors.Vocab object at 0x000002114A5645F8>, 'reduced': <gensim.models.keyedvectors.Vocab object at 0x000002114A564630>, 'centered': <gensim.models.keyedvectors.Vocab object at 0x000002114A564668>, 'carnegie': <gensim.models.keyedvectors.Vocab object at 0x000002114A5646A0>, 'mellon': <gensim.models.keyedvectors.Vocab object at 0x000002114A5646D8>, 'stanford': <gensim.models.keyedvectors.Vocab object at 0x000002114A564710>, 'gofai': <gensim.models.keyedvectors.Vocab object at 0x000002114A564748>, 'great': <gensim.models.keyedvectors.Vocab object at 0x000002114A564780>, 'thinking': <gensim.models.keyedvectors.Vocab object at 0x000002114A5647B8>, 'economist': <gensim.models.keyedvectors.Vocab object at 0x000002114A5647F0>, 'studied': <gensim.models.keyedvectors.Vocab object at 0x000002114A564828>, 'management': <gensim.models.keyedvectors.Vocab object at 0x000002114A564860>, 'team': <gensim.models.keyedvectors.Vocab object at 0x000002114A564898>, 'psychological': <gensim.models.keyedvectors.Vocab object at 0x000002114A5648D0>, 'experiments': <gensim.models.keyedvectors.Vocab object at 0x000002114A564908>, 'develop': <gensim.models.keyedvectors.Vocab object at 0x000002114A564940>, 'architecture': <gensim.models.keyedvectors.Vocab object at 0x000002114A564978>, 'try': <gensim.models.keyedvectors.Vocab object at 0x000002114A5649B0>, 'focused': <gensim.models.keyedvectors.Vocab object at 0x000002114A5649E8>, 'variety': <gensim.models.keyedvectors.Vocab object at 0x000002114A564A20>, 'focus': <gensim.models.keyedvectors.Vocab object at 0x000002114A564A58>, 'programming': <gensim.models.keyedvectors.Vocab object at 0x000002114A564A90>, 'found': <gensim.models.keyedvectors.Vocab object at 0x000002114A564AC8>, 'ad': <gensim.models.keyedvectors.Vocab object at 0x000002114A564B00>, 'hoc': <gensim.models.keyedvectors.Vocab object at 0x000002114A564B38>, 'solutions': <gensim.models.keyedvectors.Vocab object at 0x000002114A564B70>, 'argued': <gensim.models.keyedvectors.Vocab object at 0x000002114A564BA8>, 'scruffy': <gensim.models.keyedvectors.Vocab object at 0x000002114A564BE0>, 'bases': <gensim.models.keyedvectors.Vocab object at 0x000002114A564C18>, 'hand': <gensim.models.keyedvectors.Vocab object at 0x000002114A564C50>, 'complicated': <gensim.models.keyedvectors.Vocab object at 0x000002114A564C88>, 'memories': <gensim.models.keyedvectors.Vocab object at 0x000002114A564CC0>, 'build': <gensim.models.keyedvectors.Vocab object at 0x000002114A564CF8>, 'revolution': <gensim.models.keyedvectors.Vocab object at 0x000002114A564D30>, 'introduced': <gensim.models.keyedvectors.Vocab object at 0x000002114A564D68>, 'edward': <gensim.models.keyedvectors.Vocab object at 0x000002114A564DA0>, 'successful': <gensim.models.keyedvectors.Vocab object at 0x000002114A564DD8>, 'key': <gensim.models.keyedvectors.Vocab object at 0x000002114A564E10>, 'component': <gensim.models.keyedvectors.Vocab object at 0x000002114A564E48>, 'facts': <gensim.models.keyedvectors.Vocab object at 0x000002114A564E80>, 'driven': <gensim.models.keyedvectors.Vocab object at 0x000002114A564EB8>, 'enormous': <gensim.models.keyedvectors.Vocab object at 0x000002114A564EF0>, 'imitate': <gensim.models.keyedvectors.Vocab object at 0x000002114A564F28>, 'especially': <gensim.models.keyedvectors.Vocab object at 0x000002114A564F60>, 'manage': <gensim.models.keyedvectors.Vocab object at 0x000002114A564F98>, 'embodied': <gensim.models.keyedvectors.Vocab object at 0x000002114A564FD0>, 'rodney': <gensim.models.keyedvectors.Vocab object at 0x000002114A568048>, 'brooks': <gensim.models.keyedvectors.Vocab object at 0x000002114A568080>, 'survive': <gensim.models.keyedvectors.Vocab object at 0x000002114A5680B8>, 'view': <gensim.models.keyedvectors.Vocab object at 0x000002114A5680F0>, 'control': <gensim.models.keyedvectors.Vocab object at 0x000002114A568128>, 'idea': <gensim.models.keyedvectors.Vocab object at 0x000002114A568160>, 'higher': <gensim.models.keyedvectors.Vocab object at 0x000002114A568198>, 'developmental': <gensim.models.keyedvectors.Vocab object at 0x000002114A5681D0>, 'novel': <gensim.models.keyedvectors.Vocab object at 0x000002114A568208>, 'david': <gensim.models.keyedvectors.Vocab object at 0x000002114A568240>, 'soft': <gensim.models.keyedvectors.Vocab object at 0x000002114A568278>, 'solution': <gensim.models.keyedvectors.Vocab object at 0x000002114A5682B0>, 'sufficient': <gensim.models.keyedvectors.Vocab object at 0x000002114A5682E8>, 'fuzzy': <gensim.models.keyedvectors.Vocab object at 0x000002114A568320>, 'application': <gensim.models.keyedvectors.Vocab object at 0x000002114A568358>, 'sophisticated': <gensim.models.keyedvectors.Vocab object at 0x000002114A568390>, 'hidden': <gensim.models.keyedvectors.Vocab object at 0x000002114A5683C8>, 'markov': <gensim.models.keyedvectors.Vocab object at 0x000002114A568400>, 'hmm': <gensim.models.keyedvectors.Vocab object at 0x000002114A568438>, 'compare': <gensim.models.keyedvectors.Vocab object at 0x000002114A568470>, 'shared': <gensim.models.keyedvectors.Vocab object at 0x000002114A5684A8>, 'levels': <gensim.models.keyedvectors.Vocab object at 0x000002114A5684E0>, 'acquiring': <gensim.models.keyedvectors.Vocab object at 0x000002114A568518>, 'test': <gensim.models.keyedvectors.Vocab object at 0x000002114A568550>, 'performed': <gensim.models.keyedvectors.Vocab object at 0x000002114A568588>, 'combinations': <gensim.models.keyedvectors.Vocab object at 0x000002114A5685C0>, 'critics': <gensim.models.keyedvectors.Vocab object at 0x000002114A5685F8>, 'shift': <gensim.models.keyedvectors.Vocab object at 0x000002114A568630>, 'necessary': <gensim.models.keyedvectors.Vocab object at 0x000002114A568668>, 'searching': <gensim.models.keyedvectors.Vocab object at 0x000002114A5686A0>, 'rule': <gensim.models.keyedvectors.Vocab object at 0x000002114A5686D8>, 'ends': <gensim.models.keyedvectors.Vocab object at 0x000002114A568710>, 'moving': <gensim.models.keyedvectors.Vocab object at 0x000002114A568748>, 'searches': <gensim.models.keyedvectors.Vocab object at 0x000002114A568780>, 'numbers': <gensim.models.keyedvectors.Vocab object at 0x000002114A5687B8>, 'result': <gensim.models.keyedvectors.Vocab object at 0x000002114A5687F0>, 'slow': <gensim.models.keyedvectors.Vocab object at 0x000002114A568828>, 'steps': <gensim.models.keyedvectors.Vocab object at 0x000002114A568860>, 'serve': <gensim.models.keyedvectors.Vocab object at 0x000002114A568898>, 'entirely': <gensim.models.keyedvectors.Vocab object at 0x000002114A5688D0>, 'tree': <gensim.models.keyedvectors.Vocab object at 0x000002114A568908>, 'guess': <gensim.models.keyedvectors.Vocab object at 0x000002114A568940>, 'limit': <gensim.models.keyedvectors.Vocab object at 0x000002114A568978>, 'size': <gensim.models.keyedvectors.Vocab object at 0x000002114A5689B0>, 'begin': <gensim.models.keyedvectors.Vocab object at 0x000002114A5689E8>, 'random': <gensim.models.keyedvectors.Vocab object at 0x000002114A568A20>, 'landscape': <gensim.models.keyedvectors.Vocab object at 0x000002114A568A58>, 'keep': <gensim.models.keyedvectors.Vocab object at 0x000002114A568A90>, 'population': <gensim.models.keyedvectors.Vocab object at 0x000002114A568AC8>, 'guesses': <gensim.models.keyedvectors.Vocab object at 0x000002114A568B00>, 'genetic': <gensim.models.keyedvectors.Vocab object at 0x000002114A568B38>, 'expression': <gensim.models.keyedvectors.Vocab object at 0x000002114A568B70>, 'via': <gensim.models.keyedvectors.Vocab object at 0x000002114A568BA8>, 'ant': <gensim.models.keyedvectors.Vocab object at 0x000002114A568BE0>, 'applied': <gensim.models.keyedvectors.Vocab object at 0x000002114A568C18>, 'method': <gensim.models.keyedvectors.Vocab object at 0x000002114A568C50>, 'truth': <gensim.models.keyedvectors.Vocab object at 0x000002114A568C88>, 'assigns': <gensim.models.keyedvectors.Vocab object at 0x000002114A568CC0>, 'vague': <gensim.models.keyedvectors.Vocab object at 0x000002114A568CF8>, 'statements': <gensim.models.keyedvectors.Vocab object at 0x000002114A568D30>, 'contribute': <gensim.models.keyedvectors.Vocab object at 0x000002114A568D68>, 'close': <gensim.models.keyedvectors.Vocab object at 0x000002114A568DA0>, 'train': <gensim.models.keyedvectors.Vocab object at 0x000002114A568DD8>, 'brake': <gensim.models.keyedvectors.Vocab object at 0x000002114A568E10>, 'default': <gensim.models.keyedvectors.Vocab object at 0x000002114A568E48>, 'logics': <gensim.models.keyedvectors.Vocab object at 0x000002114A568E80>, 'help': <gensim.models.keyedvectors.Vocab object at 0x000002114A568EB8>, 'handle': <gensim.models.keyedvectors.Vocab object at 0x000002114A568EF0>, 'calculus': <gensim.models.keyedvectors.Vocab object at 0x000002114A568F28>, 'event': <gensim.models.keyedvectors.Vocab object at 0x000002114A568F60>, 'causal': <gensim.models.keyedvectors.Vocab object at 0x000002114A568F98>, 'belief': <gensim.models.keyedvectors.Vocab object at 0x000002114A568FD0>, 'various': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A048>, 'filtering': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A080>, 'prediction': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A0B8>, 'occur': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A0F0>, 'observations': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A128>, 'chain': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A160>, 'live': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A198>, 'rate': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A1D0>, 'losses': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A208>, 'million': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A240>, 'shiny': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A278>, 'controllers': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A2B0>, 'conditions': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A2E8>, 'tuned': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A320>, 'making': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A358>, 'class': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A390>, 'combined': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A3C8>, 'observation': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A400>, 'k': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A438>, 'naive': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A470>, 'bayes': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A4A8>, 'depends': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A4E0>, 'distribution': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A518>, 'across': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A550>, 'perform': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A588>, 'actual': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A5C0>, 'rather': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A5F8>, 'speed': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A630>, 'conventional': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A668>, 'wisdom': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A6A0>, 'tend': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A6D8>, 'accurate': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A710>, 'sets': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A748>, 'neuron': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A780>, 'n': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A7B8>, 'weighted': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A7F0>, 'weights': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A828>, 'fire': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A860>, 'wire': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A898>, 'activation': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A8D0>, 'subnetwork': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A908>, 'meaning': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A940>, 'foot': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A978>, 'continuous': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A9B0>, 'predicting': <gensim.models.keyedvectors.Vocab object at 0x000002114A56A9E8>, 'car': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AA20>, 'widespread': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AA58>, 'public': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AA90>, 'consciousness': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AAC8>, 'contributed': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AB00>, 'corporate': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AB38>, 'spending': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AB70>, 'perceptron': <gensim.models.keyedvectors.Vocab object at 0x000002114A56ABA8>, 'layer': <gensim.models.keyedvectors.Vocab object at 0x000002114A56ABE0>, 'linear': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AC18>, 'alexey': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AC50>, 'grigorevich': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AC88>, 'ivakhnenko': <gensim.models.keyedvectors.Vocab object at 0x000002114A56ACC0>, 'stephen': <gensim.models.keyedvectors.Vocab object at 0x000002114A56ACF8>, 'kunihiko': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AD30>, 'fukushima': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AD68>, 'feedforward': <gensim.models.keyedvectors.Vocab object at 0x000002114A56ADA0>, 'signal': <gensim.models.keyedvectors.Vocab object at 0x000002114A56ADD8>, 'recurrent': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AE10>, 'short': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AE48>, 'perceptrons': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AE80>, 'competitive': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AEB8>, 'today': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AEF0>, 'backpropagation': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AF28>, 'automatic': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AF60>, 'published': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AF98>, 'temporal': <gensim.models.keyedvectors.Vocab object at 0x000002114A56AFD0>, 'gradient': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F048>, 'descent': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F080>, 'created': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F0B8>, 'groups': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F0F0>, 'neuroevolution': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F128>, 'dead': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F160>, 'links': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F198>, 'six': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F1D0>, 'layers': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F208>, 'seven': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F240>, 'depth': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F278>, 'ten': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F2B0>, 'length': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F2E8>, 'overview': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F320>, 'colleagues': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F358>, 'already': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F390>, 'pre': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F3C8>, 'hardware': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F400>, 'efficient': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F438>, 'convolutional': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F470>, 'cnns': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F4A8>, 'traced': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F4E0>, 'back': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F518>, 'competitions': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F550>, 'rnns': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F588>, 'arbitrary': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F5C0>, 'rnn': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F5F8>, 'suffer': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F630>, 'shown': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F668>, 'numerous': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F6A0>, 'lstm': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F6D8>, 'ctc': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F710>, 'voice': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F748>, 'billions': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F780>, 'improved': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F7B8>, 'steam': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F7F0>, 'purpose': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F828>, 'generating': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F860>, 'researcher': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F898>, 'andrew': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F8D0>, 'imperfect': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F908>, 'anything': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F940>, 'automate': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F978>, 'benchmark': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F9B0>, 'brought': <gensim.models.keyedvectors.Vocab object at 0x000002114A56F9E8>, 'challenges': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FA20>, 'automated': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FA58>, 'captcha': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FA90>, 'name': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FAC8>, 'administered': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FB00>, 'targeted': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FB38>, 'asks': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FB70>, 'taking': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FBA8>, 'extreme': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FBE0>, 'exceed': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FC18>, 'intellectual': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FC50>, 'list': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FC88>, 'drones': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FCC0>, 'art': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FCF8>, 'online': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FD30>, 'targeting': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FD68>, 'media': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FDA0>, 'source': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FDD8>, 'news': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FE10>, 'organizations': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FE48>, 'platforms': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FE80>, 'stories': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FEB8>, 'generate': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FEF0>, 'traffic': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FF28>, 'deepfakes': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FF60>, 'though': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FF98>, 'cause': <gensim.models.keyedvectors.Vocab object at 0x000002114A56FFD0>, 'harm': <gensim.models.keyedvectors.Vocab object at 0x000002114A572048>, 'healthcare': <gensim.models.keyedvectors.Vocab object at 0x000002114A572080>, 'cost': <gensim.models.keyedvectors.Vocab object at 0x000002114A5720B8>, 'save': <gensim.models.keyedvectors.Vocab object at 0x000002114A5720F0>, 'california': <gensim.models.keyedvectors.Vocab object at 0x000002114A572128>, 'drugs': <gensim.models.keyedvectors.Vocab object at 0x000002114A572160>, 'assisting': <gensim.models.keyedvectors.Vocab object at 0x000002114A572198>, 'doctors': <gensim.models.keyedvectors.Vocab object at 0x000002114A5721D0>, 'right': <gensim.models.keyedvectors.Vocab object at 0x000002114A572208>, 'cancer': <gensim.models.keyedvectors.Vocab object at 0x000002114A572240>, 'treat': <gensim.models.keyedvectors.Vocab object at 0x000002114A572278>, 'choose': <gensim.models.keyedvectors.Vocab object at 0x000002114A5722B0>, 'treatment': <gensim.models.keyedvectors.Vocab object at 0x000002114A5722E8>, 'decades': <gensim.models.keyedvectors.Vocab object at 0x000002114A572320>, 'monitor': <gensim.models.keyedvectors.Vocab object at 0x000002114A572358>, 'referred': <gensim.models.keyedvectors.Vocab object at 0x000002114A572390>, 'recent': <gensim.models.keyedvectors.Vocab object at 0x000002114A5723C8>, 'national': <gensim.models.keyedvectors.Vocab object at 0x000002114A572400>, 'surgery': <gensim.models.keyedvectors.Vocab object at 0x000002114A572438>, 'creation': <gensim.models.keyedvectors.Vocab object at 0x000002114A572470>, 'evolution': <gensim.models.keyedvectors.Vocab object at 0x000002114A5724A8>, 'involved': <gensim.models.keyedvectors.Vocab object at 0x000002114A5724E0>, 'collision': <gensim.models.keyedvectors.Vocab object at 0x000002114A572518>, 'prevention': <gensim.models.keyedvectors.Vocab object at 0x000002114A572550>, 'mapping': <gensim.models.keyedvectors.Vocab object at 0x000002114A572588>, 'vehicle': <gensim.models.keyedvectors.Vocab object at 0x000002114A5725C0>, 'developments': <gensim.models.keyedvectors.Vocab object at 0x000002114A5725F8>, 'trucks': <gensim.models.keyedvectors.Vocab object at 0x000002114A572630>, 'testing': <gensim.models.keyedvectors.Vocab object at 0x000002114A572668>, 'truck': <gensim.models.keyedvectors.Vocab object at 0x000002114A5726A0>, 'platoons': <gensim.models.keyedvectors.Vocab object at 0x000002114A5726D8>, 'factor': <gensim.models.keyedvectors.Vocab object at 0x000002114A572710>, 'influences': <gensim.models.keyedvectors.Vocab object at 0x000002114A572748>, 'driver': <gensim.models.keyedvectors.Vocab object at 0x000002114A572780>, 'surroundings': <gensim.models.keyedvectors.Vocab object at 0x000002114A5727B8>, 'passengers': <gensim.models.keyedvectors.Vocab object at 0x000002114A5727F0>, 'safety': <gensim.models.keyedvectors.Vocab object at 0x000002114A572828>, 'head': <gensim.models.keyedvectors.Vocab object at 0x000002114A572860>, 'decide': <gensim.models.keyedvectors.Vocab object at 0x000002114A572898>, 'financial': <gensim.models.keyedvectors.Vocab object at 0x000002114A5728D0>, 'investigation': <gensim.models.keyedvectors.Vocab object at 0x000002114A572908>, 'security': <gensim.models.keyedvectors.Vocab object at 0x000002114A572940>, 'fraud': <gensim.models.keyedvectors.Vocab object at 0x000002114A572978>, 'force': <gensim.models.keyedvectors.Vocab object at 0x000002114A5729B0>, 'services': <gensim.models.keyedvectors.Vocab object at 0x000002114A5729E8>, 'changes': <gensim.models.keyedvectors.Vocab object at 0x000002114A572A20>, 'place': <gensim.models.keyedvectors.Vocab object at 0x000002114A572A58>, 'august': <gensim.models.keyedvectors.Vocab object at 0x000002114A572A90>, 'trading': <gensim.models.keyedvectors.Vocab object at 0x000002114A572AC8>, 'behavioral': <gensim.models.keyedvectors.Vocab object at 0x000002114A572B00>, 'ceo': <gensim.models.keyedvectors.Vocab object at 0x000002114A572B38>, 'automation': <gensim.models.keyedvectors.Vocab object at 0x000002114A572B70>, 'rpa': <gensim.models.keyedvectors.Vocab object at 0x000002114A572BA8>, 'audit': <gensim.models.keyedvectors.Vocab object at 0x000002114A572BE0>, 'changed': <gensim.models.keyedvectors.Vocab object at 0x000002114A572C18>, 'economic': <gensim.models.keyedvectors.Vocab object at 0x000002114A572C50>, 'demand': <gensim.models.keyedvectors.Vocab object at 0x000002114A572C88>, 'estimate': <gensim.models.keyedvectors.Vocab object at 0x000002114A572CC0>, 'individualized': <gensim.models.keyedvectors.Vocab object at 0x000002114A572CF8>, 'furthermore': <gensim.models.keyedvectors.Vocab object at 0x000002114A572D30>, 'markets': <gensim.models.keyedvectors.Vocab object at 0x000002114A572D68>, 'reducing': <gensim.models.keyedvectors.Vocab object at 0x000002114A572DA0>, 'volume': <gensim.models.keyedvectors.Vocab object at 0x000002114A572DD8>, 'limits': <gensim.models.keyedvectors.Vocab object at 0x000002114A572E10>, 'rational': <gensim.models.keyedvectors.Vocab object at 0x000002114A572E48>, 'course': <gensim.models.keyedvectors.Vocab object at 0x000002114A572E80>, 'hacking': <gensim.models.keyedvectors.Vocab object at 0x000002114A572EB8>, 'attacks': <gensim.models.keyedvectors.Vocab object at 0x000002114A572EF0>, 'begun': <gensim.models.keyedvectors.Vocab object at 0x000002114A572F28>, 'teams': <gensim.models.keyedvectors.Vocab object at 0x000002114A572F60>, 'potential': <gensim.models.keyedvectors.Vocab object at 0x000002114A572F98>, 'service': <gensim.models.keyedvectors.Vocab object at 0x000002114A572FD0>, 'case': <gensim.models.keyedvectors.Vocab object at 0x000002114A575048>, 'tech': <gensim.models.keyedvectors.Vocab object at 0x000002114A575080>, 'calculate': <gensim.models.keyedvectors.Vocab object at 0x000002114A5750B8>, 'duration': <gensim.models.keyedvectors.Vocab object at 0x000002114A5750F0>, 'professions': <gensim.models.keyedvectors.Vocab object at 0x000002114A575128>, 'routinely': <gensim.models.keyedvectors.Vocab object at 0x000002114A575160>, 'commander': <gensim.models.keyedvectors.Vocab object at 0x000002114A575198>, 'technologies': <gensim.models.keyedvectors.Vocab object at 0x000002114A5751D0>, 'threat': <gensim.models.keyedvectors.Vocab object at 0x000002114A575208>, 'inside': <gensim.models.keyedvectors.Vocab object at 0x000002114A575240>, 'repetitive': <gensim.models.keyedvectors.Vocab object at 0x000002114A575278>, 'customer': <gensim.models.keyedvectors.Vocab object at 0x000002114A5752B0>, 'benefit': <gensim.models.keyedvectors.Vocab object at 0x000002114A5752E8>, 'adding': <gensim.models.keyedvectors.Vocab object at 0x000002114A575320>, 'exhibitions': <gensim.models.keyedvectors.Vocab object at 0x000002114A575358>, 'issue': <gensim.models.keyedvectors.Vocab object at 0x000002114A575390>, 'role': <gensim.models.keyedvectors.Vocab object at 0x000002114A5753C8>, 'arts': <gensim.models.keyedvectors.Vocab object at 0x000002114A575400>, 'ars': <gensim.models.keyedvectors.Vocab object at 0x000002114A575438>, 'electronica': <gensim.models.keyedvectors.Vocab object at 0x000002114A575470>, 'think': <gensim.models.keyedvectors.Vocab object at 0x000002114A5754A8>, 'dangerous': <gensim.models.keyedvectors.Vocab object at 0x000002114A5754E0>, 'scientists': <gensim.models.keyedvectors.Vocab object at 0x000002114A575518>, 'institute': <gensim.models.keyedvectors.Vocab object at 0x000002114A575550>, 'laws': <gensim.models.keyedvectors.Vocab object at 0x000002114A575588>, 'minimize': <gensim.models.keyedvectors.Vocab object at 0x000002114A5755C0>, 'risks': <gensim.models.keyedvectors.Vocab object at 0x000002114A5755F8>, 'united': <gensim.models.keyedvectors.Vocab object at 0x000002114A575630>, 'expressed': <gensim.models.keyedvectors.Vocab object at 0x000002114A575668>, 'job': <gensim.models.keyedvectors.Vocab object at 0x000002114A5756A0>, 'jobs': <gensim.models.keyedvectors.Vocab object at 0x000002114A5756D8>, 'hawking': <gensim.models.keyedvectors.Vocab object at 0x000002114A575710>, 'founder': <gensim.models.keyedvectors.Vocab object at 0x000002114A575748>, 'elon': <gensim.models.keyedvectors.Vocab object at 0x000002114A575780>, 'musk': <gensim.models.keyedvectors.Vocab object at 0x000002114A5757B8>, 'concerns': <gensim.models.keyedvectors.Vocab object at 0x000002114A5757F0>, 'spell': <gensim.models.keyedvectors.Vocab object at 0x000002114A575828>, 'end': <gensim.models.keyedvectors.Vocab object at 0x000002114A575860>, 'race': <gensim.models.keyedvectors.Vocab object at 0x000002114A575898>, 'superintelligence': <gensim.models.keyedvectors.Vocab object at 0x000002114A5758D0>, 'argues': <gensim.models.keyedvectors.Vocab object at 0x000002114A575908>, 'resources': <gensim.models.keyedvectors.Vocab object at 0x000002114A575940>, 'shut': <gensim.models.keyedvectors.Vocab object at 0x000002114A575978>, 'prevent': <gensim.models.keyedvectors.Vocab object at 0x000002114A5759B0>, 'prominent': <gensim.models.keyedvectors.Vocab object at 0x000002114A5759E8>, 'responsible': <gensim.models.keyedvectors.Vocab object at 0x000002114A575A20>, 'concerned': <gensim.models.keyedvectors.Vocab object at 0x000002114A575A58>, 'mark': <gensim.models.keyedvectors.Vocab object at 0x000002114A575A90>, 'believes': <gensim.models.keyedvectors.Vocab object at 0x000002114A575AC8>, 'developing': <gensim.models.keyedvectors.Vocab object at 0x000002114A575B00>, 'realized': <gensim.models.keyedvectors.Vocab object at 0x000002114A575B38>, 'worth': <gensim.models.keyedvectors.Vocab object at 0x000002114A575B70>, 'researching': <gensim.models.keyedvectors.Vocab object at 0x000002114A575BA8>, 'either': <gensim.models.keyedvectors.Vocab object at 0x000002114A575BE0>, 'weizenbaum': <gensim.models.keyedvectors.Vocab object at 0x000002114A575C18>, 'position': <gensim.models.keyedvectors.Vocab object at 0x000002114A575C50>, 'computationalism': <gensim.models.keyedvectors.Vocab object at 0x000002114A575C88>, 'women': <gensim.models.keyedvectors.Vocab object at 0x000002114A575CC0>, 'men': <gensim.models.keyedvectors.Vocab object at 0x000002114A575CF8>, 'approving': <gensim.models.keyedvectors.Vocab object at 0x000002114A575D30>, 'ranging': <gensim.models.keyedvectors.Vocab object at 0x000002114A575D68>, 'recidivism': <gensim.models.keyedvectors.Vocab object at 0x000002114A575DA0>, 'defendants': <gensim.models.keyedvectors.Vocab object at 0x000002114A575DD8>, 'compas': <gensim.models.keyedvectors.Vocab object at 0x000002114A575E10>, 'white': <gensim.models.keyedvectors.Vocab object at 0x000002114A575E48>, 'employment': <gensim.models.keyedvectors.Vocab object at 0x000002114A575E80>, 'creates': <gensim.models.keyedvectors.Vocab object at 0x000002114A575EB8>, 'worry': <gensim.models.keyedvectors.Vocab object at 0x000002114A575EF0>, 'collar': <gensim.models.keyedvectors.Vocab object at 0x000002114A575F28>, 'subjective': <gensim.models.keyedvectors.Vocab object at 0x000002114A575F60>, 'ford': <gensim.models.keyedvectors.Vocab object at 0x000002114A575F98>, 'economists': <gensim.models.keyedvectors.Vocab object at 0x000002114A575FD0>, 'want': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A048>, 'ethical': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A080>, 'moral': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A0B8>, 'friendly': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A0F0>, 'discussion': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A128>, 'towards': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A160>, 'rights': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A198>, 'wallach': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A1D0>, 'amas': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A208>, 'identifies': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A240>, 'aaai': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A278>, 'symposium': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A2B0>, 'concerning': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A2E8>, 'dimension': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A320>, 'morality': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A358>, 'stems': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A390>, 'ais': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A3C8>, 'civilization': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A400>, 'earth': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A438>, 'sentient': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A470>, 'hard': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A4A8>, 'explaining': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A4E0>, 'feel': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A518>, 'explain': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A550>, 'swatch': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A588>, 'red': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A5C0>, 'looks': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A5F8>, 'day': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A630>, 'searle': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A668>, 'strong': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A6A0>, 'transhumanism': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A6D8>, 'improvement': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A710>, 'singularity': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A748>, 'ray': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A780>, 'kurzweil': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A7B8>, 'george': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A7F0>, 'culture': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A828>, 'asimov': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A860>, 'series': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A898>, 'sorayama': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A8D0>, 'organic': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A908>, 'dick': <gensim.models.keyedvectors.Vocab object at 0x000002114A57A940>}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(all_words, min_count=2)\n",
    "\n",
    "vocabulary = word2vec.wv.vocab\n",
    "print(vocabulary)\n",
    "#The output we see is the list of unique words which appear at least twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "We successfully created our Word2Vec model in the last section. Now is the time to explore what we created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Vectors for a Word\n",
    "We know that the Word2Vec model converts words to their corresponding vectors. Let’s see how we can view vector representation of any particular word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v1 = word2vec.wc('artificial')\n",
    "#The code does not work, as word2vec has no attribute wc. Will look into this in more detail later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector v1 contains the vector representation for the word “artificial”. By default, a hundred dimensional vector is created by Gensim Word2Vec. This is a much, much smaller vector as compared to what would have been produced by bag of words. If we use the bag of words approach for embedding the article, the length of the vector for each will be 1206 since there are 1206 unique words with a minimum frequency of 2. If the minimum frequency of occurrence is set to 1, the size of the bag of words vector will further increase. On the other hand, vectors generated through Word2Vec are not affected by the size of the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Similar Words\n",
    "\n",
    "Earlier we said that contextual information of the words is not lost using Word2Vec approach. We can verify this by finding all the words similar to the word “intelligence”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('many', 0.680070698261261),\n",
       " ('human', 0.6624724864959717),\n",
       " ('ai', 0.6479796171188354),\n",
       " ('could', 0.6053080558776855),\n",
       " ('artificial', 0.6050031185150146),\n",
       " ('use', 0.5637954473495483),\n",
       " ('computer', 0.5551739931106567),\n",
       " ('humans', 0.5545571446418762),\n",
       " ('search', 0.5525883436203003),\n",
       " ('learning', 0.5486801862716675)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words = word2vec.wv.most_similar('intelligence')\n",
    "sim_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, you can see the words similar to “intelligence” along with their similarity index. The word “ai” is the one of the most similar words to “intelligence” according to the model, which actually makes sense. Similarly, words such as “human” and “artificial” often coexist with the word “intelligence”. Our model has successfully captured these relations using just a single Wikipedia article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding Layer\n",
    "\n",
    "The embedding layer in Keras can be used when we want to create the embeddings to embed higher dimensional data into lower dimensional vector space.\n",
    "\n",
    "Keras offers an Embedding layer that can be used for neural networks on text data. It requires that the input data be integer encoded so that each word is represented by a unique integer. \n",
    "\n",
    "This data preparation step can be performed using the Tokenizer API also provided with Keras. \n",
    "\n",
    "The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset. You must specify:\n",
    "- the input dim which is the size of the vocabulary\n",
    "- the output dim which is the size of the vector space of the embedding\n",
    "- and optionally the input length which is the number of words in input sequences\n",
    "\n",
    "example:\n",
    "\n",
    "A vocabulary of 200 words, a distributed representation of 32 dimensions and an input length of 50 words.\n",
    "\n",
    "- _layer = Embedding(200, 32, input_length=50)\n",
    "- _Concrete example of defining an Embedding layer_\n",
    "\n",
    "In fact, the output vectors are not computed from the input using any mathematical operation. Instead, each input integer is used as an index to access a table that contains all possible vectors. That is the reason why you need to specify the size of the vocabulary as the first argument (so the table can be initialized).+\n",
    "\n",
    "The most common application of this layer is for text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s see a simple example. Our training set consists only of two phrases:\n",
    "\n",
    "S1 = 'Hope to see you soon'\n",
    "S2 = 'Nice to see you again'\n",
    "\n",
    "#So we can encode these phrases by assigning each word a unique integer number (by order of appearance in our training dataset for example). \n",
    "#Then our phrases could be rewritten as:\n",
    "\n",
    "P1 = [0,1,2,3,4]\n",
    "P2 = [5,1,2,3,6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Now imagine we want to train a network whose first layer is an embedding layer. In this case, we should initialize it as follows:\n",
    "\n",
    "Embedding(7, 2, input_length=5)\n",
    "\n",
    "- The first argument (7) is the number of distinct words in the training set. \n",
    "- The second argument (2) indicates the size of the embedding vectors. \n",
    "- The input_length argument, of course, determines the size of each input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code found on https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic and useful task while dealing with text based problems is to tokenize each word separately and label each word according to its most likely part of speech. This task is basically called as Part of Speech Tagging (POST).\n",
    "\n",
    "In this lesson, we will use the Brown Corpus, an influential dataset that is used in many studies of POST. The Brown Corpus defined a tagset (specific collection of POS labels) that has been reused in many other annotated resources in English.\n",
    "\n",
    "Recently, a different version of the tagset has been defined which is called the Universal Parts of Speech Tagset.\n",
    "\n",
    "Let’s start with NLTK installation and downloading i.e. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\renate\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (3.4.0.3)\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The FreqDist NLTK Object: Counting Things\n",
    "\n",
    "FreqDist (Frequency Distribution) is an object that counts occurrences of objects. It is defined in the nltk.probability module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 2, 'b': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's demonstrate how it works\n",
    "from nltk.probability import FreqDist\n",
    "list = ['a', 'b', 'a']\n",
    "fdist = FreqDist(list)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['a']\n",
    "#the frequency of 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['c']\n",
    "#the frequency of 'c' --> 0 as this is not in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.max()\n",
    "#the maximum object / most frequent object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist) \n",
    "#how many objects are in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a', 'b'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.keys()\n",
    "#What unique keys are there in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.freq('a')\n",
    "#What % is the frequency of 'a' of the total number of counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.N()   \n",
    "#number of samples counted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on the Brown Corpus with NLTK\n",
    "The tagged_sents version of the corpus is a list of sentences. Each sentence is a list of pairs (tuples) (word, tag). Similarly, one can access the corpus as a flat list of tagged words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Renate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "brown_news_tagged = brown.tagged_sents(tagset='universal')\n",
    "brown_news_words = brown.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Renate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let’s check: which word is the most common among the 100,000 words in this part of the Brown corpus? Which tag is the most common?\n",
    "import nltk\n",
    "nltk.download('universal_tagset')\n",
    "fdistw = FreqDist([w for (w, t) in brown_news_words])\n",
    "fdistw.N()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw 1,161,192 words in this section of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56057"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdistw) \n",
    "#distinct words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistw.max() \n",
    "#most frequent word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62713"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistw['the']  \n",
    "#how many times is 'the' in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5.40%\n"
     ]
    }
   ],
   "source": [
    "print('%5.2f%%' % (fdistw.freq('the') * 100))\n",
    "#We observe that the distribution of word tokens to word types is extremely unbalanced – a single word (the) accounts for over 5% of the word tokens. \n",
    "#This is a general observation of linguistic data — known as Zipf’s Law — few types are extremely frequent, and many types are extremely rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinguishing Word Type and Work Token\n",
    "When distinguishing word type and word token, we can decide to consider that strings that vary only because of case variants correspond to the same word type – for example, the token Book and book correspond to the same word type book (and so do bOOk and bOok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us count the words without distinction of upper/lower case and the tags\n",
    "fdistwl = FreqDist([w.lower() for (w, t) in brown_news_words])\n",
    "fdistt = FreqDist([t for (w, t) in brown_news_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49815"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdistwl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ignore case variants, there are only 49,815 word types instead of 62,713 when case differences are kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.73%\n"
     ]
    }
   ],
   "source": [
    "#let's find the number of NOUN's in the text\n",
    "print('%5.2f%%' % (fdistt.freq('NOUN') * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity of the POST task\n",
    "The first question we address about the task of POS tagging is: how complex is it?\n",
    "\n",
    "One way to quantify the complexity of the task is to measure its perplexity. The intuitive meaning of perplexity is: when the tagger is considering which tag to associate to a word, how “confused” is it? That is, how many options does it have to choose from?\n",
    "\n",
    "Obviously, this depends on the number of tags in the tagset. The universal tagset includes 17 tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NOUN': 275558, 'VERB': 182750, '.': 147565, 'ADP': 144766, 'DET': 137019, 'ADJ': 83721, 'ADV': 56239, 'PRON': 49334, 'CONJ': 38151, 'PRT': 29829, ...})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of any knowledge about words and tags, the perplexity of the task with a tagset of size 17 will be 17. We will see that adding knowledge will reduce the perplexity of the task.\n",
    "\n",
    "Note that the decision on how to tag a word, without more information is ambiguous for multiple reasons:\n",
    "\n",
    "- The same string can be understood as a noun or a verb (book).\n",
    "- Some POS tags have a systematically ambiguous definition: a present participle can be used in progressive verb usages (I am going:VERB), but it can also be used in an adjectival position modifying a noun: (A striking:ADJ comparison). In other words, it is unclear in the definition itself of the tag whether the tag refers to a syntactic function or to a morphological property of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring success\n",
    "Let’s say, we develop a tagger, how to ensure if the tagger is successful or not, whether the decision made by the tagger is good or not?\n",
    "\n",
    "The way to address these issues is to define a criterion for success, and to test the tagger on a large test dataset. Assume we have a large dataset of 1M words with their tags assigned manually. We first split the dataset into 2 parts: one part on which we will “learn” facts about the words and their tags (we call this the training dataset), and one part which we use to test the results of our tagger (we call this the test dataset).\n",
    "\n",
    "It is critical NOT to test our tagger on the training dataset — because we want to test whether the tagger is able to generalize from data it has seen and make decision on unseen data. (A “stupid” tagger would learn the exact data seen in the training dataset “by heart”, and respond exactly as shown when asked on training data — it would get a perfect score on the training data, but a poor score on any unseen data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged:  [('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]\n",
      "Untagged:  ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "#This is one way to split the dataset into training and testing:\n",
    "brown_train = brown_news_tagged[5000:]\n",
    "brown_test = brown_news_tagged[:5000]\n",
    "from nltk.tag import untag\n",
    "test_sent = untag(brown_test[0])\n",
    "print(\"Tagged: \", brown_test[0])\n",
    "print(\"Untagged: \", test_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure success, in this task, we will measure accuracy. The tagger object in NLTK includes a method called evaluate to measure the accuracy of a tagger on a given test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'XYZ'), ('is', 'XYZ'), ('a', 'XYZ'), ('test', 'XYZ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A default tagger assigns the same tag to all words\n",
    "from nltk import DefaultTagger\n",
    "default_tagger = DefaultTagger('XYZ')\n",
    "default_tagger.tag('This is a test'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 30.2%\n"
     ]
    }
   ],
   "source": [
    "#Since ‘NOUN’ is the most frequent universal tag in the Brown corpus, we can use a tagger that assigns ‘NOUN’ to all words as a baseline.\n",
    "default_tagger = DefaultTagger('NOUN')\n",
    "print('Accuracy: %4.1f%%' % (100.0 * default_tagger.evaluate(brown_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, note that we improved the expected accuracy from picking one out of 17 answers with no knowledge, to picking one out of about 3 answers with very little knowledge (what is the most frequent tag in the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources of Knowledge to Improve Tagging Accuracy\n",
    "Intuitively, the sources of knowledge that can help us decide what is the tag of a word include:\n",
    "\n",
    "- A dictionary that lists the possible parts of speech for each word\n",
    "- The context of the word in a sentence (neighboring words)\n",
    "- The morphological form of the word (suffixes, prefixes)\n",
    "We will now develop a sequence of taggers that use these knowledge sources, and combine them. The taggers we develop will implement the nltk.tag.TaggerI interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup Tagger: Using Dictionary Knowledge\n",
    "Assume we have a dictionary that lists the possible tags for each word in English. Could we use this information to perform better tagging?\n",
    "\n",
    "The intuition is that we would only assign to a word a tag that it can have in the dictionary. For example, if “box” can only be a Verb or a Noun, when we have to tag an instance of the word “box”, we only choose between 2 options – and not between 17 options. Thus, dictionary knowledge will reduce the perplexity of the task.\n",
    "\n",
    "There are 3 issues we must address to turn this into working code:\n",
    "\n",
    "- Where do we get the dictionary?\n",
    "- How do we choose between the various tags associated to a word in the dictionary? (For example, how do we choose between VERB and NOUN for “box”).\n",
    "- What do we do for words that do not appear in the dictionary?\n",
    "\n",
    "The simple solutions we will test are the following – note that for each question, there exist other strategies that we will investigate later:\n",
    "\n",
    "- Where do we get the dictionary: we will learn it from a sample dataset.\n",
    "- How do we choose between the various tags associated to a word in the dictionary: we will choose the most likely tag as observed in the sample dataset.\n",
    "- What do we do for words that do not appear in the dictionary: we will pass unknown words to a backoff tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", None),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'ADJ'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The nltk.UnigramTagger implements this overall strategy. \n",
    "#It must be trained on a dataset, from which it builds a model of “unigrams”. The following code shows how it is used:\n",
    "\n",
    "from nltk import UnigramTagger\n",
    "# Train the unigram model\n",
    "unigram_tagger = UnigramTagger(brown_train)\n",
    "# Test it on a single sentence\n",
    "unigram_tagger.tag(untag(brown_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the unigram tagger leaves some words tagged as ‘None’ — these are unknown words, words that were not observed in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram tagger accuracy: 90.5%\n"
     ]
    }
   ],
   "source": [
    "#How successful is this tagger?\n",
    "print('Unigram tagger accuracy: %4.1f%%' % ( 100.0 * unigram_tagger.evaluate(brown_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90.5% is quite an improvement on the 31% of the default tagger. And this is without any backoff and without using morphological clues.\n",
    "\n",
    "Is 90.5% a good level of accuracy? In fact it is not. It is accuracy per word. It means that on average, in every sentence of about 20 words, we will accumulate 2 errors. 2 errors in each sentence is a very high error rate. It makes it difficult to run another task on the output of such a tagger. Think how difficult the life of a parser would be if 2 words in every sentence are wrongly tagged. The problem is known as the pipeline effect — when language processing tools are chained in a pipeline, error rates accumulate from module to module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram tagger with backoff accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "#How much would a good backoff help? Let’s try first to add the NN-default tagger as a backoff:\n",
    "nn_tagger = DefaultTagger('NOUN')\n",
    "\n",
    "ut2 = UnigramTagger(brown_train, backoff=nn_tagger)\n",
    "print('Unigram tagger with backoff accuracy: %4.1f%%' % ( 100.0 * ut2.evaluate(brown_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a simple backoff (with accuracy of 31%) improved accuracy from 90.5% to 94.5%.\n",
    "\n",
    "One way to report this is in terms of error reduction: the error rate went down from 9.5% (100-90.5) to 5.5%. That’s an absolute error reduction of 9.5-5.5 = 4.0%. Error reduction is generally reported as a percentage of the error: 100.0 * (4.0 / 9.5) = 42.1% relative error reduction.\n",
    "\n",
    "In other words, out of the words not tagged by the original model (with no backoff), 42.1% were corrected by the backoff.\n",
    "\n",
    "What can we say about this error reduction? It is different from the accuracy of the backoff (42.1% vs 31%).\n",
    "\n",
    "One lesson to learn from this is that the distribution of unknown words is significantly different from the distribution of all the words in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Parts of speech are classes of words that can be characterized by criteria of different types:\n",
    "\n",
    "- Syntactic: 2 words of the same class can substitute each other in a sentence and leave the sentence syntactically acceptable\n",
    "- Morphological: words of the same class are inflected in similar manner\n",
    "- Semantic: words of the same class denote entities of similar semantic types (object, action, property, relation)\n",
    "\n",
    "Tagsets of various granularities can be considered. We mentioned the standard Brown corpus tagset (about 60 tags for the complete tagset) and the reduced universal tagset (17 tags).\n",
    "\n",
    "The key point of the approach we investigated is that it is data-driven: we attempt to solve the task by:\n",
    "\n",
    "- Obtain sample data annotated manually: we used the Brown corpus\n",
    "- Define a success metric: we used the definition of accuracy\n",
    "- Measure the adequacy of a method by measuring its success\n",
    "- Measure the complexity of the problem by using the notion of perplexity\n",
    "\n",
    "The computational methods we developed are characterized by:\n",
    "\n",
    "- We first define possible knowledge sources that can help us solve the task. Specifically, we investigated dictionary, morphological context as possible sources.\n",
    "- We developed computational models that represent each of these knowledge sources in simple data structures (hash tables, frequency distributions, conditional frequency distributions).\n",
    "- We tested simple machine learning methods: data is acquired by inspecting a training dataset, then evaluated by testing on a test dataset.\n",
    "- We investigated one method to combine several systems into a combined system: backoff models.\n",
    "This methodology will be further developed in the next chapters, as we will address more complex tasks (parsing, summarization) and use more sophisticated machine learning methods.\n",
    "\n",
    "The task of Parts of Speech tagging is very well studied in English. The most efficient systems obtain accuracy rates of over 98% even on fine granularity tagsets – which is equivalent to the rate of success human beings obtain and the best agreement among human taggers generally obtained. The best systems use better machine learning algorithms (HMM, SVM) and treat unknown words (words not seen in training data) with more sophistication than what we have observed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
